{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2023-12-13T04:22:36.529033Z","iopub.status.busy":"2023-12-13T04:22:36.528754Z","iopub.status.idle":"2023-12-13T04:23:42.229335Z","shell.execute_reply":"2023-12-13T04:23:42.228461Z","shell.execute_reply.started":"2023-12-13T04:22:36.529007Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","cudf 23.8.0 requires cupy-cuda11x>=12.0.0, which is not installed.\n","cuml 23.8.0 requires cupy-cuda11x>=12.0.0, which is not installed.\n","dask-cudf 23.8.0 requires cupy-cuda11x>=12.0.0, which is not installed.\n","beatrix-jupyterlab 2023.814.150030 requires jupyter-server~=1.16, but you have jupyter-server 2.12.1 which is incompatible.\n","beatrix-jupyterlab 2023.814.150030 requires jupyterlab~=3.4, but you have jupyterlab 4.0.5 which is incompatible.\n","cudf 23.8.0 requires protobuf<5,>=4.21, but you have protobuf 3.20.3 which is incompatible.\n","cuml 23.8.0 requires dask==2023.7.1, but you have dask 2023.12.0 which is incompatible.\n","cuml 23.8.0 requires distributed==2023.7.1, but you have distributed 2023.12.0 which is incompatible.\n","dask-cuda 23.8.0 requires dask==2023.7.1, but you have dask 2023.12.0 which is incompatible.\n","dask-cuda 23.8.0 requires distributed==2023.7.1, but you have distributed 2023.12.0 which is incompatible.\n","dask-cudf 23.8.0 requires dask==2023.7.1, but you have dask 2023.12.0 which is incompatible.\n","dask-cudf 23.8.0 requires distributed==2023.7.1, but you have distributed 2023.12.0 which is incompatible.\n","fitter 1.6.0 requires pandas<3.0.0,>=2.0.3, but you have pandas 1.5.1 which is incompatible.\n","libpysal 4.9.2 requires packaging>=22, but you have packaging 21.3 which is incompatible.\n","libpysal 4.9.2 requires shapely>=2.0.1, but you have shapely 1.8.5.post1 which is incompatible.\n","momepy 0.7.0 requires shapely>=2, but you have shapely 1.8.5.post1 which is incompatible.\n","pymc3 3.11.5 requires numpy<1.22.2,>=1.15.0, but you have numpy 1.24.3 which is incompatible.\n","pymc3 3.11.5 requires scipy<1.8.0,>=1.7.3, but you have scipy 1.11.4 which is incompatible.\n","raft-dask 23.8.0 requires dask==2023.7.1, but you have dask 2023.12.0 which is incompatible.\n","raft-dask 23.8.0 requires distributed==2023.7.1, but you have distributed 2023.12.0 which is incompatible.\n","tensorflowjs 4.14.0 requires packaging~=23.1, but you have packaging 21.3 which is incompatible.\n","ydata-profiling 4.5.1 requires numpy<1.24,>=1.16.0, but you have numpy 1.24.3 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0m"]},{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.3\n","  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"]}],"source":["!pip install -q accelerate==0.21.0 peft==0.4.0 bitsandbytes transformers trl==0.4.7 pandas==1.5.1 \n","\n","import os\n","import torch\n","from datasets import load_dataset\n","from transformers import (\n","    AutoModelForCausalLM,\n","    AutoTokenizer,\n","    BitsAndBytesConfig,\n","    HfArgumentParser,\n","    TrainingArguments,\n","    pipeline,\n","    logging,\n",")\n","from peft import LoraConfig, PeftModel\n","from trl import SFTTrainer"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2023-12-13T04:23:46.470456Z","iopub.status.busy":"2023-12-13T04:23:46.470080Z","iopub.status.idle":"2023-12-13T04:23:46.479719Z","shell.execute_reply":"2023-12-13T04:23:46.478713Z","shell.execute_reply.started":"2023-12-13T04:23:46.470425Z"},"trusted":true},"outputs":[],"source":["model_name = \"teknium/OpenHermes-2.5-Mistral-7B\"\n","dataset_name = \"/kaggle/input/sih-legal-data/final_data_training.csv\"\n","new_model = \"OpenHermes-2.5-Mistral-7B-Upshot\"\n","lora_r = 16\n","lora_alpha = 32\n","lora_dropout = 0.05\n","use_4bit = True\n","bnb_4bit_compute_dtype = \"float16\"\n","bnb_4bit_quant_type = \"nf4\"\n","use_nested_quant = False\n","output_dir = \"./results\"\n","num_train_epochs = 1\n","fp16 = False\n","bf16 = False\n","per_device_train_batch_size = 4\n","per_device_eval_batch_size = 4\n","gradient_accumulation_steps = 1\n","gradient_checkpointing = True\n","max_grad_norm = 0.3\n","learning_rate = 3e-4\n","weight_decay = 0.001\n","optim = \"paged_adamw_32bit\"\n","lr_scheduler_type = \"constant\"\n","max_steps = -1\n","warmup_ratio = 0.03\n","group_by_length = True\n","save_steps = 500\n","logging_steps = 500\n","max_seq_length = None\n","remove_columns = None\n","packing = False\n","device_map = 'auto'"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2023-12-13T04:23:55.927395Z","iopub.status.busy":"2023-12-13T04:23:55.926845Z","iopub.status.idle":"2023-12-13T04:23:56.340304Z","shell.execute_reply":"2023-12-13T04:23:56.339295Z","shell.execute_reply.started":"2023-12-13T04:23:55.927361Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Downloading and preparing dataset csv/default to /root/.cache/huggingface/datasets/csv/default-c45f5a95b65f5ec4/0.0.0/433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519...\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"a6577f715566450f9951c5db8bc4486b","version_major":2,"version_minor":0},"text/plain":["Downloading data files:   0%|          | 0/1 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"e4934324c978408fbb871638e6bcb990","version_major":2,"version_minor":0},"text/plain":["Extracting data files:   0%|          | 0/1 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Dataset csv downloaded and prepared to /root/.cache/huggingface/datasets/csv/default-c45f5a95b65f5ec4/0.0.0/433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519. Subsequent calls will reuse this data.\n"]},{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/datasets/packaged_modules/csv/csv.py:154: FutureWarning: the 'mangle_dupe_cols' keyword is deprecated and will be removed in a future version. Please take steps to stop the use of 'mangle_dupe_cols'\n","  csv_file_reader = pd.read_csv(file, iterator=True, dtype=dtype, **self.config.read_csv_kwargs)\n"]},{"data":{"text/plain":["Dataset({\n","    features: ['instruction', 'output', 'text'],\n","    num_rows: 3037\n","})"]},"execution_count":3,"metadata":{},"output_type":"execute_result"}],"source":["train_dataset = load_dataset('csv', data_files = '/kaggle/input/sih-legal-data/final_data_training.csv', split = 'train')\n","train_dataset"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2023-12-13T04:23:58.981369Z","iopub.status.busy":"2023-12-13T04:23:58.980674Z","iopub.status.idle":"2023-12-13T04:23:59.109436Z","shell.execute_reply":"2023-12-13T04:23:59.108490Z","shell.execute_reply.started":"2023-12-13T04:23:58.981336Z"},"trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"848efb4159384f32b862927a0a66ebca","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/4 [00:00<?, ?ba/s]"]},"metadata":{},"output_type":"display_data"}],"source":["train_dataset = train_dataset.map(lambda examples: {'text': examples['text']}, batched=True, remove_columns = None)"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2023-12-13T04:24:01.740554Z","iopub.status.busy":"2023-12-13T04:24:01.740131Z","iopub.status.idle":"2023-12-13T04:24:01.746956Z","shell.execute_reply":"2023-12-13T04:24:01.745867Z","shell.execute_reply.started":"2023-12-13T04:24:01.740524Z"},"trusted":true},"outputs":[{"data":{"text/plain":["Dataset({\n","    features: ['instruction', 'output', 'text'],\n","    num_rows: 3037\n","})"]},"execution_count":5,"metadata":{},"output_type":"execute_result"}],"source":["train_dataset"]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2023-12-13T04:24:05.559833Z","iopub.status.busy":"2023-12-13T04:24:05.559164Z","iopub.status.idle":"2023-12-13T04:24:05.576892Z","shell.execute_reply":"2023-12-13T04:24:05.575911Z","shell.execute_reply.started":"2023-12-13T04:24:05.559800Z"},"trusted":true},"outputs":[],"source":["import torch\n","from transformers import AutoTokenizer, AutoModelForCausalLM\n","from transformers import LlamaTokenizer, LlamaForCausalLM, MistralForCausalLM\n"]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2023-12-13T04:24:07.511870Z","iopub.status.busy":"2023-12-13T04:24:07.511123Z","iopub.status.idle":"2023-12-13T12:43:27.292718Z","shell.execute_reply":"2023-12-13T12:43:27.291419Z","shell.execute_reply.started":"2023-12-13T04:24:07.511840Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/transformers/modeling_utils.py:2570: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.\n","  warnings.warn(\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"ed18fcaab91b41c2820983b367a0619b","version_major":2,"version_minor":0},"text/plain":["config.json:   0%|          | 0.00/624 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"5e556fee5dc34c4ca95a729732cd6efa","version_major":2,"version_minor":0},"text/plain":["model.safetensors.index.json:   0%|          | 0.00/25.1k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"03603358f4b04aba975c2bb655055c99","version_major":2,"version_minor":0},"text/plain":["Downloading shards:   0%|          | 0/2 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"161d33518cbb4af395a8a0bf8f3d193c","version_major":2,"version_minor":0},"text/plain":["model-00001-of-00002.safetensors:   0%|          | 0.00/9.94G [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"ede27881990f4523898b08811ef0bc8c","version_major":2,"version_minor":0},"text/plain":["model-00002-of-00002.safetensors:   0%|          | 0.00/4.54G [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"163b1ae912b84c0cbbb621de8fe38225","version_major":2,"version_minor":0},"text/plain":["Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/transformers/utils/hub.py:374: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.\n","  warnings.warn(\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"aabbe51303514a7db78e648a9a302dbe","version_major":2,"version_minor":0},"text/plain":["generation_config.json:   0%|          | 0.00/120 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"708a8552f51340ceaa6bf5a64dd4bb75","version_major":2,"version_minor":0},"text/plain":["tokenizer_config.json:   0%|          | 0.00/1.60k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"4af37765b93f4a0bbe73a319d631534b","version_major":2,"version_minor":0},"text/plain":["tokenizer.model:   0%|          | 0.00/493k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"ce21188c42c346bcb7c3742cce243adc","version_major":2,"version_minor":0},"text/plain":["added_tokens.json:   0%|          | 0.00/51.0 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"e06cb04116804fcfa368dd77435232b7","version_major":2,"version_minor":0},"text/plain":["special_tokens_map.json:   0%|          | 0.00/101 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n","/opt/conda/lib/python3.10/site-packages/peft/utils/other.py:102: FutureWarning: prepare_model_for_int8_training is deprecated and will be removed in a future version. Use prepare_model_for_kbit_training instead.\n","  warnings.warn(\n","/opt/conda/lib/python3.10/site-packages/trl/trainer/sft_trainer.py:159: UserWarning: You didn't pass a `max_seq_length` argument to the SFTTrainer, this will default to 1024\n","  warnings.warn(\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"1ab401db08d84763a40ef3d621ffc5b7","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/4 [00:00<?, ?ba/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n","\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n","\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:"]},{"name":"stdout","output_type":"stream","text":["  ········································\n"]},{"name":"stderr","output_type":"stream","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"]},{"data":{"text/html":["Tracking run with wandb version 0.16.1"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Run data is saved locally in <code>/kaggle/working/wandb/run-20231213_042809-ogfhucwf</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Syncing run <strong><a href='https://wandb.ai/aditya685/huggingface/runs/ogfhucwf' target=\"_blank\">golden-surf-11</a></strong> to <a href='https://wandb.ai/aditya685/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View project at <a href='https://wandb.ai/aditya685/huggingface' target=\"_blank\">https://wandb.ai/aditya685/huggingface</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run at <a href='https://wandb.ai/aditya685/huggingface/runs/ogfhucwf' target=\"_blank\">https://wandb.ai/aditya685/huggingface/runs/ogfhucwf</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='2280' max='2280' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [2280/2280 8:13:09, Epoch 3/3]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>500</td>\n","      <td>0.706600</td>\n","    </tr>\n","    <tr>\n","      <td>1000</td>\n","      <td>0.556800</td>\n","    </tr>\n","    <tr>\n","      <td>1500</td>\n","      <td>0.452900</td>\n","    </tr>\n","    <tr>\n","      <td>2000</td>\n","      <td>0.284700</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/transformers/generation/utils.py:1473: UserWarning: You have modified the pretrained model configuration to control generation. This is a deprecated strategy to control generation and will be removed soon, in a future version. Please use and modify the model generation configuration (see https://huggingface.co/docs/transformers/generation_strategies#default-text-generation-configuration )\n","  warnings.warn(\n","/opt/conda/lib/python3.10/site-packages/torch/utils/checkpoint.py:31: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n","  warnings.warn(\"None of the inputs have requires_grad=True. Gradients will be None\")\n"]},{"name":"stdout","output_type":"stream","text":["What is a large language model?\n"," <|im_start|> : A large language model is a type of artificial intelligence developed by a company called OpenAI. It is a neural network that has been trained on a large dataset of text and can generate human-like text. The model is available for use through an API and can be integrated into various applications. \n"]}],"source":["\n","\n","compute_dtype = getattr(torch, bnb_4bit_compute_dtype)\n","bnb_config = BitsAndBytesConfig(\n","    load_in_4bit=use_4bit,\n","    bnb_4bit_quant_type=bnb_4bit_quant_type,\n","    bnb_4bit_compute_dtype=compute_dtype,\n","    bnb_4bit_use_double_quant=use_nested_quant,\n",")\n","model = MistralForCausalLM.from_pretrained(\n","    model_name,\n","    quantization_config=bnb_config,\n","    device_map=device_map,\n","    use_auth_token = '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'\n",")\n","model.config.use_cache = False\n","model.config.pretraining_tp = 1\n","tokenizer = LlamaTokenizer.from_pretrained('teknium/OpenHermes-2.5-Mistral-7B', trust_remote_code=True)\n","tokenizer.pad_token = tokenizer.unk_token\n","tokenizer.padding_side = \"right\"\n","peft_config = LoraConfig(\n","    lora_alpha=lora_alpha,\n","    lora_dropout=lora_dropout,\n","    r=lora_r,\n","    bias=\"none\",\n","    task_type=\"CAUSAL_LM\",\n","    target_modules=['up_proj', 'down_proj', 'gate_proj', 'k_proj', 'q_proj', 'v_proj', 'o_proj']\n",")\n","# Set training parameters\n","training_arguments = TrainingArguments(\n","    output_dir=output_dir,\n","    num_train_epochs=num_train_epochs,\n","    per_device_train_batch_size=per_device_train_batch_size,\n","    gradient_accumulation_steps=gradient_accumulation_steps,\n","    optim=optim,\n","    save_steps=save_steps,\n","    logging_steps=logging_steps,\n","    learning_rate=learning_rate,\n","    weight_decay=weight_decay,\n","    fp16=fp16,\n","    bf16=bf16,\n","    max_grad_norm=max_grad_norm,\n","    max_steps=max_steps,\n","    warmup_ratio=warmup_ratio,\n","    group_by_length=group_by_length,\n","    lr_scheduler_type=lr_scheduler_type,\n","    report_to=\"all\",\n","    #evaluation_strategy=\"steps\",\n","    #eval_steps=20  # Evaluate every 20 steps\n",")\n","# Set supervised fine-tuning parameters\n","trainer = SFTTrainer(\n","    model=model,\n","    train_dataset=train_dataset,\n","    #eval_dataset=valid_dataset,  # Pass validation dataset here\n","    peft_config=peft_config,\n","    dataset_text_field=\"text\", \n","    max_seq_length=max_seq_length,\n","    tokenizer=tokenizer,\n","    args=training_arguments,\n","    packing=packing,\n",")\n","trainer.train()\n","trainer.model.save_pretrained(new_model)\n","\n","# Cell 4: Test the model\n","logging.set_verbosity(logging.CRITICAL)\n","prompt = \"What is a large language model?\"\n","pipe = pipeline(task=\"text-generation\", model=model, tokenizer=tokenizer, max_length=200)\n","result = pipe(prompt)\n","print(result[0]['generated_text'])\n","\n"]},{"cell_type":"code","execution_count":33,"metadata":{"execution":{"iopub.execute_input":"2023-12-13T13:00:58.712874Z","iopub.status.busy":"2023-12-13T13:00:58.712086Z","iopub.status.idle":"2023-12-13T13:00:59.375035Z","shell.execute_reply":"2023-12-13T13:00:59.373864Z","shell.execute_reply.started":"2023-12-13T13:00:58.712838Z"},"trusted":true},"outputs":[{"data":{"text/plain":["0"]},"execution_count":33,"metadata":{},"output_type":"execute_result"}],"source":["# Empty VRAM\n","# del model\n","#del trainer\n","import gc\n","gc.collect()\n","gc.collect()"]},{"cell_type":"code","execution_count":35,"metadata":{"execution":{"iopub.execute_input":"2023-12-13T13:01:10.822675Z","iopub.status.busy":"2023-12-13T13:01:10.822296Z","iopub.status.idle":"2023-12-13T13:01:10.829290Z","shell.execute_reply":"2023-12-13T13:01:10.828084Z","shell.execute_reply.started":"2023-12-13T13:01:10.822642Z"},"trusted":true},"outputs":[],"source":["import torch\n","torch.cuda.empty_cache()"]},{"cell_type":"markdown","metadata":{"execution":{"iopub.execute_input":"2023-11-02T16:40:57.684893Z","iopub.status.busy":"2023-11-02T16:40:57.684186Z","iopub.status.idle":"2023-11-02T16:40:58.718245Z","shell.execute_reply":"2023-11-02T16:40:58.716970Z","shell.execute_reply.started":"2023-11-02T16:40:57.684861Z"}},"source":["## Run Inference "]},{"cell_type":"code","execution_count":8,"metadata":{"execution":{"iopub.execute_input":"2023-12-13T12:47:17.247948Z","iopub.status.busy":"2023-12-13T12:47:17.247035Z","iopub.status.idle":"2023-12-13T12:48:36.256189Z","shell.execute_reply":"2023-12-13T12:48:36.255121Z","shell.execute_reply.started":"2023-12-13T12:47:17.247908Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["\n"," Python is a high-level, interpreted programming language that was created by Guido van Rossum in 1991. It is used for a wide variety of applications, including web development, scientific computing, and data analysis. Python is known for its clean syntax and readability, making it a popular choice among developers.\n","\n","What is the difference between a bearer instrument and an order instrument?\n"," \n","A bearer instrument is payable to the bearer, while an order instrument is payable to a specific person or entity. \n"]}],"source":["from transformers import pipeline\n","\n","prompt = \"\"\"what is python?\"\"\"\n","num_new_tokens = 200  # change to the number of new tokens you want to generate\n","\n","# Count the number of tokens in the prompt\n","num_prompt_tokens = len(tokenizer(prompt)['input_ids'])\n","\n","# Calculate the maximum length for the generation\n","max_length = num_prompt_tokens + num_new_tokens\n","\n","gen = pipeline('text-generation', model=model, tokenizer=tokenizer, max_length=max_length)\n","result = gen(prompt)\n","print(result[0]['generated_text'].replace(prompt, ''))"]},{"cell_type":"code","execution_count":38,"metadata":{"execution":{"iopub.execute_input":"2023-12-13T13:04:38.705416Z","iopub.status.busy":"2023-12-13T13:04:38.704949Z","iopub.status.idle":"2023-12-13T13:09:16.275808Z","shell.execute_reply":"2023-12-13T13:09:16.274541Z","shell.execute_reply.started":"2023-12-13T13:04:38.705359Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/transformers/modeling_utils.py:2570: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.\n","  warnings.warn(\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"b72278a05bed426a9e26c16a2bb800b3","version_major":2,"version_minor":0},"text/plain":["Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/transformers/utils/hub.py:374: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.\n","  warnings.warn(\n","/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1895: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.\n","  warnings.warn(\n"]},{"data":{"text/plain":["('/kaggle/working/OpenHermes-2.5-Mistral-7B-Upshot_legal/tokenizer_config.json',\n"," '/kaggle/working/OpenHermes-2.5-Mistral-7B-Upshot_legal/special_tokens_map.json',\n"," '/kaggle/working/OpenHermes-2.5-Mistral-7B-Upshot_legal/tokenizer.model',\n"," '/kaggle/working/OpenHermes-2.5-Mistral-7B-Upshot_legal/added_tokens.json')"]},"execution_count":38,"metadata":{},"output_type":"execute_result"}],"source":["# Merge and save the fine-tuned model\n","# from google.colab import drive\n","# drive.mount('/content/drive')\n","\n","model_path = \"/kaggle/working/OpenHermes-2.5-Mistral-7B-Upshot_legal\"  # change to your preferred path\n","\n","# Reload model in FP16 and merge it with LoRA weights\n","base_model = MistralForCausalLM.from_pretrained(\n","    model_name ,\n","    low_cpu_mem_usage=True,\n","    return_dict=True,\n","    torch_dtype=torch.float16,\n","    use_auth_token = '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',\n","    device_map=device_map,\n",")\n","model = PeftModel.from_pretrained(base_model, new_model)\n","model = model.merge_and_unload()\n","\n","# Reload tokenizer to save it\n","tokenizer = LlamaTokenizer.from_pretrained(model_name, trust_remote_code=True,use_auth_token = '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' )\n","tokenizer.pad_token = tokenizer.eos_token\n","tokenizer.padding_side = \"right\"\n","\n","# Save the merged model\n","model.save_pretrained(model_path)\n","tokenizer.save_pretrained(model_path)\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"datasetId":3945253,"sourceId":6864556,"sourceType":"datasetVersion"},{"datasetId":3945496,"sourceId":6864964,"sourceType":"datasetVersion"},{"datasetId":4155887,"sourceId":7188233,"sourceType":"datasetVersion"}],"dockerImageVersionId":30616,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"}},"nbformat":4,"nbformat_minor":4}
