{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "b4538bac146543f49103cfeef567b5c8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7f3aa6fa1f21468ba52f1bc60139ebce",
              "IPY_MODEL_9ce108f35cb149c8aafca408e64a7e63",
              "IPY_MODEL_040bcdbdfd3f4d34a4b65ec02da8d69f"
            ],
            "layout": "IPY_MODEL_301561d4cc6e41dbae667c7331f3dd75"
          }
        },
        "7f3aa6fa1f21468ba52f1bc60139ebce": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8293cad12eb648b7b062770cb2f684d6",
            "placeholder": "​",
            "style": "IPY_MODEL_1f9f630895ba4ebfb2e278a88766ff06",
            "value": "upshot-sih-7b-v2.0.gguf: 100%"
          }
        },
        "9ce108f35cb149c8aafca408e64a7e63": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ff81bdcb6c6b4fecbd9c0a1151f008c3",
            "max": 7695874944,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_693e4217f8d14c81bec27ff600feda01",
            "value": 7695874944
          }
        },
        "040bcdbdfd3f4d34a4b65ec02da8d69f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_27d449c464f049efbfe902567cd44753",
            "placeholder": "​",
            "style": "IPY_MODEL_050a6b5c55884e0a9a563d2dd77f5cc4",
            "value": " 7.70G/7.70G [03:19&lt;00:00, 40.2MB/s]"
          }
        },
        "301561d4cc6e41dbae667c7331f3dd75": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8293cad12eb648b7b062770cb2f684d6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1f9f630895ba4ebfb2e278a88766ff06": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ff81bdcb6c6b4fecbd9c0a1151f008c3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "693e4217f8d14c81bec27ff600feda01": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "27d449c464f049efbfe902567cd44753": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "050a6b5c55884e0a9a563d2dd77f5cc4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install huggingface_hub --q"
      ],
      "metadata": {
        "id": "KaWRIlN7HzKb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile download.py\n",
        "\n",
        "from huggingface_hub import snapshot_download\n",
        "model_id=\"Aditya685/upshot-sih\"\n",
        "snapshot_download(repo_id=model_id, local_dir=\"upshot-sih\",\n",
        "                  local_dir_use_symlinks=False, revision=\"main\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1CyQc61oH0gP",
        "outputId": "dc78e0a9-b588-4c4e-9539-57ab1800fc0c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing download.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python download.py\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0PBRC1xQIP_I",
        "outputId": "0e0a40c9-3448-4945-820c-3398ed89eade"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fetching 11 files:   0% 0/11 [00:00<?, ?it/s]\n",
            "config.json: 100% 654/654 [00:00<00:00, 3.54MB/s]\n",
            "\n",
            "added_tokens.json: 100% 51.0/51.0 [00:00<00:00, 286kB/s]\n",
            "\n",
            "model.safetensors.index.json: 100% 23.9k/23.9k [00:00<00:00, 61.0MB/s]\n",
            "\n",
            "generation_config.json: 100% 115/115 [00:00<00:00, 691kB/s]\n",
            "\n",
            "special_tokens_map.json: 100% 449/449 [00:00<00:00, 2.19MB/s]\n",
            "\n",
            ".gitattributes: 100% 1.52k/1.52k [00:00<00:00, 8.47MB/s]\n",
            "Fetching 11 files:   9% 1/11 [00:00<00:09,  1.03it/s]\n",
            "tokenizer_config.json: 100% 1.60k/1.60k [00:00<00:00, 7.05MB/s]\n",
            "\n",
            "model-00002-of-00003.safetensors:   0% 0.00/5.00G [00:00<?, ?B/s]\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:   0% 0.00/4.54G [00:00<?, ?B/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00003.safetensors:   0% 0.00/4.94G [00:00<?, ?B/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "tokenizer.model: 100% 493k/493k [00:00<00:00, 10.5MB/s]\n",
            "\n",
            "model-00002-of-00003.safetensors:   0% 10.5M/5.00G [00:00<01:48, 46.0MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00003.safetensors:   0% 10.5M/4.94G [00:00<01:13, 66.9MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00003.safetensors:   0% 21.0M/4.94G [00:00<01:00, 81.2MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00002-of-00003.safetensors:   0% 21.0M/5.00G [00:00<02:07, 39.1MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00003.safetensors:   1% 31.5M/4.94G [00:00<00:56, 86.5MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:   0% 10.5M/4.54G [00:00<03:22, 22.4MB/s]\u001b[A\u001b[A\n",
            "model-00002-of-00003.safetensors:   1% 31.5M/5.00G [00:00<01:38, 50.5MB/s]\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:   0% 21.0M/4.54G [00:00<01:54, 39.5MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00003.safetensors:   1% 41.9M/4.94G [00:00<01:12, 67.4MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00002-of-00003.safetensors:   1% 41.9M/5.00G [00:00<01:29, 55.3MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00003.safetensors:   1% 52.4M/4.94G [00:00<01:07, 72.1MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:   1% 31.5M/4.54G [00:00<01:36, 46.9MB/s]\u001b[A\u001b[A\n",
            "model-00002-of-00003.safetensors:   1% 52.4M/5.00G [00:00<01:20, 61.1MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00003.safetensors:   1% 62.9M/4.94G [00:00<01:04, 76.0MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:   1% 41.9M/4.54G [00:00<01:20, 55.7MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00003.safetensors:   1% 73.4M/4.94G [00:00<01:05, 74.6MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:   1% 52.4M/4.54G [00:01<01:19, 56.5MB/s]\u001b[A\u001b[A\n",
            "model-00002-of-00003.safetensors:   1% 62.9M/5.00G [00:01<01:52, 44.0MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00003.safetensors:   2% 83.9M/4.94G [00:01<01:15, 64.2MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:   1% 62.9M/4.54G [00:01<01:18, 57.1MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00003.safetensors:   2% 94.4M/4.94G [00:01<01:10, 68.3MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:   2% 73.4M/4.54G [00:01<01:12, 61.3MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00003.safetensors:   2% 105M/4.94G [00:01<01:06, 72.6MB/s] \u001b[A\u001b[A\u001b[A\n",
            "model-00002-of-00003.safetensors:   1% 73.4M/5.00G [00:01<02:04, 39.6MB/s]\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:   2% 83.9M/4.54G [00:01<01:14, 60.2MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00003.safetensors:   2% 115M/4.94G [00:01<01:06, 72.3MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00002-of-00003.safetensors:   2% 83.9M/5.00G [00:01<01:49, 44.8MB/s]\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:   2% 94.4M/4.54G [00:01<01:08, 65.2MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00003.safetensors:   3% 126M/4.94G [00:01<01:03, 75.4MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:   2% 105M/4.54G [00:01<01:10, 63.3MB/s] \u001b[A\u001b[A\n",
            "model-00002-of-00003.safetensors:   2% 94.4M/5.00G [00:02<01:49, 44.8MB/s]\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:   3% 115M/4.54G [00:02<01:18, 56.2MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00003.safetensors:   3% 136M/4.94G [00:02<01:37, 49.2MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00002-of-00003.safetensors:   2% 105M/5.00G [00:02<01:49, 44.6MB/s] \u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:   3% 126M/4.54G [00:02<01:16, 57.3MB/s]\u001b[A\u001b[A\n",
            "model-00002-of-00003.safetensors:   2% 115M/5.00G [00:02<01:48, 45.1MB/s]\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:   3% 136M/4.54G [00:02<01:11, 61.9MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00003.safetensors:   3% 147M/4.94G [00:02<02:14, 35.7MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:   3% 147M/4.54G [00:02<01:15, 58.4MB/s]\u001b[A\u001b[A\n",
            "model-00002-of-00003.safetensors:   3% 126M/5.00G [00:02<01:59, 40.8MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00003.safetensors:   3% 157M/4.94G [00:02<01:58, 40.5MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:   3% 157M/4.54G [00:02<01:12, 60.6MB/s]\u001b[A\u001b[A\n",
            "model-00002-of-00003.safetensors:   3% 136M/5.00G [00:03<01:51, 43.7MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00003.safetensors:   3% 168M/4.94G [00:02<01:43, 46.2MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:   4% 168M/4.54G [00:02<01:10, 62.1MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:   4% 178M/4.54G [00:03<01:11, 61.4MB/s]\u001b[A\u001b[A\n",
            "model-00002-of-00003.safetensors:   3% 147M/5.00G [00:03<01:53, 42.9MB/s]\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:   4% 189M/4.54G [00:03<01:06, 65.6MB/s]\u001b[A\u001b[A\n",
            "model-00002-of-00003.safetensors:   3% 157M/5.00G [00:03<01:36, 50.2MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00003.safetensors:   4% 178M/4.94G [00:03<02:02, 38.9MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00003.safetensors:   4% 189M/4.94G [00:03<01:42, 46.6MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00002-of-00003.safetensors:   3% 168M/5.00G [00:03<01:30, 53.6MB/s]\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:   4% 199M/4.54G [00:03<01:16, 56.7MB/s]\u001b[A\u001b[A\n",
            "model-00002-of-00003.safetensors:   4% 178M/5.00G [00:03<01:43, 46.8MB/s]\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:   5% 210M/4.54G [00:03<01:24, 51.3MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00003.safetensors:   4% 199M/4.94G [00:03<02:08, 37.0MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00002-of-00003.safetensors:   4% 189M/5.00G [00:03<01:29, 54.0MB/s]\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:   5% 220M/4.54G [00:03<01:15, 57.5MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00003.safetensors:   4% 210M/4.94G [00:03<01:52, 42.1MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00002-of-00003.safetensors:   4% 199M/5.00G [00:04<01:28, 54.5MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:   4% 210M/5.00G [00:04<01:25, 56.3MB/s]\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:   5% 231M/4.54G [00:04<01:37, 44.4MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00003.safetensors:   4% 220M/4.94G [00:04<01:51, 42.3MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00002-of-00003.safetensors:   4% 220M/5.00G [00:04<01:17, 62.0MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:   5% 231M/5.00G [00:04<01:15, 63.3MB/s]\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:   5% 241M/4.54G [00:04<01:44, 40.9MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00003.safetensors:   5% 231M/4.94G [00:04<02:19, 33.8MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00002-of-00003.safetensors:   5% 241M/5.00G [00:04<01:23, 56.9MB/s]\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:   6% 252M/4.54G [00:04<01:36, 44.3MB/s]\u001b[A\u001b[A\n",
            "model-00002-of-00003.safetensors:   5% 252M/5.00G [00:04<01:15, 62.8MB/s]\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:   6% 262M/4.54G [00:04<01:32, 46.1MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00003.safetensors:   5% 241M/4.94G [00:04<02:09, 36.2MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00002-of-00003.safetensors:   5% 262M/5.00G [00:05<01:17, 60.9MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00003.safetensors:   5% 252M/4.94G [00:05<01:46, 44.0MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:   6% 273M/4.54G [00:05<01:40, 42.4MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00003.safetensors:   5% 262M/4.94G [00:06<03:34, 21.8MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00003.safetensors:   6% 283M/4.94G [00:06<02:09, 35.9MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00002-of-00003.safetensors:   5% 273M/5.00G [00:06<03:41, 21.4MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00003.safetensors:   6% 304M/4.94G [00:06<01:31, 50.5MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:   6% 283M/4.54G [00:06<03:39, 19.4MB/s]\u001b[A\u001b[A\n",
            "model-00002-of-00003.safetensors:   6% 283M/5.00G [00:06<03:04, 25.5MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00003.safetensors:   7% 325M/4.94G [00:06<01:12, 64.1MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00002-of-00003.safetensors:   6% 294M/5.00G [00:06<02:29, 31.5MB/s]\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:   6% 294M/4.54G [00:06<02:58, 23.7MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00003.safetensors:   7% 346M/4.94G [00:06<00:58, 78.6MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00002-of-00003.safetensors:   6% 304M/5.00G [00:06<02:01, 38.6MB/s]\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:   7% 304M/4.54G [00:06<02:20, 30.1MB/s]\u001b[A\u001b[A\n",
            "model-00002-of-00003.safetensors:   6% 315M/5.00G [00:07<01:39, 46.9MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00003.safetensors:   7% 367M/4.94G [00:06<00:51, 89.1MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:   7% 325M/4.54G [00:06<01:32, 45.8MB/s]\u001b[A\u001b[A\n",
            "model-00002-of-00003.safetensors:   7% 325M/5.00G [00:07<01:23, 55.9MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00003.safetensors:   8% 388M/4.94G [00:07<01:03, 71.6MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00002-of-00003.safetensors:   7% 336M/5.00G [00:07<01:46, 43.9MB/s]\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:   7% 336M/4.54G [00:07<01:47, 39.1MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00003.safetensors:   8% 398M/4.94G [00:07<01:02, 73.2MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00002-of-00003.safetensors:   7% 346M/5.00G [00:07<01:35, 48.8MB/s]\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:   8% 346M/4.54G [00:07<01:36, 43.6MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00003.safetensors:   8% 409M/4.94G [00:07<01:04, 70.1MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00002-of-00003.safetensors:   7% 357M/5.00G [00:07<01:35, 48.7MB/s]\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:   8% 357M/4.54G [00:07<01:35, 43.8MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00003.safetensors:   8% 419M/4.94G [00:07<01:14, 60.8MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00002-of-00003.safetensors:   7% 367M/5.00G [00:09<05:00, 15.4MB/s]\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:   8% 367M/4.54G [00:10<05:19, 13.1MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00003.safetensors:   9% 430M/4.94G [00:11<06:45, 11.1MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:   8% 377M/4.54G [00:11<05:58, 11.6MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:   9% 388M/4.54G [00:11<04:27, 15.5MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00003.safetensors:   9% 451M/4.94G [00:11<04:13, 17.7MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00002-of-00003.safetensors:   8% 377M/5.00G [00:11<07:41, 10.0MB/s]\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:   9% 398M/4.54G [00:11<03:27, 19.9MB/s]\u001b[A\u001b[A\n",
            "model-00002-of-00003.safetensors:   8% 398M/5.00G [00:11<04:23, 17.4MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00003.safetensors:   9% 461M/4.94G [00:11<03:36, 20.7MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:   9% 409M/4.54G [00:11<02:52, 24.0MB/s]\u001b[A\u001b[A\n",
            "model-00002-of-00003.safetensors:   8% 409M/5.00G [00:11<03:40, 20.9MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00003.safetensors:  10% 472M/4.94G [00:11<03:04, 24.2MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:   9% 419M/4.54G [00:11<02:26, 28.1MB/s]\u001b[A\u001b[A\n",
            "model-00002-of-00003.safetensors:   8% 419M/5.00G [00:12<02:59, 25.5MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00003.safetensors:  10% 482M/4.94G [00:11<02:32, 29.3MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00002-of-00003.safetensors:   9% 430M/5.00G [00:12<02:25, 31.3MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00003.safetensors:  10% 493M/4.94G [00:12<02:08, 34.6MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  10% 440M/4.54G [00:12<01:41, 40.4MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00003.safetensors:  10% 503M/4.94G [00:12<01:54, 38.9MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00002-of-00003.safetensors:   9% 440M/5.00G [00:12<02:14, 34.0MB/s]\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  10% 451M/4.54G [00:12<01:35, 42.7MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00003.safetensors:  10% 514M/4.94G [00:12<01:38, 44.9MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00002-of-00003.safetensors:   9% 451M/5.00G [00:12<01:51, 40.7MB/s]\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  10% 461M/4.54G [00:12<01:31, 44.7MB/s]\u001b[A\u001b[A\n",
            "model-00002-of-00003.safetensors:   9% 461M/5.00G [00:15<08:05, 9.35MB/s]\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  10% 472M/4.54G [00:15<06:36, 10.3MB/s]\u001b[A\u001b[A\n",
            "model-00002-of-00003.safetensors:  10% 482M/5.00G [00:15<04:44, 15.9MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00003.safetensors:  11% 524M/4.94G [00:15<08:16, 8.89MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  11% 493M/4.54G [00:15<04:03, 16.6MB/s]\u001b[A\u001b[A\n",
            "model-00002-of-00003.safetensors:  10% 493M/5.00G [00:16<03:58, 18.9MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00003.safetensors:  11% 545M/4.94G [00:16<04:51, 15.1MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  11% 503M/4.54G [00:16<03:31, 19.1MB/s]\u001b[A\u001b[A\n",
            "model-00002-of-00003.safetensors:  10% 503M/5.00G [00:16<03:20, 22.4MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00003.safetensors:  11% 556M/4.94G [00:16<03:58, 18.4MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  11% 514M/4.54G [00:16<02:53, 23.1MB/s]\u001b[A\u001b[A\n",
            "model-00002-of-00003.safetensors:  10% 514M/5.00G [00:16<02:39, 28.1MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00003.safetensors:  12% 577M/4.94G [00:16<02:39, 27.4MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00002-of-00003.safetensors:  10% 524M/5.00G [00:16<02:09, 34.5MB/s]\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  12% 524M/4.54G [00:16<02:24, 27.7MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00003.safetensors:  12% 587M/4.94G [00:16<02:14, 32.4MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00002-of-00003.safetensors:  11% 535M/5.00G [00:16<01:46, 41.8MB/s]\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  12% 535M/4.54G [00:16<02:11, 30.5MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00003.safetensors:  12% 598M/4.94G [00:16<02:00, 36.0MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00002-of-00003.safetensors:  11% 545M/5.00G [00:17<01:40, 44.3MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00003.safetensors:  13% 619M/4.94G [00:20<06:35, 10.9MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00002-of-00003.safetensors:  11% 566M/5.00G [00:20<07:01, 10.5MB/s]\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  12% 556M/4.54G [00:20<06:50, 9.70MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00003.safetensors:  13% 629M/4.94G [00:20<05:26, 13.2MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00002-of-00003.safetensors:  12% 577M/5.00G [00:21<05:40, 13.0MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00003.safetensors:  13% 640M/4.94G [00:21<04:26, 16.2MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00002-of-00003.safetensors:  12% 587M/5.00G [00:21<04:32, 16.2MB/s]\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  13% 577M/4.54G [00:21<04:29, 14.7MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00003.safetensors:  13% 661M/4.94G [00:21<02:49, 25.3MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00002-of-00003.safetensors:  12% 598M/5.00G [00:21<03:42, 19.8MB/s]\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  13% 587M/4.54G [00:21<03:51, 17.1MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00003.safetensors:  14% 682M/4.94G [00:21<01:54, 37.2MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00002-of-00003.safetensors:  12% 608M/5.00G [00:21<03:02, 24.0MB/s]\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  13% 608M/4.54G [00:21<02:35, 25.2MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  14% 629M/4.54G [00:21<01:54, 34.2MB/s]\u001b[A\u001b[A\n",
            "model-00002-of-00003.safetensors:  12% 619M/5.00G [00:21<02:41, 27.1MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00003.safetensors:  14% 703M/4.94G [00:21<01:43, 40.9MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  14% 640M/4.54G [00:21<01:42, 38.1MB/s]\u001b[A\u001b[A\n",
            "model-00002-of-00003.safetensors:  13% 629M/5.00G [00:22<02:13, 32.7MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00003.safetensors:  14% 713M/4.94G [00:21<01:34, 44.6MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00002-of-00003.safetensors:  13% 640M/5.00G [00:22<01:47, 40.6MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00003.safetensors:  15% 724M/4.94G [00:22<01:23, 50.7MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  14% 650M/4.54G [00:22<01:32, 42.0MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00003.safetensors:  15% 744M/4.94G [00:22<01:03, 65.7MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00002-of-00003.safetensors:  13% 661M/5.00G [00:22<01:16, 57.0MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00003.safetensors:  15% 765M/4.94G [00:22<00:51, 81.3MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  15% 661M/4.54G [00:22<01:43, 37.3MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00003.safetensors:  16% 786M/4.94G [00:22<00:41, 99.9MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00002-of-00003.safetensors:  13% 671M/5.00G [00:22<01:26, 50.1MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00003.safetensors:  16% 807M/4.94G [00:22<00:38, 106MB/s] \u001b[A\u001b[A\u001b[A\n",
            "model-00002-of-00003.safetensors:  14% 692M/5.00G [00:22<01:03, 67.5MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  14% 713M/5.00G [00:22<00:51, 83.1MB/s]\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  15% 671M/4.54G [00:22<01:59, 32.5MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00003.safetensors:  17% 828M/4.94G [00:22<00:43, 94.3MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00002-of-00003.safetensors:  15% 734M/5.00G [00:23<00:43, 98.4MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  15% 755M/5.00G [00:23<00:37, 112MB/s] \u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00003.safetensors:  17% 849M/4.94G [00:23<00:46, 87.3MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00002-of-00003.safetensors:  16% 776M/5.00G [00:23<00:33, 125MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00003.safetensors:  17% 860M/4.94G [00:23<00:47, 86.2MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00002-of-00003.safetensors:  16% 797M/5.00G [00:23<00:36, 114MB/s]\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  15% 682M/4.54G [00:23<02:22, 27.2MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00003.safetensors:  18% 870M/4.94G [00:23<00:48, 84.8MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00003.safetensors:  18% 881M/4.94G [00:23<00:48, 83.8MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00002-of-00003.safetensors:  16% 818M/5.00G [00:23<00:41, 102MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00003.safetensors:  18% 891M/4.94G [00:23<00:49, 81.3MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00002-of-00003.safetensors:  17% 839M/5.00G [00:24<00:43, 95.2MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00003.safetensors:  18% 902M/4.94G [00:23<01:00, 66.7MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  15% 692M/4.54G [00:24<02:46, 23.1MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00003.safetensors:  18% 912M/4.94G [00:24<00:58, 68.5MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00002-of-00003.safetensors:  17% 849M/5.00G [00:24<00:52, 79.1MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00003.safetensors:  19% 923M/4.94G [00:24<00:56, 71.6MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00003.safetensors:  19% 933M/4.94G [00:24<00:53, 74.7MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00002-of-00003.safetensors:  17% 870M/5.00G [00:24<00:52, 79.4MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00003.safetensors:  19% 944M/4.94G [00:24<00:53, 74.8MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00002-of-00003.safetensors:  18% 891M/5.00G [00:24<00:45, 90.0MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00003.safetensors:  19% 954M/4.94G [00:24<01:01, 64.7MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  15% 703M/4.54G [00:24<03:10, 20.2MB/s]\u001b[A\u001b[A\n",
            "model-00002-of-00003.safetensors:  18% 902M/5.00G [00:24<00:50, 80.9MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00003.safetensors:  20% 965M/4.94G [00:24<01:01, 64.5MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00003.safetensors:  20% 975M/4.94G [00:25<01:02, 64.0MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00002-of-00003.safetensors:  18% 912M/5.00G [00:25<01:04, 63.4MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00003.safetensors:  20% 986M/4.94G [00:25<00:59, 66.6MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00002-of-00003.safetensors:  18% 923M/5.00G [00:25<01:00, 67.1MB/s]\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  16% 713M/4.54G [00:25<03:26, 18.5MB/s]\u001b[A\u001b[A\n",
            "model-00002-of-00003.safetensors:  19% 933M/5.00G [00:25<01:28, 45.9MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00003.safetensors:  20% 996M/4.94G [00:25<01:50, 35.8MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00002-of-00003.safetensors:  19% 954M/5.00G [00:26<01:14, 54.2MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00003.safetensors:  20% 1.01G/4.94G [00:26<01:43, 37.9MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  16% 724M/4.54G [00:26<03:33, 17.9MB/s]\u001b[A\u001b[A\n",
            "model-00002-of-00003.safetensors:  20% 975M/5.00G [00:26<00:59, 67.9MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00003.safetensors:  21% 1.02G/4.94G [00:26<01:26, 45.2MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00003.safetensors:  21% 1.03G/4.94G [00:26<01:13, 53.1MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00003.safetensors:  21% 1.05G/4.94G [00:26<00:49, 78.9MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00002-of-00003.safetensors:  20% 996M/5.00G [00:26<00:58, 68.6MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00003.safetensors:  22% 1.07G/4.94G [00:26<00:40, 96.5MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00002-of-00003.safetensors:  20% 1.01G/5.00G [00:26<00:56, 70.8MB/s]\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  16% 734M/4.54G [00:26<03:33, 17.8MB/s]\u001b[A\u001b[A\n",
            "model-00002-of-00003.safetensors:  20% 1.02G/5.00G [00:26<00:56, 70.4MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  21% 1.03G/5.00G [00:27<00:59, 67.0MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00003.safetensors:  22% 1.09G/4.94G [00:26<00:51, 75.1MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00002-of-00003.safetensors:  21% 1.04G/5.00G [00:27<00:57, 69.3MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00003.safetensors:  22% 1.10G/4.94G [00:27<00:50, 76.5MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00002-of-00003.safetensors:  21% 1.05G/5.00G [00:27<01:03, 62.7MB/s]\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  16% 744M/4.54G [00:27<03:33, 17.8MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00003.safetensors:  22% 1.11G/4.94G [00:27<01:01, 61.9MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00002-of-00003.safetensors:  21% 1.06G/5.00G [00:27<01:07, 58.5MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  21% 1.07G/5.00G [00:27<01:01, 63.9MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00003.safetensors:  23% 1.12G/4.94G [00:27<01:09, 55.2MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00003.safetensors:  23% 1.13G/4.94G [00:27<01:03, 60.3MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  17% 755M/4.54G [00:27<03:33, 17.7MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00003.safetensors:  23% 1.14G/4.94G [00:27<01:07, 56.5MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00002-of-00003.safetensors:  22% 1.08G/5.00G [00:28<01:51, 35.3MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00003.safetensors:  23% 1.15G/4.94G [00:28<01:29, 42.6MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  17% 765M/4.54G [00:28<03:28, 18.1MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00003.safetensors:  24% 1.16G/4.94G [00:28<01:18, 48.3MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00002-of-00003.safetensors:  22% 1.09G/5.00G [00:28<01:52, 34.8MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  22% 1.10G/5.00G [00:28<01:35, 40.8MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00003.safetensors:  24% 1.17G/4.94G [00:28<01:20, 46.6MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00002-of-00003.safetensors:  22% 1.11G/5.00G [00:29<01:32, 42.0MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00003.safetensors:  24% 1.18G/4.94G [00:28<01:22, 45.4MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  17% 776M/4.54G [00:29<03:36, 17.4MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00003.safetensors:  24% 1.20G/4.94G [00:29<01:12, 51.9MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00002-of-00003.safetensors:  22% 1.12G/5.00G [00:29<01:34, 40.9MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00003.safetensors:  24% 1.21G/4.94G [00:29<01:05, 57.1MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00002-of-00003.safetensors:  23% 1.13G/5.00G [00:29<01:35, 40.5MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00003.safetensors:  25% 1.22G/4.94G [00:29<01:13, 50.6MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00002-of-00003.safetensors:  23% 1.14G/5.00G [00:29<01:27, 44.0MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00003.safetensors:  25% 1.23G/4.94G [00:29<01:04, 57.4MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00003.safetensors:  25% 1.24G/4.94G [00:29<01:01, 60.1MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  17% 786M/4.54G [00:29<03:54, 16.0MB/s]\u001b[A\u001b[A\n",
            "model-00002-of-00003.safetensors:  23% 1.15G/5.00G [00:30<01:29, 43.0MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00003.safetensors:  25% 1.25G/4.94G [00:29<00:56, 65.9MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00002-of-00003.safetensors:  23% 1.16G/5.00G [00:30<01:16, 50.4MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00003.safetensors:  25% 1.26G/4.94G [00:30<00:54, 67.3MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00003.safetensors:  26% 1.27G/4.94G [00:30<00:50, 72.5MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00002-of-00003.safetensors:  23% 1.17G/5.00G [00:30<01:16, 50.3MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00003.safetensors:  26% 1.28G/4.94G [00:30<00:49, 73.9MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00002-of-00003.safetensors:  24% 1.18G/5.00G [00:30<01:10, 53.8MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00003.safetensors:  26% 1.29G/4.94G [00:30<00:47, 76.3MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00002-of-00003.safetensors:  24% 1.20G/5.00G [00:30<01:07, 56.7MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00003.safetensors:  26% 1.30G/4.94G [00:30<00:47, 76.8MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  18% 797M/4.54G [00:30<04:12, 14.8MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00003.safetensors:  27% 1.31G/4.94G [00:30<00:46, 78.6MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00003.safetensors:  27% 1.32G/4.94G [00:30<00:45, 79.9MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00002-of-00003.safetensors:  24% 1.21G/5.00G [00:31<01:21, 46.8MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00003.safetensors:  27% 1.33G/4.94G [00:30<00:44, 80.7MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00003.safetensors:  27% 1.34G/4.94G [00:31<00:44, 81.1MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00002-of-00003.safetensors:  24% 1.22G/5.00G [00:31<01:35, 39.7MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  25% 1.23G/5.00G [00:31<01:20, 47.1MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00003.safetensors:  27% 1.35G/4.94G [00:31<01:17, 46.4MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00002-of-00003.safetensors:  25% 1.24G/5.00G [00:31<01:20, 46.9MB/s]\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  18% 807M/4.54G [00:31<04:33, 13.7MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00003.safetensors:  28% 1.36G/4.94G [00:31<01:07, 53.4MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00002-of-00003.safetensors:  25% 1.25G/5.00G [00:31<01:13, 50.9MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00003.safetensors:  28% 1.37G/4.94G [00:31<00:59, 60.1MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00002-of-00003.safetensors:  25% 1.26G/5.00G [00:32<01:13, 50.8MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00003.safetensors:  28% 1.38G/4.94G [00:31<00:56, 62.6MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00002-of-00003.safetensors:  25% 1.27G/5.00G [00:32<01:06, 55.8MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00003.safetensors:  28% 1.39G/4.94G [00:32<01:06, 53.7MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00002-of-00003.safetensors:  26% 1.28G/5.00G [00:32<01:08, 54.3MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00003.safetensors:  28% 1.41G/4.94G [00:32<01:14, 47.8MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00003.safetensors:  29% 1.42G/4.94G [00:32<01:07, 52.0MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  18% 818M/4.54G [00:32<05:10, 12.0MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00003.safetensors:  29% 1.43G/4.94G [00:32<01:04, 54.5MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00002-of-00003.safetensors:  26% 1.29G/5.00G [00:33<01:51, 33.2MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00003.safetensors:  29% 1.44G/4.94G [00:32<00:58, 60.2MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00003.safetensors:  29% 1.45G/4.94G [00:33<01:02, 55.7MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00002-of-00003.safetensors:  26% 1.30G/5.00G [00:33<02:15, 27.3MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  26% 1.31G/5.00G [00:33<01:47, 34.3MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00003.safetensors:  29% 1.46G/4.94G [00:33<01:29, 39.0MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00002-of-00003.safetensors:  26% 1.32G/5.00G [00:33<01:33, 39.3MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00003.safetensors:  30% 1.47G/4.94G [00:33<01:15, 46.0MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  18% 828M/4.54G [00:33<05:45, 10.8MB/s]\u001b[A\u001b[A\n",
            "model-00002-of-00003.safetensors:  27% 1.33G/5.00G [00:34<01:37, 37.8MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00003.safetensors:  30% 1.48G/4.94G [00:34<01:24, 40.8MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00002-of-00003.safetensors:  27% 1.34G/5.00G [00:34<01:20, 45.4MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00003.safetensors:  30% 1.49G/4.94G [00:34<01:12, 47.9MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00002-of-00003.safetensors:  27% 1.35G/5.00G [00:34<01:09, 52.5MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00003.safetensors:  30% 1.50G/4.94G [00:34<01:02, 55.1MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00002-of-00003.safetensors:  27% 1.36G/5.00G [00:34<01:08, 53.2MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  27% 1.37G/5.00G [00:34<01:01, 59.1MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00003.safetensors:  31% 1.51G/4.94G [00:34<01:12, 47.6MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00003.safetensors:  31% 1.52G/4.94G [00:34<01:02, 54.7MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00002-of-00003.safetensors:  28% 1.38G/5.00G [00:34<00:59, 60.9MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00003.safetensors:  31% 1.53G/4.94G [00:34<00:55, 61.0MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  18% 839M/4.54G [00:35<06:12, 9.94MB/s]\u001b[A\u001b[A\n",
            "model-00002-of-00003.safetensors:  28% 1.39G/5.00G [00:35<02:12, 27.2MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00003.safetensors:  31% 1.54G/4.94G [00:35<01:57, 29.0MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00002-of-00003.safetensors:  28% 1.41G/5.00G [00:35<01:45, 34.1MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00003.safetensors:  31% 1.55G/4.94G [00:35<01:35, 35.6MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00002-of-00003.safetensors:  28% 1.42G/5.00G [00:36<01:25, 41.8MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00003.safetensors:  32% 1.56G/4.94G [00:35<01:19, 42.4MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00002-of-00003.safetensors:  29% 1.43G/5.00G [00:36<01:16, 46.7MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00003.safetensors:  32% 1.57G/4.94G [00:36<01:10, 47.7MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00002-of-00003.safetensors:  29% 1.44G/5.00G [00:36<01:06, 53.4MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00003.safetensors:  32% 1.58G/4.94G [00:36<00:59, 56.4MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00002-of-00003.safetensors:  29% 1.46G/5.00G [00:36<00:49, 71.8MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  30% 1.48G/5.00G [00:36<00:37, 94.5MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00003.safetensors:  32% 1.59G/4.94G [00:36<01:28, 38.0MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00002-of-00003.safetensors:  30% 1.50G/5.00G [00:36<00:39, 89.6MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00003.safetensors:  32% 1.60G/4.94G [00:36<01:20, 41.5MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00003.safetensors:  33% 1.61G/4.94G [00:37<01:08, 48.8MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  19% 849M/4.54G [00:37<07:43, 7.96MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00003.safetensors:  33% 1.63G/4.94G [00:37<01:06, 49.9MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00003.safetensors:  33% 1.65G/4.94G [00:37<00:51, 63.8MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00002-of-00003.safetensors:  30% 1.52G/5.00G [00:37<01:13, 47.4MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00003.safetensors:  34% 1.66G/4.94G [00:37<00:51, 64.4MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00002-of-00003.safetensors:  31% 1.53G/5.00G [00:37<01:06, 51.9MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00003.safetensors:  34% 1.67G/4.94G [00:37<00:47, 68.5MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00003.safetensors:  34% 1.68G/4.94G [00:37<00:45, 72.1MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00002-of-00003.safetensors:  31% 1.54G/5.00G [00:38<01:10, 48.7MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00003.safetensors:  34% 1.69G/4.94G [00:38<00:51, 63.1MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00002-of-00003.safetensors:  31% 1.55G/5.00G [00:38<01:04, 53.8MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  31% 1.56G/5.00G [00:38<00:57, 59.4MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00003.safetensors:  34% 1.70G/4.94G [00:38<00:57, 56.8MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00002-of-00003.safetensors:  31% 1.57G/5.00G [00:38<00:53, 64.1MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00003.safetensors:  35% 1.71G/4.94G [00:38<00:51, 63.0MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00002-of-00003.safetensors:  32% 1.58G/5.00G [00:38<00:50, 68.2MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00003.safetensors:  35% 1.72G/4.94G [00:38<01:02, 51.9MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00003.safetensors:  35% 1.73G/4.94G [00:38<01:01, 52.4MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00002-of-00003.safetensors:  32% 1.59G/5.00G [00:39<01:19, 42.8MB/s]\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  19% 860M/4.54G [00:39<08:44, 7.02MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00003.safetensors:  35% 1.74G/4.94G [00:39<00:54, 58.5MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00002-of-00003.safetensors:  32% 1.60G/5.00G [00:40<03:17, 17.2MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  32% 1.61G/5.00G [00:40<02:49, 19.9MB/s]\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  19% 870M/4.54G [00:40<09:22, 6.53MB/s]\u001b[A\u001b[A\n",
            "model-00002-of-00003.safetensors:  33% 1.64G/5.00G [00:41<01:41, 33.1MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00003.safetensors:  35% 1.75G/4.94G [00:40<03:32, 15.0MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00002-of-00003.safetensors:  33% 1.66G/5.00G [00:41<01:08, 49.2MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00003.safetensors:  36% 1.76G/4.94G [00:41<02:42, 19.5MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00002-of-00003.safetensors:  34% 1.68G/5.00G [00:41<00:49, 67.7MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00003.safetensors:  36% 1.78G/4.94G [00:41<01:38, 32.0MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00002-of-00003.safetensors:  34% 1.70G/5.00G [00:41<00:43, 76.5MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00003.safetensors:  36% 1.80G/4.94G [00:41<01:06, 47.3MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00003.safetensors:  37% 1.82G/4.94G [00:41<00:52, 59.4MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00002-of-00003.safetensors:  34% 1.72G/5.00G [00:41<00:49, 66.4MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00003.safetensors:  37% 1.85G/4.94G [00:41<00:47, 64.9MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00002-of-00003.safetensors:  35% 1.74G/5.00G [00:42<00:52, 61.9MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00003.safetensors:  38% 1.86G/4.94G [00:42<00:55, 55.7MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00002-of-00003.safetensors:  35% 1.75G/5.00G [00:42<00:50, 64.2MB/s]\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  19% 881M/4.54G [00:42<09:38, 6.32MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00003.safetensors:  38% 1.87G/4.94G [00:45<04:27, 11.5MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00002-of-00003.safetensors:  35% 1.76G/5.00G [00:45<04:20, 12.4MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00003.safetensors:  38% 1.89G/4.94G [00:45<02:54, 17.5MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00002-of-00003.safetensors:  36% 1.78G/5.00G [00:46<02:53, 18.5MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00003.safetensors:  38% 1.90G/4.94G [00:46<02:30, 20.3MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00002-of-00003.safetensors:  36% 1.79G/5.00G [00:46<02:31, 21.2MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00003.safetensors:  39% 1.92G/4.94G [00:46<01:41, 29.8MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00002-of-00003.safetensors:  36% 1.80G/5.00G [00:46<02:06, 25.3MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  36% 1.81G/5.00G [00:46<01:44, 30.5MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00003.safetensors:  39% 1.94G/4.94G [00:46<01:13, 41.1MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  20% 891M/4.54G [00:46<13:21, 4.55MB/s]\u001b[A\u001b[A\n",
            "model-00002-of-00003.safetensors:  37% 1.84G/5.00G [00:46<01:08, 46.3MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00003.safetensors:  40% 1.96G/4.94G [00:46<00:59, 50.3MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00002-of-00003.safetensors:  37% 1.85G/5.00G [00:46<01:02, 50.1MB/s]\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  20% 902M/4.54G [00:46<09:40, 6.26MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00003.safetensors:  40% 1.97G/4.94G [00:46<00:55, 53.5MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00002-of-00003.safetensors:  37% 1.86G/5.00G [00:46<00:59, 52.9MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00003.safetensors:  40% 1.98G/4.94G [00:46<00:53, 55.1MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00002-of-00003.safetensors:  37% 1.87G/5.00G [00:47<00:54, 57.2MB/s]\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  20% 912M/4.54G [00:47<07:29, 8.08MB/s]\u001b[A\u001b[A\n",
            "model-00002-of-00003.safetensors:  38% 1.89G/5.00G [00:47<00:47, 66.0MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00003.safetensors:  41% 2.00G/4.94G [00:47<00:48, 61.1MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00002-of-00003.safetensors:  38% 1.91G/5.00G [00:47<00:37, 81.9MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00003.safetensors:  41% 2.02G/4.94G [00:47<00:39, 74.0MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00002-of-00003.safetensors:  39% 1.93G/5.00G [00:47<00:31, 96.6MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00003.safetensors:  41% 2.04G/4.94G [00:47<00:33, 87.1MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00002-of-00003.safetensors:  39% 1.95G/5.00G [00:47<00:28, 105MB/s] \u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00003.safetensors:  42% 2.07G/4.94G [00:47<00:30, 94.2MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00002-of-00003.safetensors:  39% 1.97G/5.00G [00:48<00:27, 109MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00003.safetensors:  42% 2.09G/4.94G [00:47<00:27, 102MB/s] \u001b[A\u001b[A\u001b[A\n",
            "model-00002-of-00003.safetensors:  40% 1.99G/5.00G [00:48<00:26, 112MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00003.safetensors:  43% 2.11G/4.94G [00:48<00:25, 111MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  20% 923M/4.54G [00:48<07:04, 8.52MB/s]\u001b[A\u001b[A\n",
            "model-00002-of-00003.safetensors:  40% 2.01G/5.00G [00:48<00:30, 97.4MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  41% 2.03G/5.00G [00:48<00:32, 91.5MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00003.safetensors:  43% 2.13G/4.94G [00:48<00:41, 68.0MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00002-of-00003.safetensors:  41% 2.04G/5.00G [00:48<00:33, 89.4MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00003.safetensors:  43% 2.14G/4.94G [00:48<00:39, 70.7MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00002-of-00003.safetensors:  41% 2.06G/5.00G [00:48<00:33, 87.7MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  41% 2.07G/5.00G [00:49<00:34, 85.7MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00003.safetensors:  43% 2.15G/4.94G [00:49<00:44, 62.2MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  21% 933M/4.54G [00:49<06:27, 9.31MB/s]\u001b[A\u001b[A\n",
            "model-00002-of-00003.safetensors:  42% 2.08G/5.00G [00:49<00:34, 84.6MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  42% 2.09G/5.00G [00:49<00:34, 84.0MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  42% 2.10G/5.00G [00:49<00:35, 82.6MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00003.safetensors:  44% 2.16G/4.94G [00:49<00:57, 48.6MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00002-of-00003.safetensors:  42% 2.11G/5.00G [00:49<00:35, 81.9MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00003.safetensors:  44% 2.17G/4.94G [00:49<00:56, 49.4MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00002-of-00003.safetensors:  42% 2.12G/5.00G [00:49<00:46, 62.3MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00003.safetensors:  44% 2.18G/4.94G [00:49<00:56, 49.3MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  21% 944M/4.54G [00:49<05:47, 10.3MB/s]\u001b[A\u001b[A\n",
            "model-00002-of-00003.safetensors:  43% 2.13G/5.00G [00:50<00:42, 67.1MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  43% 2.14G/5.00G [00:50<00:40, 70.9MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00003.safetensors:  44% 2.19G/4.94G [00:50<00:59, 46.5MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00002-of-00003.safetensors:  43% 2.15G/5.00G [00:50<00:47, 59.5MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00003.safetensors:  45% 2.20G/4.94G [00:50<01:01, 44.9MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00002-of-00003.safetensors:  43% 2.16G/5.00G [00:50<00:43, 65.0MB/s]\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  21% 954M/4.54G [00:50<05:11, 11.5MB/s]\u001b[A\u001b[A\n",
            "model-00002-of-00003.safetensors:  43% 2.17G/5.00G [00:50<00:40, 69.4MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00003.safetensors:  45% 2.21G/4.94G [00:50<01:01, 44.8MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00002-of-00003.safetensors:  44% 2.18G/5.00G [00:50<00:41, 67.4MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00003.safetensors:  45% 2.22G/4.94G [00:50<00:58, 46.8MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00002-of-00003.safetensors:  44% 2.19G/5.00G [00:50<00:39, 71.7MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  44% 2.20G/5.00G [00:51<00:41, 68.2MB/s]\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  21% 965M/4.54G [00:51<04:36, 12.9MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00003.safetensors:  45% 2.23G/4.94G [00:51<01:05, 41.5MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00003.safetensors:  45% 2.24G/4.94G [00:51<00:57, 47.2MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00002-of-00003.safetensors:  44% 2.21G/5.00G [00:51<00:51, 54.0MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00003.safetensors:  46% 2.25G/4.94G [00:51<00:51, 52.2MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00002-of-00003.safetensors:  44% 2.22G/5.00G [00:51<00:52, 53.2MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00003.safetensors:  46% 2.26G/4.94G [00:51<00:50, 53.4MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  21% 975M/4.54G [00:51<04:07, 14.4MB/s]\u001b[A\u001b[A\n",
            "model-00002-of-00003.safetensors:  45% 2.23G/5.00G [00:51<00:52, 52.4MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00003.safetensors:  46% 2.28G/4.94G [00:51<00:46, 57.6MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00002-of-00003.safetensors:  45% 2.24G/5.00G [00:51<00:50, 54.1MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00003.safetensors:  46% 2.29G/4.94G [00:51<00:45, 58.9MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00002-of-00003.safetensors:  45% 2.25G/5.00G [00:52<00:45, 61.0MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00003.safetensors:  46% 2.30G/4.94G [00:52<00:41, 63.3MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  22% 986M/4.54G [00:52<03:41, 16.0MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00003.safetensors:  47% 2.31G/4.94G [00:52<00:41, 63.4MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00002-of-00003.safetensors:  45% 2.26G/5.00G [00:52<00:55, 49.1MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00003.safetensors:  47% 2.32G/4.94G [00:52<00:40, 64.3MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00002-of-00003.safetensors:  46% 2.28G/5.00G [00:52<00:59, 45.7MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00003.safetensors:  47% 2.33G/4.94G [00:52<00:46, 56.6MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  22% 996M/4.54G [00:52<03:26, 17.2MB/s]\u001b[A\u001b[A\n",
            "model-00002-of-00003.safetensors:  46% 2.29G/5.00G [00:52<00:59, 45.5MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00003.safetensors:  47% 2.34G/4.94G [00:52<00:49, 52.7MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00002-of-00003.safetensors:  46% 2.30G/5.00G [00:53<00:53, 50.9MB/s]\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  22% 1.01G/4.54G [00:52<02:59, 19.7MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00003.safetensors:  48% 2.35G/4.94G [00:52<00:45, 57.2MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00002-of-00003.safetensors:  46% 2.31G/5.00G [00:53<00:49, 54.4MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00003.safetensors:  48% 2.36G/4.94G [00:53<00:44, 57.8MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00002-of-00003.safetensors:  46% 2.32G/5.00G [00:53<00:42, 62.6MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00003.safetensors:  48% 2.37G/4.94G [00:53<00:39, 64.4MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  22% 1.02G/4.54G [00:53<02:46, 21.2MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00003.safetensors:  48% 2.38G/4.94G [00:53<00:36, 71.1MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00003.safetensors:  48% 2.39G/4.94G [00:53<00:33, 77.0MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00002-of-00003.safetensors:  47% 2.33G/5.00G [00:53<00:53, 49.9MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00003.safetensors:  49% 2.40G/4.94G [00:53<00:37, 68.4MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00002-of-00003.safetensors:  47% 2.34G/5.00G [00:53<00:50, 52.7MB/s]\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  23% 1.03G/4.54G [00:53<02:32, 23.1MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00003.safetensors:  49% 2.41G/4.94G [00:53<00:34, 72.3MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00002-of-00003.safetensors:  47% 2.35G/5.00G [00:53<00:43, 60.3MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  47% 2.36G/5.00G [00:54<00:45, 57.5MB/s]\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  23% 1.04G/4.54G [00:54<02:16, 25.7MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00003.safetensors:  49% 2.42G/4.94G [00:54<00:40, 62.3MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00003.safetensors:  49% 2.43G/4.94G [00:54<00:40, 62.6MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00003.safetensors:  49% 2.44G/4.94G [00:54<00:37, 67.3MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  23% 1.05G/4.54G [00:54<02:08, 27.2MB/s]\u001b[A\u001b[A\n",
            "model-00002-of-00003.safetensors:  47% 2.37G/5.00G [00:54<00:58, 45.3MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00003.safetensors:  50% 2.45G/4.94G [00:54<00:34, 71.3MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00002-of-00003.safetensors:  48% 2.38G/5.00G [00:54<00:49, 52.5MB/s]\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  23% 1.06G/4.54G [00:54<01:59, 29.2MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00003.safetensors:  50% 2.46G/4.94G [00:54<00:38, 63.8MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00003.safetensors:  50% 2.47G/4.94G [00:54<00:35, 68.7MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  24% 1.07G/4.54G [00:54<01:49, 31.6MB/s]\u001b[A\u001b[A\n",
            "model-00002-of-00003.safetensors:  48% 2.39G/5.00G [00:55<01:10, 36.9MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00003.safetensors:  50% 2.49G/4.94G [00:54<00:39, 62.4MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00003.safetensors:  50% 2.50G/4.94G [00:55<00:36, 67.2MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00002-of-00003.safetensors:  48% 2.40G/5.00G [00:55<01:03, 40.9MB/s]\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  24% 1.08G/4.54G [00:55<01:45, 32.8MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00003.safetensors:  51% 2.51G/4.94G [00:55<01:07, 35.9MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00002-of-00003.safetensors:  48% 2.41G/5.00G [00:55<01:30, 28.6MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00003.safetensors:  51% 2.53G/4.94G [00:55<00:45, 53.5MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  24% 1.09G/4.54G [00:55<02:22, 24.2MB/s]\u001b[A\u001b[A\n",
            "model-00002-of-00003.safetensors:  48% 2.42G/5.00G [00:56<01:14, 34.8MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  49% 2.43G/5.00G [00:56<00:59, 42.9MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00003.safetensors:  51% 2.54G/4.94G [00:56<00:45, 53.0MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  24% 1.10G/4.54G [00:56<02:00, 28.5MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  24% 1.11G/4.54G [00:56<01:35, 36.0MB/s]\u001b[A\u001b[A\n",
            "model-00002-of-00003.safetensors:  49% 2.44G/5.00G [00:56<00:59, 42.9MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00003.safetensors:  52% 2.55G/4.94G [00:56<00:46, 51.3MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  25% 1.12G/4.54G [00:56<01:18, 43.6MB/s]\u001b[A\u001b[A\n",
            "model-00002-of-00003.safetensors:  49% 2.45G/5.00G [00:56<00:49, 51.5MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00003.safetensors:  52% 2.56G/4.94G [00:56<00:40, 58.6MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  25% 1.13G/4.54G [00:56<01:06, 51.6MB/s]\u001b[A\u001b[A\n",
            "model-00002-of-00003.safetensors:  49% 2.46G/5.00G [00:56<00:47, 53.5MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00003.safetensors:  52% 2.57G/4.94G [00:56<00:43, 55.2MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  25% 1.14G/4.54G [00:56<01:09, 49.1MB/s]\u001b[A\u001b[A\n",
            "model-00002-of-00003.safetensors:  49% 2.47G/5.00G [00:56<00:47, 53.0MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00003.safetensors:  52% 2.58G/4.94G [00:56<00:41, 56.7MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  25% 1.15G/4.54G [00:56<01:05, 51.6MB/s]\u001b[A\u001b[A\n",
            "model-00002-of-00003.safetensors:  50% 2.49G/5.00G [00:57<00:47, 52.7MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00003.safetensors:  52% 2.59G/4.94G [00:56<00:41, 56.3MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  26% 1.16G/4.54G [00:57<01:03, 53.1MB/s]\u001b[A\u001b[A\n",
            "model-00002-of-00003.safetensors:  50% 2.50G/5.00G [00:57<00:42, 59.3MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00003.safetensors:  53% 2.60G/4.94G [00:57<00:37, 62.2MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  26% 1.17G/4.54G [00:59<04:31, 12.4MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00003.safetensors:  53% 2.61G/4.94G [00:59<03:04, 12.6MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  26% 1.18G/4.54G [00:59<03:32, 15.8MB/s]\u001b[A\u001b[A\n",
            "model-00002-of-00003.safetensors:  50% 2.51G/5.00G [00:59<03:35, 11.6MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00003.safetensors:  53% 2.62G/4.94G [00:59<02:23, 16.2MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  26% 1.20G/4.54G [00:59<02:39, 21.0MB/s]\u001b[A\u001b[A\n",
            "model-00002-of-00003.safetensors:  50% 2.52G/5.00G [00:59<02:37, 15.8MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00003.safetensors:  53% 2.63G/4.94G [00:59<01:46, 21.7MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  27% 1.22G/4.54G [01:00<01:45, 31.6MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00003.safetensors:  54% 2.65G/4.94G [01:00<01:10, 32.3MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00002-of-00003.safetensors:  51% 2.54G/5.00G [01:00<01:41, 24.2MB/s]\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  27% 1.23G/4.54G [01:00<01:27, 37.9MB/s]\u001b[A\u001b[A\n",
            "model-00002-of-00003.safetensors:  51% 2.55G/5.00G [01:00<01:24, 29.0MB/s]\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  27% 1.25G/4.54G [01:00<01:01, 53.5MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00003.safetensors:  54% 2.66G/4.94G [01:00<01:09, 32.8MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00002-of-00003.safetensors:  51% 2.56G/5.00G [01:00<01:13, 33.3MB/s]\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  28% 1.26G/4.54G [01:00<00:58, 56.4MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00003.safetensors:  54% 2.68G/4.94G [01:00<00:47, 47.7MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  28% 1.27G/4.54G [01:00<00:52, 62.8MB/s]\u001b[A\u001b[A\n",
            "model-00002-of-00003.safetensors:  52% 2.58G/5.00G [01:00<00:52, 45.7MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00003.safetensors:  55% 2.69G/4.94G [01:00<00:42, 53.5MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  28% 1.29G/4.54G [01:00<00:40, 79.9MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00003.safetensors:  55% 2.71G/4.94G [01:00<00:37, 59.6MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00002-of-00003.safetensors:  52% 2.59G/5.00G [01:00<00:47, 50.3MB/s]\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  29% 1.30G/4.54G [01:00<00:45, 71.4MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00003.safetensors:  55% 2.72G/4.94G [01:01<00:46, 48.4MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00002-of-00003.safetensors:  52% 2.60G/5.00G [01:01<00:56, 42.8MB/s]\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  29% 1.31G/4.54G [01:01<00:58, 55.2MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00003.safetensors:  55% 2.73G/4.94G [01:01<00:42, 52.1MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00002-of-00003.safetensors:  52% 2.61G/5.00G [01:01<00:48, 48.9MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00003.safetensors:  55% 2.74G/4.94G [01:01<00:40, 54.1MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  29% 1.33G/4.54G [01:01<00:48, 66.8MB/s]\u001b[A\u001b[A\n",
            "model-00002-of-00003.safetensors:  52% 2.62G/5.00G [01:01<00:48, 49.5MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00003.safetensors:  56% 2.75G/4.94G [01:01<00:36, 60.7MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  30% 1.34G/4.54G [01:01<00:45, 70.6MB/s]\u001b[A\u001b[A\n",
            "model-00002-of-00003.safetensors:  53% 2.63G/5.00G [01:01<00:41, 57.6MB/s]\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  30% 1.35G/4.54G [01:01<00:48, 65.6MB/s]\u001b[A\u001b[A\n",
            "model-00002-of-00003.safetensors:  53% 2.64G/5.00G [01:01<00:43, 53.8MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00003.safetensors:  56% 2.77G/4.94G [01:01<00:34, 62.6MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  30% 1.36G/4.54G [01:02<00:51, 62.2MB/s]\u001b[A\u001b[A\n",
            "model-00002-of-00003.safetensors:  53% 2.65G/5.00G [01:02<00:41, 56.3MB/s]\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  30% 1.37G/4.54G [01:02<00:52, 60.2MB/s]\u001b[A\u001b[A\n",
            "model-00002-of-00003.safetensors:  53% 2.66G/5.00G [01:05<04:29, 8.68MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  53% 2.67G/5.00G [01:05<03:19, 11.6MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00003.safetensors:  56% 2.79G/4.94G [01:05<03:01, 11.9MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00002-of-00003.safetensors:  54% 2.68G/5.00G [01:06<02:27, 15.7MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  54% 2.69G/5.00G [01:06<01:51, 20.7MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00003.safetensors:  57% 2.81G/4.94G [01:06<02:02, 17.5MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00002-of-00003.safetensors:  54% 2.72G/5.00G [01:06<01:09, 33.0MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00003.safetensors:  57% 2.83G/4.94G [01:06<01:26, 24.5MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  30% 1.38G/4.54G [01:06<06:22, 8.25MB/s]\u001b[A\u001b[A\n",
            "model-00002-of-00003.safetensors:  55% 2.73G/5.00G [01:06<01:00, 37.9MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00003.safetensors:  58% 2.85G/4.94G [01:06<01:02, 33.5MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  31% 1.39G/4.54G [01:06<04:50, 10.8MB/s]\u001b[A\u001b[A\n",
            "model-00002-of-00003.safetensors:  55% 2.74G/5.00G [01:06<00:49, 45.3MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00003.safetensors:  58% 2.86G/4.94G [01:06<00:54, 38.2MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  31% 1.41G/4.54G [01:06<03:39, 14.3MB/s]\u001b[A\u001b[A\n",
            "model-00002-of-00003.safetensors:  55% 2.75G/5.00G [01:06<00:45, 49.9MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00003.safetensors:  58% 2.87G/4.94G [01:06<00:54, 38.0MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  31% 1.42G/4.54G [01:06<02:54, 17.9MB/s]\u001b[A\u001b[A\n",
            "model-00002-of-00003.safetensors:  55% 2.76G/5.00G [01:07<00:45, 49.4MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00003.safetensors:  58% 2.88G/4.94G [01:06<00:46, 44.2MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  31% 1.43G/4.54G [01:07<02:12, 23.6MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00003.safetensors:  59% 2.89G/4.94G [01:08<01:34, 21.6MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00002-of-00003.safetensors:  56% 2.78G/5.00G [01:10<03:25, 10.8MB/s]\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  32% 1.44G/4.54G [01:10<07:03, 7.34MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00003.safetensors:  59% 2.90G/4.94G [01:10<03:25, 9.94MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  32% 1.45G/4.54G [01:11<05:21, 9.63MB/s]\u001b[A\u001b[A\n",
            "model-00002-of-00003.safetensors:  56% 2.79G/5.00G [01:11<02:51, 12.9MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00003.safetensors:  59% 2.92G/4.94G [01:11<02:41, 12.5MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  32% 1.46G/4.54G [01:11<03:54, 13.1MB/s]\u001b[A\u001b[A\n",
            "model-00002-of-00003.safetensors:  56% 2.80G/5.00G [01:11<02:13, 16.5MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00003.safetensors:  59% 2.93G/4.94G [01:11<02:02, 16.5MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00003.safetensors:  59% 2.94G/4.94G [01:11<01:32, 21.7MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00002-of-00003.safetensors:  56% 2.81G/5.00G [01:11<01:43, 21.1MB/s]\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  33% 1.48G/4.54G [01:11<02:19, 22.0MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00003.safetensors:  60% 2.95G/4.94G [01:11<01:13, 27.2MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00002-of-00003.safetensors:  56% 2.82G/5.00G [01:11<01:23, 26.1MB/s]\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  33% 1.49G/4.54G [01:11<01:52, 27.2MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00003.safetensors:  60% 2.97G/4.94G [01:11<00:47, 41.2MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00002-of-00003.safetensors:  57% 2.83G/5.00G [01:11<01:11, 30.4MB/s]\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  33% 1.50G/4.54G [01:11<01:37, 31.2MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00003.safetensors:  60% 2.98G/4.94G [01:11<00:46, 42.1MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00002-of-00003.safetensors:  57% 2.84G/5.00G [01:12<01:03, 34.0MB/s]\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  33% 1.51G/4.54G [01:11<01:29, 34.0MB/s]\u001b[A\u001b[A\n",
            "model-00002-of-00003.safetensors:  57% 2.85G/5.00G [01:12<00:51, 41.6MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00003.safetensors:  60% 2.99G/4.94G [01:11<00:41, 47.4MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  33% 1.52G/4.54G [01:12<02:15, 22.2MB/s]\u001b[A\u001b[A\n",
            "model-00002-of-00003.safetensors:  57% 2.86G/5.00G [01:16<05:07, 6.94MB/s]\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  34% 1.53G/4.54G [01:16<06:43, 7.46MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  34% 1.55G/4.54G [01:16<03:48, 13.1MB/s]\u001b[A\u001b[A\n",
            "model-00002-of-00003.safetensors:  58% 2.88G/5.00G [01:16<02:51, 12.3MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00003.safetensors:  61% 3.00G/4.94G [01:16<04:26, 7.28MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00002-of-00003.safetensors:  58% 2.90G/5.00G [01:16<01:48, 19.4MB/s]\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  35% 1.57G/4.54G [01:16<02:26, 20.2MB/s]\u001b[A\u001b[A\n",
            "model-00002-of-00003.safetensors:  59% 2.93G/5.00G [01:17<01:14, 27.8MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00003.safetensors:  61% 3.02G/4.94G [01:16<02:39, 12.1MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  35% 1.59G/4.54G [01:17<01:43, 28.5MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  35% 1.60G/4.54G [01:17<01:28, 33.2MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00003.safetensors:  61% 3.03G/4.94G [01:17<02:06, 15.2MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00002-of-00003.safetensors:  59% 2.95G/5.00G [01:17<00:59, 34.3MB/s]\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  36% 1.61G/4.54G [01:17<01:27, 33.4MB/s]\u001b[A\u001b[A\n",
            "model-00002-of-00003.safetensors:  59% 2.96G/5.00G [01:17<00:53, 37.8MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00003.safetensors:  62% 3.04G/4.94G [01:17<01:49, 17.4MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00003.safetensors:  62% 3.05G/4.94G [01:17<01:26, 22.0MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00002-of-00003.safetensors:  59% 2.97G/5.00G [01:17<00:48, 42.2MB/s]\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  36% 1.64G/4.54G [01:17<01:04, 45.1MB/s]\u001b[A\u001b[A\n",
            "model-00002-of-00003.safetensors:  60% 2.98G/5.00G [01:17<00:41, 49.2MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00003.safetensors:  62% 3.06G/4.94G [01:17<01:08, 27.4MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  36% 1.65G/4.54G [01:17<00:56, 51.3MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00003.safetensors:  62% 3.07G/4.94G [01:17<00:54, 34.1MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00002-of-00003.safetensors:  60% 3.00G/5.00G [01:18<00:32, 62.0MB/s]\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  37% 1.67G/4.54G [01:17<00:44, 64.0MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00003.safetensors:  62% 3.08G/4.94G [01:17<00:44, 41.8MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  37% 1.68G/4.54G [01:18<00:43, 66.0MB/s]\u001b[A\u001b[A\n",
            "model-00002-of-00003.safetensors:  60% 3.02G/5.00G [01:18<00:26, 74.1MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00003.safetensors:  63% 3.10G/4.94G [01:18<00:31, 57.8MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00002-of-00003.safetensors:  61% 3.04G/5.00G [01:18<00:22, 85.7MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00003.safetensors:  63% 3.12G/4.94G [01:18<00:24, 75.7MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  37% 1.69G/4.54G [01:18<00:51, 55.4MB/s]\u001b[A\u001b[A\n",
            "model-00002-of-00003.safetensors:  61% 3.06G/5.00G [01:18<00:20, 93.4MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00003.safetensors:  64% 3.15G/4.94G [01:18<00:20, 86.8MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00002-of-00003.safetensors:  62% 3.08G/5.00G [01:18<00:18, 103MB/s] \u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  37% 1.70G/4.54G [01:18<00:55, 51.2MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00003.safetensors:  64% 3.17G/4.94G [01:18<00:18, 94.7MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00002-of-00003.safetensors:  62% 3.10G/5.00G [01:18<00:17, 108MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00003.safetensors:  64% 3.19G/4.94G [01:18<00:16, 104MB/s] \u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  38% 1.71G/4.54G [01:18<01:05, 43.2MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00003.safetensors:  65% 3.21G/4.94G [01:18<00:15, 109MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00002-of-00003.safetensors:  62% 3.12G/5.00G [01:19<00:19, 95.2MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00003.safetensors:  65% 3.23G/4.94G [01:19<00:14, 116MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00002-of-00003.safetensors:  63% 3.14G/5.00G [01:19<00:20, 89.7MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00003.safetensors:  66% 3.25G/4.94G [01:19<00:13, 124MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  38% 1.72G/4.54G [01:19<01:14, 37.9MB/s]\u001b[A\u001b[A\n",
            "model-00002-of-00003.safetensors:  63% 3.15G/5.00G [01:19<00:21, 86.6MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00003.safetensors:  66% 3.27G/4.94G [01:19<00:13, 126MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00002-of-00003.safetensors:  63% 3.16G/5.00G [01:19<00:22, 81.2MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00003.safetensors:  67% 3.29G/4.94G [01:19<00:12, 133MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00002-of-00003.safetensors:  63% 3.17G/5.00G [01:19<00:22, 80.3MB/s]\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  38% 1.73G/4.54G [01:19<01:20, 34.8MB/s]\u001b[A\u001b[A\n",
            "model-00002-of-00003.safetensors:  64% 3.18G/5.00G [01:19<00:22, 79.5MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00003.safetensors:  67% 3.31G/4.94G [01:19<00:14, 116MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00002-of-00003.safetensors:  64% 3.19G/5.00G [01:20<00:24, 73.5MB/s]\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  38% 1.74G/4.54G [01:20<01:24, 33.1MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00003.safetensors:  67% 3.33G/4.94G [01:20<00:15, 105MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00002-of-00003.safetensors:  64% 3.20G/5.00G [01:20<00:24, 74.9MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  64% 3.21G/5.00G [01:20<00:23, 76.0MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00003.safetensors:  68% 3.36G/4.94G [01:20<00:16, 98.5MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00002-of-00003.safetensors:  64% 3.22G/5.00G [01:20<00:23, 76.5MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00003.safetensors:  68% 3.37G/4.94G [01:20<00:16, 95.8MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00002-of-00003.safetensors:  65% 3.23G/5.00G [01:20<00:24, 71.3MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00003.safetensors:  68% 3.38G/4.94G [01:20<00:17, 92.2MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  39% 1.75G/4.54G [01:20<01:40, 27.6MB/s]\u001b[A\u001b[A\n",
            "model-00002-of-00003.safetensors:  65% 3.24G/5.00G [01:20<00:24, 71.9MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00003.safetensors:  69% 3.39G/4.94G [01:20<00:17, 89.1MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00002-of-00003.safetensors:  65% 3.25G/5.00G [01:20<00:23, 75.8MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00003.safetensors:  69% 3.40G/4.94G [01:20<00:17, 90.0MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00003.safetensors:  69% 3.41G/4.94G [01:20<00:17, 88.9MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00002-of-00003.safetensors:  65% 3.26G/5.00G [01:21<00:24, 70.6MB/s]\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  39% 1.76G/4.54G [01:21<01:48, 25.7MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00003.safetensors:  69% 3.42G/4.94G [01:21<00:18, 83.1MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00003.safetensors:  69% 3.43G/4.94G [01:21<00:20, 75.4MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00002-of-00003.safetensors:  65% 3.27G/5.00G [01:21<00:35, 49.0MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00003.safetensors:  70% 3.44G/4.94G [01:21<00:19, 78.7MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00003.safetensors:  70% 3.45G/4.94G [01:21<00:18, 80.5MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  39% 1.77G/4.54G [01:21<01:52, 24.6MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00003.safetensors:  70% 3.46G/4.94G [01:21<00:23, 63.1MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00003.safetensors:  70% 3.47G/4.94G [01:21<00:21, 67.7MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  39% 1.78G/4.54G [01:21<01:53, 24.4MB/s]\u001b[A\u001b[A\n",
            "model-00002-of-00003.safetensors:  66% 3.28G/5.00G [01:22<01:02, 27.6MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00003.safetensors:  70% 3.48G/4.94G [01:22<00:29, 49.6MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00003.safetensors:  71% 3.49G/4.94G [01:22<00:27, 52.8MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00002-of-00003.safetensors:  66% 3.29G/5.00G [01:22<00:58, 29.4MB/s]\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  39% 1.79G/4.54G [01:22<01:55, 23.8MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00003.safetensors:  71% 3.50G/4.94G [01:22<00:24, 59.6MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00002-of-00003.safetensors:  66% 3.30G/5.00G [01:22<00:53, 32.0MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00003.safetensors:  71% 3.51G/4.94G [01:22<00:26, 53.2MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00002-of-00003.safetensors:  66% 3.31G/5.00G [01:22<00:45, 36.7MB/s]\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  40% 1.80G/4.54G [01:22<01:54, 23.9MB/s]\u001b[A\u001b[A\n",
            "model-00002-of-00003.safetensors:  66% 3.32G/5.00G [01:23<00:38, 43.0MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00003.safetensors:  71% 3.52G/4.94G [01:23<00:32, 43.9MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00003.safetensors:  71% 3.53G/4.94G [01:23<00:27, 51.5MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00002-of-00003.safetensors:  67% 3.33G/5.00G [01:23<00:41, 40.4MB/s]\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  40% 1.81G/4.54G [01:23<01:52, 24.2MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00003.safetensors:  72% 3.54G/4.94G [01:23<00:24, 56.6MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00003.safetensors:  72% 3.55G/4.94G [01:23<00:25, 53.8MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  40% 1.82G/4.54G [01:23<01:54, 23.8MB/s]\u001b[A\u001b[A\n",
            "model-00002-of-00003.safetensors:  67% 3.34G/5.00G [01:23<00:51, 32.3MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00003.safetensors:  72% 3.57G/4.94G [01:23<00:26, 51.2MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00002-of-00003.safetensors:  67% 3.36G/5.00G [01:24<00:45, 36.1MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00003.safetensors:  72% 3.58G/4.94G [01:23<00:26, 52.1MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00002-of-00003.safetensors:  67% 3.37G/5.00G [01:24<00:37, 43.3MB/s]\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  40% 1.84G/4.54G [01:24<01:52, 24.0MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00003.safetensors:  73% 3.59G/4.94G [01:24<00:28, 48.2MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00002-of-00003.safetensors:  68% 3.38G/5.00G [01:24<00:35, 45.2MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00003.safetensors:  73% 3.60G/4.94G [01:24<00:24, 55.5MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00002-of-00003.safetensors:  68% 3.39G/5.00G [01:24<00:31, 51.7MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00003.safetensors:  73% 3.61G/4.94G [01:24<00:24, 55.5MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00002-of-00003.safetensors:  68% 3.40G/5.00G [01:24<00:28, 57.0MB/s]\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  41% 1.85G/4.54G [01:24<01:51, 24.3MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00003.safetensors:  73% 3.62G/4.94G [01:24<00:21, 61.0MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00002-of-00003.safetensors:  68% 3.41G/5.00G [01:24<00:27, 57.4MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00003.safetensors:  73% 3.63G/4.94G [01:24<00:19, 67.0MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00002-of-00003.safetensors:  68% 3.42G/5.00G [01:25<00:29, 53.3MB/s]\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  41% 1.86G/4.54G [01:25<01:50, 24.4MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00003.safetensors:  74% 3.64G/4.94G [01:25<00:26, 48.4MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00003.safetensors:  74% 3.65G/4.94G [01:25<00:23, 54.7MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00002-of-00003.safetensors:  69% 3.43G/5.00G [01:25<00:37, 41.4MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00003.safetensors:  74% 3.66G/4.94G [01:25<00:20, 61.5MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  41% 1.87G/4.54G [01:25<01:48, 24.6MB/s]\u001b[A\u001b[A\n",
            "model-00002-of-00003.safetensors:  69% 3.44G/5.00G [01:25<00:32, 48.3MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00003.safetensors:  74% 3.67G/4.94G [01:25<00:19, 67.0MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00002-of-00003.safetensors:  69% 3.45G/5.00G [01:25<00:31, 49.2MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00003.safetensors:  74% 3.68G/4.94G [01:25<00:21, 57.6MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  41% 1.88G/4.54G [01:25<01:47, 24.7MB/s]\u001b[A\u001b[A\n",
            "model-00002-of-00003.safetensors:  69% 3.46G/5.00G [01:26<00:30, 50.4MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00003.safetensors:  75% 3.69G/4.94G [01:25<00:19, 63.2MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00003.safetensors:  75% 3.70G/4.94G [01:26<00:18, 68.7MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00002-of-00003.safetensors:  69% 3.47G/5.00G [01:26<00:28, 52.8MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00003.safetensors:  75% 3.71G/4.94G [01:26<00:16, 73.3MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00002-of-00003.safetensors:  70% 3.48G/5.00G [01:26<00:26, 56.9MB/s]\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  42% 1.89G/4.54G [01:26<01:46, 24.8MB/s]\u001b[A\u001b[A\n",
            "model-00002-of-00003.safetensors:  70% 3.49G/5.00G [01:26<00:24, 60.6MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00003.safetensors:  75% 3.72G/4.94G [01:26<00:25, 48.1MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00002-of-00003.safetensors:  70% 3.50G/5.00G [01:26<00:24, 60.6MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  70% 3.51G/5.00G [01:26<00:22, 65.7MB/s]\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  42% 1.90G/4.54G [01:26<01:46, 24.9MB/s]\u001b[A\u001b[A\n",
            "model-00002-of-00003.safetensors:  70% 3.52G/5.00G [01:27<00:24, 59.8MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00003.safetensors:  76% 3.73G/4.94G [01:26<00:31, 38.8MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00002-of-00003.safetensors:  71% 3.53G/5.00G [01:27<00:23, 62.6MB/s]\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  42% 1.91G/4.54G [01:27<01:45, 24.9MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00003.safetensors:  76% 3.74G/4.94G [01:27<00:29, 40.9MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00003.safetensors:  76% 3.75G/4.94G [01:27<00:26, 44.5MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00002-of-00003.safetensors:  71% 3.54G/5.00G [01:27<00:30, 47.0MB/s]\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  42% 1.92G/4.54G [01:27<01:44, 25.0MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00003.safetensors:  76% 3.76G/4.94G [01:27<00:29, 40.3MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00002-of-00003.safetensors:  71% 3.55G/5.00G [01:27<00:34, 42.1MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00003.safetensors:  76% 3.77G/4.94G [01:27<00:28, 40.5MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  42% 1.93G/4.54G [01:27<01:44, 25.0MB/s]\u001b[A\u001b[A\n",
            "model-00002-of-00003.safetensors:  71% 3.57G/5.00G [01:28<00:36, 39.8MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00003.safetensors:  77% 3.79G/4.94G [01:28<00:25, 46.0MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00002-of-00003.safetensors:  72% 3.58G/5.00G [01:28<00:35, 40.4MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00003.safetensors:  77% 3.80G/4.94G [01:28<00:26, 43.9MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  43% 1.94G/4.54G [01:28<01:44, 24.9MB/s]\u001b[A\u001b[A\n",
            "model-00002-of-00003.safetensors:  72% 3.59G/5.00G [01:28<00:29, 47.4MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00003.safetensors:  77% 3.81G/4.94G [01:28<00:23, 48.2MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00002-of-00003.safetensors:  72% 3.60G/5.00G [01:28<00:28, 49.1MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00003.safetensors:  77% 3.82G/4.94G [01:28<00:22, 50.6MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  43% 1.95G/4.54G [01:28<01:43, 25.0MB/s]\u001b[A\u001b[A\n",
            "model-00002-of-00003.safetensors:  72% 3.61G/5.00G [01:28<00:30, 45.7MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00003.safetensors:  77% 3.83G/4.94G [01:28<00:20, 54.5MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00003.safetensors:  78% 3.84G/4.94G [01:29<00:19, 56.0MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00002-of-00003.safetensors:  72% 3.62G/5.00G [01:29<00:30, 45.8MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00003.safetensors:  78% 3.85G/4.94G [01:29<00:18, 58.8MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  43% 1.96G/4.54G [01:29<01:48, 23.8MB/s]\u001b[A\u001b[A\n",
            "model-00002-of-00003.safetensors:  73% 3.63G/5.00G [01:29<00:31, 44.2MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00003.safetensors:  78% 3.86G/4.94G [01:29<00:18, 59.5MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00003.safetensors:  78% 3.87G/4.94G [01:29<00:17, 60.6MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00002-of-00003.safetensors:  73% 3.64G/5.00G [01:29<00:32, 41.6MB/s]\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  43% 1.97G/4.54G [01:29<01:41, 25.3MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00003.safetensors:  78% 3.88G/4.94G [01:29<00:16, 64.6MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00002-of-00003.safetensors:  73% 3.65G/5.00G [01:29<00:30, 43.8MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00003.safetensors:  79% 3.89G/4.94G [01:29<00:17, 61.5MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00002-of-00003.safetensors:  73% 3.66G/5.00G [01:30<00:26, 50.6MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00003.safetensors:  79% 3.90G/4.94G [01:29<00:15, 66.5MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  44% 1.98G/4.54G [01:30<01:41, 25.3MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00003.safetensors:  79% 3.91G/4.94G [01:30<00:15, 65.2MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00002-of-00003.safetensors:  73% 3.67G/5.00G [01:30<00:31, 41.6MB/s]\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  44% 1.99G/4.54G [01:30<01:41, 25.2MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00003.safetensors:  79% 3.92G/4.94G [01:30<00:21, 48.6MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00002-of-00003.safetensors:  74% 3.68G/5.00G [01:30<00:29, 44.4MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00003.safetensors:  80% 3.93G/4.94G [01:30<00:18, 55.8MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00002-of-00003.safetensors:  74% 3.69G/5.00G [01:30<00:26, 48.5MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00003.safetensors:  80% 3.94G/4.94G [01:30<00:16, 61.4MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00002-of-00003.safetensors:  74% 3.70G/5.00G [01:31<00:25, 50.3MB/s]\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  44% 2.00G/4.54G [01:30<01:40, 25.2MB/s]\u001b[A\u001b[A\n",
            "model-00002-of-00003.safetensors:  74% 3.71G/5.00G [01:31<00:24, 51.7MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00003.safetensors:  80% 3.95G/4.94G [01:31<00:21, 46.2MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00002-of-00003.safetensors:  74% 3.72G/5.00G [01:31<00:24, 52.8MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00003.safetensors:  80% 3.97G/4.94G [01:31<00:14, 65.9MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  44% 2.01G/4.54G [01:31<01:40, 25.2MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00003.safetensors:  81% 3.98G/4.94G [01:31<00:14, 67.4MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00002-of-00003.safetensors:  75% 3.73G/5.00G [01:31<00:26, 48.6MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00003.safetensors:  81% 4.00G/4.94G [01:31<00:13, 72.1MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00003.safetensors:  81% 4.01G/4.94G [01:31<00:12, 75.2MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  45% 2.02G/4.54G [01:31<01:38, 25.5MB/s]\u001b[A\u001b[A\n",
            "model-00002-of-00003.safetensors:  75% 3.74G/5.00G [01:31<00:25, 49.8MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00003.safetensors:  81% 4.02G/4.94G [01:31<00:16, 56.9MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00002-of-00003.safetensors:  75% 3.75G/5.00G [01:32<00:26, 47.4MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00003.safetensors:  81% 4.03G/4.94G [01:32<00:14, 62.0MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  45% 2.03G/4.54G [01:32<01:37, 25.6MB/s]\u001b[A\u001b[A\n",
            "model-00002-of-00003.safetensors:  75% 3.76G/5.00G [01:32<00:24, 50.2MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00003.safetensors:  82% 4.04G/4.94G [01:32<00:16, 53.4MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00002-of-00003.safetensors:  76% 3.77G/5.00G [01:32<00:24, 49.6MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00003.safetensors:  82% 4.05G/4.94G [01:32<00:16, 55.4MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  45% 2.04G/4.54G [01:32<01:37, 25.6MB/s]\u001b[A\u001b[A\n",
            "model-00002-of-00003.safetensors:  76% 3.79G/5.00G [01:32<00:24, 48.6MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  76% 3.80G/5.00G [01:32<00:24, 49.8MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00003.safetensors:  82% 4.06G/4.94G [01:32<00:18, 48.6MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  45% 2.06G/4.54G [01:32<01:37, 25.6MB/s]\u001b[A\u001b[A\n",
            "model-00002-of-00003.safetensors:  76% 3.81G/5.00G [01:33<00:22, 53.1MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00003.safetensors:  82% 4.07G/4.94G [01:33<00:19, 44.0MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00002-of-00003.safetensors:  76% 3.82G/5.00G [01:33<00:21, 55.7MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00003.safetensors:  83% 4.08G/4.94G [01:33<00:17, 48.5MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00002-of-00003.safetensors:  77% 3.83G/5.00G [01:33<00:20, 57.3MB/s]\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  45% 2.07G/4.54G [01:33<01:34, 26.1MB/s]\u001b[A\u001b[A\n",
            "model-00002-of-00003.safetensors:  77% 3.84G/5.00G [01:33<00:19, 59.2MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00003.safetensors:  83% 4.09G/4.94G [01:33<00:17, 47.4MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00003.safetensors:  83% 4.10G/4.94G [01:33<00:16, 51.1MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00002-of-00003.safetensors:  77% 3.85G/5.00G [01:33<00:20, 56.1MB/s]\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  46% 2.08G/4.54G [01:33<01:34, 26.1MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00003.safetensors:  83% 4.11G/4.94G [01:33<00:16, 49.2MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00002-of-00003.safetensors:  77% 3.86G/5.00G [01:34<00:22, 50.0MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00003.safetensors:  83% 4.12G/4.94G [01:34<00:16, 51.4MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  46% 2.09G/4.54G [01:34<01:31, 26.7MB/s]\u001b[A\u001b[A\n",
            "model-00002-of-00003.safetensors:  77% 3.87G/5.00G [01:34<00:23, 49.1MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  78% 3.88G/5.00G [01:34<00:21, 51.6MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00003.safetensors:  84% 4.13G/4.94G [01:34<00:17, 46.1MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00002-of-00003.safetensors:  78% 3.89G/5.00G [01:34<00:20, 54.2MB/s]\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  46% 2.10G/4.54G [01:34<01:32, 26.4MB/s]\u001b[A\u001b[A\n",
            "model-00002-of-00003.safetensors:  78% 3.90G/5.00G [01:34<00:19, 55.7MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  78% 3.91G/5.00G [01:34<00:18, 60.3MB/s]\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  46% 2.11G/4.54G [01:34<01:29, 27.2MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00003.safetensors:  84% 4.14G/4.94G [01:34<00:25, 31.4MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00002-of-00003.safetensors:  78% 3.92G/5.00G [01:35<00:17, 62.2MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00003.safetensors:  84% 4.15G/4.94G [01:35<00:21, 37.0MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00002-of-00003.safetensors:  79% 3.93G/5.00G [01:35<00:16, 63.0MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00003.safetensors:  84% 4.16G/4.94G [01:35<00:17, 45.3MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  47% 2.12G/4.54G [01:35<01:27, 27.7MB/s]\u001b[A\u001b[A\n",
            "model-00002-of-00003.safetensors:  79% 3.94G/5.00G [01:35<00:16, 64.7MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00003.safetensors:  84% 4.17G/4.94G [01:35<00:15, 50.3MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00002-of-00003.safetensors:  79% 3.95G/5.00G [01:35<00:16, 64.7MB/s]\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  47% 2.13G/4.54G [01:35<01:25, 28.1MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00003.safetensors:  85% 4.18G/4.94G [01:35<00:21, 34.8MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00002-of-00003.safetensors:  79% 3.96G/5.00G [01:36<00:24, 42.5MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  80% 3.98G/5.00G [01:36<00:16, 62.1MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00003.safetensors:  85% 4.19G/4.94G [01:36<00:19, 38.1MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  47% 2.14G/4.54G [01:36<01:45, 22.8MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00003.safetensors:  85% 4.20G/4.94G [01:36<00:17, 42.5MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00002-of-00003.safetensors:  80% 4.01G/5.00G [01:36<00:14, 67.1MB/s]\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  47% 2.15G/4.54G [01:36<01:26, 27.7MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00003.safetensors:  85% 4.22G/4.94G [01:36<00:15, 46.4MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  48% 2.16G/4.54G [01:36<01:12, 33.0MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00003.safetensors:  85% 4.23G/4.94G [01:36<00:15, 45.0MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00002-of-00003.safetensors:  80% 4.02G/5.00G [01:36<00:19, 49.2MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  81% 4.03G/5.00G [01:37<00:18, 53.2MB/s]\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  48% 2.17G/4.54G [01:36<01:13, 32.1MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00003.safetensors:  86% 4.25G/4.94G [01:36<00:12, 55.3MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00003.safetensors:  86% 4.26G/4.94G [01:37<00:12, 55.8MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00002-of-00003.safetensors:  81% 4.04G/5.00G [01:37<00:21, 44.8MB/s]\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  48% 2.18G/4.54G [01:37<01:12, 32.7MB/s]\u001b[A\u001b[A\n",
            "model-00002-of-00003.safetensors:  81% 4.05G/5.00G [01:37<00:19, 48.4MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00003.safetensors:  86% 4.27G/4.94G [01:37<00:12, 52.0MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  48% 2.19G/4.54G [01:37<01:10, 33.2MB/s]\u001b[A\u001b[A\n",
            "model-00002-of-00003.safetensors:  81% 4.06G/5.00G [01:37<00:19, 47.9MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00003.safetensors:  87% 4.28G/4.94G [01:37<00:13, 49.3MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00002-of-00003.safetensors:  81% 4.07G/5.00G [01:37<00:19, 47.2MB/s]\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  48% 2.20G/4.54G [01:37<01:09, 33.6MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00003.safetensors:  87% 4.29G/4.94G [01:37<00:13, 48.0MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00002-of-00003.safetensors:  82% 4.08G/5.00G [01:38<00:17, 53.4MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00003.safetensors:  87% 4.30G/4.94G [01:38<00:13, 48.6MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  49% 2.21G/4.54G [01:38<01:08, 34.0MB/s]\u001b[A\u001b[A\n",
            "model-00002-of-00003.safetensors:  82% 4.09G/5.00G [01:38<00:17, 52.8MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00003.safetensors:  87% 4.31G/4.94G [01:38<00:13, 47.3MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00002-of-00003.safetensors:  82% 4.10G/5.00G [01:38<00:18, 47.7MB/s]\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  49% 2.22G/4.54G [01:38<01:07, 34.5MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00003.safetensors:  87% 4.32G/4.94G [01:38<00:13, 46.9MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00002-of-00003.safetensors:  82% 4.11G/5.00G [01:38<00:16, 52.4MB/s]\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  49% 2.23G/4.54G [01:38<01:06, 34.8MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00003.safetensors:  88% 4.33G/4.94G [01:38<00:12, 48.0MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00002-of-00003.safetensors:  82% 4.12G/5.00G [01:38<00:17, 49.3MB/s]\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  49% 2.24G/4.54G [01:39<01:03, 36.3MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00003.safetensors:  88% 4.34G/4.94G [01:39<00:20, 29.6MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00003.safetensors:  88% 4.35G/4.94G [01:40<00:38, 15.4MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  50% 2.25G/4.54G [01:41<02:54, 13.1MB/s]\u001b[A\u001b[A\n",
            "model-00002-of-00003.safetensors:  83% 4.13G/5.00G [01:41<01:06, 13.1MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00003.safetensors:  88% 4.37G/4.94G [01:41<00:22, 25.3MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  50% 2.26G/4.54G [01:41<02:12, 17.1MB/s]\u001b[A\u001b[A\n",
            "model-00002-of-00003.safetensors:  83% 4.14G/5.00G [01:41<00:51, 16.8MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00003.safetensors:  89% 4.39G/4.94G [01:41<00:15, 36.3MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  50% 2.28G/4.54G [01:41<01:41, 22.3MB/s]\u001b[A\u001b[A\n",
            "model-00002-of-00003.safetensors:  83% 4.15G/5.00G [01:41<00:38, 22.3MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00003.safetensors:  89% 4.41G/4.94G [01:41<00:10, 49.7MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00002-of-00003.safetensors:  83% 4.16G/5.00G [01:41<00:28, 29.0MB/s]\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  51% 2.30G/4.54G [01:41<01:04, 34.9MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00003.safetensors:  90% 4.44G/4.94G [01:41<00:07, 63.7MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  51% 2.32G/4.54G [01:41<00:49, 45.0MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00003.safetensors:  90% 4.46G/4.94G [01:41<00:07, 62.2MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00002-of-00003.safetensors:  84% 4.18G/5.00G [01:42<00:23, 34.1MB/s]\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  51% 2.33G/4.54G [01:41<00:45, 48.2MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00003.safetensors:  90% 4.47G/4.94G [01:42<00:07, 62.6MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00002-of-00003.safetensors:  84% 4.19G/5.00G [01:42<00:21, 38.1MB/s]\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  51% 2.34G/4.54G [01:42<00:43, 50.2MB/s]\u001b[A\u001b[A\n",
            "model-00002-of-00003.safetensors:  84% 4.20G/5.00G [01:42<00:19, 41.2MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00003.safetensors:  91% 4.48G/4.94G [01:42<00:08, 58.1MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  52% 2.35G/4.54G [01:42<00:48, 45.4MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00003.safetensors:  91% 4.49G/4.94G [01:42<00:07, 63.8MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00002-of-00003.safetensors:  84% 4.22G/5.00G [01:42<00:16, 47.8MB/s]\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  52% 2.36G/4.54G [01:42<00:42, 51.5MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00003.safetensors:  91% 4.51G/4.94G [01:42<00:05, 79.3MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  52% 2.38G/4.54G [01:42<00:30, 70.7MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00003.safetensors:  92% 4.53G/4.94G [01:42<00:04, 95.6MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00002-of-00003.safetensors:  85% 4.23G/5.00G [01:42<00:18, 42.5MB/s]\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  53% 2.40G/4.54G [01:42<00:25, 85.1MB/s]\u001b[A\u001b[A\n",
            "model-00002-of-00003.safetensors:  85% 4.24G/5.00G [01:43<00:15, 48.1MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  85% 4.25G/5.00G [01:43<00:13, 56.3MB/s]\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  53% 2.42G/4.54G [01:43<00:22, 92.8MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00003.safetensors:  92% 4.55G/4.94G [01:43<00:05, 77.9MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00002-of-00003.safetensors:  85% 4.26G/5.00G [01:43<00:11, 64.6MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  85% 4.27G/5.00G [01:43<00:10, 71.2MB/s]\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  54% 2.44G/4.54G [01:43<00:21, 97.3MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00003.safetensors:  92% 4.56G/4.94G [01:43<00:05, 64.0MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00002-of-00003.safetensors:  86% 4.29G/5.00G [01:43<00:09, 74.8MB/s]\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  54% 2.46G/4.54G [01:43<00:22, 93.1MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00003.safetensors:  92% 4.57G/4.94G [01:43<00:06, 61.5MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00002-of-00003.safetensors:  86% 4.30G/5.00G [01:43<00:10, 69.1MB/s]\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  55% 2.47G/4.54G [01:43<00:24, 83.6MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00003.safetensors:  93% 4.58G/4.94G [01:43<00:05, 65.6MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  55% 2.49G/4.54G [01:43<00:26, 78.1MB/s]\u001b[A\u001b[A\n",
            "model-00002-of-00003.safetensors:  86% 4.31G/5.00G [01:44<00:10, 64.4MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00003.safetensors:  93% 4.59G/4.94G [01:43<00:05, 63.3MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00002-of-00003.safetensors:  86% 4.32G/5.00G [01:44<00:10, 62.3MB/s]\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  55% 2.50G/4.54G [01:44<00:29, 68.8MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00003.safetensors:  93% 4.60G/4.94G [01:44<00:05, 60.7MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00002-of-00003.safetensors:  87% 4.33G/5.00G [01:44<00:11, 60.6MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00003.safetensors:  93% 4.61G/4.94G [01:44<00:05, 59.1MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  55% 2.51G/4.54G [01:44<00:35, 58.0MB/s]\u001b[A\u001b[A\n",
            "model-00002-of-00003.safetensors:  87% 4.34G/5.00G [01:44<00:10, 62.4MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00003.safetensors:  94% 4.62G/4.94G [01:44<00:05, 57.3MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00002-of-00003.safetensors:  87% 4.35G/5.00G [01:44<00:10, 61.2MB/s]\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  55% 2.52G/4.54G [01:44<00:42, 47.9MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00003.safetensors:  94% 4.63G/4.94G [01:44<00:05, 55.4MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00002-of-00003.safetensors:  87% 4.36G/5.00G [01:44<00:10, 58.8MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00003.safetensors:  94% 4.65G/4.94G [01:44<00:05, 54.9MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00002-of-00003.safetensors:  87% 4.37G/5.00G [01:45<00:10, 59.3MB/s]\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  56% 2.53G/4.54G [01:44<00:46, 43.3MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00003.safetensors:  94% 4.66G/4.94G [01:45<00:05, 54.7MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00002-of-00003.safetensors:  88% 4.38G/5.00G [01:45<00:10, 58.3MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00003.safetensors:  94% 4.67G/4.94G [01:45<00:05, 54.7MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00002-of-00003.safetensors:  88% 4.39G/5.00G [01:45<00:10, 57.7MB/s]\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  56% 2.54G/4.54G [01:45<00:55, 36.2MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00003.safetensors:  95% 4.68G/4.94G [01:45<00:04, 53.9MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00002-of-00003.safetensors:  88% 4.40G/5.00G [01:45<00:09, 60.1MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  88% 4.41G/5.00G [01:45<00:09, 60.2MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00003.safetensors:  95% 4.69G/4.94G [01:45<00:04, 53.4MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  56% 2.55G/4.54G [01:45<01:02, 32.0MB/s]\u001b[A\u001b[A\n",
            "model-00002-of-00003.safetensors:  89% 4.42G/5.00G [01:45<00:09, 59.4MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00003.safetensors:  95% 4.70G/4.94G [01:45<00:04, 53.3MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00003.safetensors:  95% 4.71G/4.94G [01:46<00:04, 53.2MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  56% 2.56G/4.54G [01:46<01:06, 29.7MB/s]\u001b[A\u001b[A\n",
            "model-00002-of-00003.safetensors:  89% 4.44G/5.00G [01:46<00:13, 42.5MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00003.safetensors:  95% 4.72G/4.94G [01:46<00:04, 49.4MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00002-of-00003.safetensors:  89% 4.45G/5.00G [01:46<00:11, 49.7MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  89% 4.47G/5.00G [01:46<00:07, 68.9MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00003.safetensors:  96% 4.73G/4.94G [01:46<00:04, 44.4MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  57% 2.57G/4.54G [01:46<01:08, 28.7MB/s]\u001b[A\u001b[A\n",
            "model-00002-of-00003.safetensors:  90% 4.48G/5.00G [01:46<00:07, 66.1MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00003.safetensors:  96% 4.74G/4.94G [01:46<00:04, 43.8MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00002-of-00003.safetensors:  90% 4.49G/5.00G [01:47<00:07, 66.7MB/s]\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  57% 2.58G/4.54G [01:47<01:09, 28.1MB/s]\u001b[A\u001b[A\n",
            "model-00002-of-00003.safetensors:  90% 4.50G/5.00G [01:47<00:07, 65.1MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00003.safetensors:  96% 4.75G/4.94G [01:47<00:04, 42.9MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00002-of-00003.safetensors:  90% 4.51G/5.00G [01:47<00:07, 62.8MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00003.safetensors:  96% 4.76G/4.94G [01:47<00:04, 42.5MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  57% 2.59G/4.54G [01:47<01:10, 27.8MB/s]\u001b[A\u001b[A\n",
            "model-00002-of-00003.safetensors:  90% 4.52G/5.00G [01:47<00:09, 52.3MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00003.safetensors:  97% 4.77G/4.94G [01:47<00:04, 42.7MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00002-of-00003.safetensors:  91% 4.53G/5.00G [01:47<00:08, 54.4MB/s]\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  57% 2.60G/4.54G [01:47<01:10, 27.5MB/s]\u001b[A\u001b[A\n",
            "model-00002-of-00003.safetensors:  91% 4.54G/5.00G [01:48<00:08, 55.1MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00003.safetensors:  97% 4.78G/4.94G [01:47<00:04, 37.8MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00003.safetensors:  97% 4.79G/4.94G [01:48<00:03, 44.5MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00002-of-00003.safetensors:  91% 4.55G/5.00G [01:48<00:08, 52.3MB/s]\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  58% 2.61G/4.54G [01:48<01:09, 27.7MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00003.safetensors:  97% 4.80G/4.94G [01:48<00:03, 44.3MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00002-of-00003.safetensors:  91% 4.56G/5.00G [01:48<00:09, 47.5MB/s]\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  58% 2.62G/4.54G [01:48<01:09, 27.7MB/s]\u001b[A\u001b[A\n",
            "model-00002-of-00003.safetensors:  91% 4.57G/5.00G [01:48<00:08, 50.8MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00003.safetensors:  97% 4.81G/4.94G [01:48<00:02, 44.3MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00003.safetensors:  98% 4.82G/4.94G [01:48<00:02, 44.6MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  58% 2.63G/4.54G [01:48<01:08, 27.7MB/s]\u001b[A\u001b[A\n",
            "model-00002-of-00003.safetensors:  92% 4.58G/5.00G [01:49<00:10, 39.0MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00003.safetensors:  98% 4.83G/4.94G [01:48<00:02, 45.3MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00002-of-00003.safetensors:  92% 4.59G/5.00G [01:49<00:09, 43.0MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00003.safetensors:  98% 4.84G/4.94G [01:49<00:02, 45.4MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  58% 2.64G/4.54G [01:49<01:07, 27.9MB/s]\u001b[A\u001b[A\n",
            "model-00002-of-00003.safetensors:  92% 4.60G/5.00G [01:49<00:08, 47.8MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  92% 4.61G/5.00G [01:49<00:07, 52.0MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00003.safetensors:  98% 4.85G/4.94G [01:49<00:01, 46.0MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00003.safetensors:  98% 4.87G/4.94G [01:49<00:01, 46.9MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  58% 2.65G/4.54G [01:49<01:10, 26.8MB/s]\u001b[A\u001b[A\n",
            "model-00002-of-00003.safetensors:  92% 4.62G/5.00G [01:49<00:08, 42.2MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00003.safetensors:  99% 4.88G/4.94G [01:49<00:01, 47.0MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00002-of-00003.safetensors:  93% 4.63G/5.00G [01:50<00:07, 45.7MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00003.safetensors:  99% 4.89G/4.94G [01:50<00:01, 47.9MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  59% 2.66G/4.54G [01:50<01:12, 26.0MB/s]\u001b[A\u001b[A\n",
            "model-00002-of-00003.safetensors:  93% 4.65G/5.00G [01:50<00:07, 45.2MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00003.safetensors:  99% 4.90G/4.94G [01:50<00:00, 48.1MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00002-of-00003.safetensors:  93% 4.66G/5.00G [01:50<00:07, 48.9MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00003.safetensors:  99% 4.91G/4.94G [01:50<00:00, 48.4MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  59% 2.67G/4.54G [01:50<01:17, 24.2MB/s]\u001b[A\u001b[A\n",
            "model-00002-of-00003.safetensors:  93% 4.67G/5.00G [01:50<00:07, 47.5MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00003.safetensors:  99% 4.92G/4.94G [01:50<00:00, 48.5MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00002-of-00003.safetensors:  94% 4.68G/5.00G [01:50<00:06, 48.8MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00003.safetensors: 100% 4.93G/4.94G [01:50<00:00, 48.6MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00002-of-00003.safetensors:  94% 4.69G/5.00G [01:51<00:05, 54.4MB/s]\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  59% 2.68G/4.54G [01:51<01:19, 23.4MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00003.safetensors: 100% 4.94G/4.94G [01:51<00:00, 48.9MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00001-of-00003.safetensors: 100% 4.94G/4.94G [01:51<00:00, 44.4MB/s]\n",
            "Fetching 11 files:  45% 5/11 [01:52<02:23, 23.93s/it]\n",
            "model-00002-of-00003.safetensors:  94% 4.71G/5.00G [01:51<00:05, 50.4MB/s]\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  59% 2.69G/4.54G [01:51<01:20, 23.0MB/s]\u001b[A\u001b[A\n",
            "model-00002-of-00003.safetensors:  94% 4.72G/5.00G [01:51<00:05, 50.7MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  95% 4.73G/5.00G [01:52<00:06, 40.6MB/s]\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  60% 2.71G/4.54G [01:52<01:19, 23.0MB/s]\u001b[A\u001b[A\n",
            "model-00002-of-00003.safetensors:  95% 4.74G/5.00G [01:52<00:05, 46.5MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  95% 4.75G/5.00G [01:52<00:05, 49.6MB/s]\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  60% 2.72G/4.54G [01:52<01:19, 23.0MB/s]\u001b[A\u001b[A\n",
            "model-00002-of-00003.safetensors:  95% 4.76G/5.00G [01:52<00:05, 42.2MB/s]\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  60% 2.73G/4.54G [01:52<01:18, 23.2MB/s]\u001b[A\u001b[A\n",
            "model-00002-of-00003.safetensors:  95% 4.77G/5.00G [01:53<00:06, 33.6MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  96% 4.78G/5.00G [01:53<00:05, 38.5MB/s]\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  60% 2.74G/4.54G [01:53<01:17, 23.2MB/s]\u001b[A\u001b[A\n",
            "model-00002-of-00003.safetensors:  96% 4.79G/5.00G [01:53<00:05, 35.3MB/s]\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  61% 2.75G/4.54G [01:53<01:16, 23.5MB/s]\u001b[A\u001b[A\n",
            "model-00002-of-00003.safetensors:  96% 4.80G/5.00G [01:54<00:07, 28.0MB/s]\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  61% 2.76G/4.54G [01:54<01:15, 23.7MB/s]\u001b[A\u001b[A\n",
            "model-00002-of-00003.safetensors:  96% 4.81G/5.00G [01:54<00:05, 33.1MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  96% 4.82G/5.00G [01:54<00:04, 39.9MB/s]\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  61% 2.77G/4.54G [01:54<01:14, 23.6MB/s]\u001b[A\u001b[A\n",
            "model-00002-of-00003.safetensors:  97% 4.83G/5.00G [01:54<00:04, 40.5MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  97% 4.84G/5.00G [01:55<00:03, 44.4MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  97% 4.85G/5.00G [01:55<00:02, 50.5MB/s]\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  61% 2.78G/4.54G [01:55<01:14, 23.8MB/s]\u001b[A\u001b[A\n",
            "model-00002-of-00003.safetensors:  97% 4.87G/5.00G [01:55<00:02, 52.4MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  98% 4.88G/5.00G [01:55<00:02, 53.8MB/s]\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  61% 2.79G/4.54G [01:55<01:12, 24.1MB/s]\u001b[A\u001b[A\n",
            "model-00002-of-00003.safetensors:  98% 4.89G/5.00G [01:55<00:01, 58.7MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  98% 4.90G/5.00G [01:55<00:01, 58.2MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  98% 4.91G/5.00G [01:56<00:01, 58.1MB/s]\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  62% 2.80G/4.54G [01:56<01:12, 24.2MB/s]\u001b[A\u001b[A\n",
            "model-00002-of-00003.safetensors:  98% 4.92G/5.00G [01:56<00:01, 62.0MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  99% 4.93G/5.00G [01:56<00:01, 60.9MB/s]\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  62% 2.81G/4.54G [01:56<01:11, 24.1MB/s]\u001b[A\u001b[A\n",
            "model-00002-of-00003.safetensors:  99% 4.94G/5.00G [01:56<00:01, 60.3MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  99% 4.95G/5.00G [01:56<00:00, 63.0MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  99% 4.96G/5.00G [01:56<00:00, 61.6MB/s]\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  62% 2.82G/4.54G [01:56<01:11, 24.1MB/s]\u001b[A\u001b[A\n",
            "model-00002-of-00003.safetensors:  99% 4.97G/5.00G [01:57<00:00, 64.5MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors: 100% 4.98G/5.00G [01:57<00:00, 62.6MB/s]\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  62% 2.83G/4.54G [01:57<01:10, 24.2MB/s]\u001b[A\u001b[A\n",
            "model-00002-of-00003.safetensors: 100% 4.99G/5.00G [01:57<00:00, 61.2MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors: 100% 5.00G/5.00G [01:57<00:00, 42.5MB/s]\n",
            "Fetching 11 files:  55% 6/11 [01:58<01:38, 19.80s/it]\n",
            "\n",
            "model-00003-of-00003.safetensors:  63% 2.84G/4.54G [01:57<01:09, 24.3MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  63% 2.85G/4.54G [01:58<01:09, 24.3MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  63% 2.86G/4.54G [01:58<01:09, 24.2MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  63% 2.87G/4.54G [01:59<01:08, 24.2MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  64% 2.88G/4.54G [01:59<01:08, 24.3MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  64% 2.89G/4.54G [01:59<01:07, 24.3MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  64% 2.90G/4.54G [02:00<01:06, 24.4MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  64% 2.92G/4.54G [02:00<01:06, 24.3MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  64% 2.93G/4.54G [02:01<01:05, 24.6MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  65% 2.94G/4.54G [02:01<01:04, 24.8MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  65% 2.95G/4.54G [02:02<01:04, 24.9MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  65% 2.96G/4.54G [02:02<01:03, 24.9MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  65% 2.97G/4.54G [02:02<01:02, 25.1MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  66% 2.98G/4.54G [02:03<01:01, 25.4MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  66% 2.99G/4.54G [02:03<01:00, 25.8MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  66% 3.00G/4.54G [02:04<00:59, 26.1MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  66% 3.01G/4.54G [02:04<00:57, 26.4MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  67% 3.02G/4.54G [02:04<00:57, 26.6MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  67% 3.03G/4.54G [02:05<00:55, 27.3MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  67% 3.04G/4.54G [02:05<00:53, 27.8MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  67% 3.05G/4.54G [02:05<00:52, 28.3MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  67% 3.06G/4.54G [02:06<00:50, 29.2MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  68% 3.07G/4.54G [02:06<00:49, 29.6MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  68% 3.08G/4.54G [02:06<00:47, 30.6MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  68% 3.09G/4.54G [02:07<00:46, 31.0MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  68% 3.10G/4.54G [02:07<00:45, 31.9MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  69% 3.11G/4.54G [02:07<00:43, 32.7MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  69% 3.12G/4.54G [02:08<00:42, 33.4MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  69% 3.14G/4.54G [02:08<00:41, 34.2MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  69% 3.15G/4.54G [02:08<00:39, 35.4MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  70% 3.16G/4.54G [02:08<00:38, 36.1MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  70% 3.17G/4.54G [02:09<00:36, 37.3MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  70% 3.18G/4.54G [02:09<00:35, 38.1MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  70% 3.19G/4.54G [02:09<00:34, 39.0MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  70% 3.20G/4.54G [02:09<00:33, 40.3MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  71% 3.21G/4.54G [02:10<00:32, 41.3MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  71% 3.22G/4.54G [02:10<00:31, 42.1MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  71% 3.23G/4.54G [02:10<00:30, 43.3MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  71% 3.24G/4.54G [02:10<00:29, 44.4MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  72% 3.25G/4.54G [02:11<00:28, 45.5MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  72% 3.26G/4.54G [02:11<00:27, 46.4MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  72% 3.27G/4.54G [02:11<00:26, 47.5MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  72% 3.28G/4.54G [02:11<00:25, 49.1MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  73% 3.29G/4.54G [02:11<00:24, 50.0MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  73% 3.30G/4.54G [02:12<00:24, 50.6MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  73% 3.31G/4.54G [02:12<00:23, 52.3MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  73% 3.32G/4.54G [02:12<00:22, 53.6MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  73% 3.33G/4.54G [02:12<00:21, 54.9MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  74% 3.34G/4.54G [02:12<00:21, 56.1MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  74% 3.36G/4.54G [02:13<00:20, 57.0MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  74% 3.37G/4.54G [02:13<00:19, 59.1MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  74% 3.38G/4.54G [02:13<00:25, 46.1MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  75% 3.40G/4.54G [02:13<00:17, 65.6MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  75% 3.41G/4.54G [02:13<00:18, 62.2MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  75% 3.42G/4.54G [02:14<00:20, 53.8MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  76% 3.43G/4.54G [02:14<00:24, 44.9MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  76% 3.44G/4.54G [02:14<00:30, 36.6MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  76% 3.45G/4.54G [02:15<00:33, 32.3MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  76% 3.46G/4.54G [02:15<00:36, 29.8MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  76% 3.47G/4.54G [02:16<00:37, 28.3MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  77% 3.48G/4.54G [02:16<00:37, 28.2MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  77% 3.49G/4.54G [02:16<00:38, 27.4MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  77% 3.50G/4.54G [02:17<00:37, 27.6MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  77% 3.51G/4.54G [02:17<00:37, 27.2MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  78% 3.52G/4.54G [02:18<00:37, 27.5MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  78% 3.53G/4.54G [02:18<00:36, 27.8MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  78% 3.54G/4.54G [02:18<00:36, 27.7MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  78% 3.55G/4.54G [02:19<00:35, 27.8MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  79% 3.57G/4.54G [02:19<00:34, 28.1MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  79% 3.58G/4.54G [02:19<00:34, 28.2MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  79% 3.59G/4.54G [02:20<00:33, 28.4MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  79% 3.60G/4.54G [02:20<00:32, 28.6MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  79% 3.61G/4.54G [02:21<00:32, 28.8MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  80% 3.62G/4.54G [02:21<00:32, 28.2MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  80% 3.63G/4.54G [02:21<00:32, 28.2MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  80% 3.64G/4.54G [02:22<00:31, 28.5MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  80% 3.65G/4.54G [02:22<00:31, 28.7MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  81% 3.66G/4.54G [02:22<00:30, 28.8MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  81% 3.67G/4.54G [02:23<00:30, 28.9MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  81% 3.68G/4.54G [02:23<00:29, 28.8MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  81% 3.69G/4.54G [02:23<00:29, 28.9MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  82% 3.70G/4.54G [02:24<00:28, 29.0MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  82% 3.71G/4.54G [02:24<00:28, 28.7MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  82% 3.72G/4.54G [02:25<00:28, 29.1MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  82% 3.73G/4.54G [02:25<00:27, 29.1MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  82% 3.74G/4.54G [02:25<00:27, 29.1MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  83% 3.75G/4.54G [02:26<00:27, 28.7MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  83% 3.76G/4.54G [02:26<00:26, 29.1MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  83% 3.77G/4.54G [02:26<00:26, 29.3MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  83% 3.79G/4.54G [02:27<00:28, 26.3MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  84% 3.80G/4.54G [02:27<00:24, 30.3MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  84% 3.81G/4.54G [02:27<00:24, 30.2MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  84% 3.82G/4.54G [02:28<00:24, 30.1MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  84% 3.83G/4.54G [02:28<00:23, 30.0MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  85% 3.84G/4.54G [02:28<00:22, 30.7MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  85% 3.85G/4.54G [02:29<00:22, 30.7MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  85% 3.86G/4.54G [02:29<00:21, 31.4MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  85% 3.87G/4.54G [02:29<00:21, 31.2MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  85% 3.88G/4.54G [02:30<00:20, 32.0MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  86% 3.89G/4.54G [02:30<00:19, 32.6MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  86% 3.90G/4.54G [02:30<00:19, 32.7MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  86% 3.91G/4.54G [02:31<00:19, 33.0MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  86% 3.92G/4.54G [02:31<00:18, 33.7MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  87% 3.93G/4.54G [02:31<00:17, 34.7MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  87% 3.94G/4.54G [02:32<00:16, 35.2MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  87% 3.95G/4.54G [02:32<00:16, 35.5MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  87% 3.96G/4.54G [02:32<00:15, 36.3MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  88% 3.97G/4.54G [02:32<00:15, 37.2MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  88% 3.98G/4.54G [02:33<00:14, 37.8MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  88% 4.00G/4.54G [02:33<00:14, 38.3MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  88% 4.01G/4.54G [02:33<00:13, 39.5MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  88% 4.02G/4.54G [02:33<00:13, 39.9MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  89% 4.03G/4.54G [02:34<00:12, 41.4MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  89% 4.04G/4.54G [02:34<00:12, 41.9MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  89% 4.05G/4.54G [02:34<00:11, 42.9MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  89% 4.06G/4.54G [02:34<00:11, 43.4MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  90% 4.07G/4.54G [02:35<00:10, 45.0MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  90% 4.08G/4.54G [02:35<00:10, 46.1MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  90% 4.09G/4.54G [02:35<00:09, 46.1MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  90% 4.10G/4.54G [02:35<00:09, 48.2MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  91% 4.11G/4.54G [02:35<00:08, 47.8MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  91% 4.12G/4.54G [02:36<00:08, 49.8MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  91% 4.13G/4.54G [02:36<00:07, 51.4MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  91% 4.14G/4.54G [02:36<00:07, 51.5MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  91% 4.15G/4.54G [02:36<00:07, 51.8MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  92% 4.16G/4.54G [02:36<00:07, 53.2MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  92% 4.17G/4.54G [02:37<00:06, 54.4MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  92% 4.18G/4.54G [02:37<00:06, 55.6MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  92% 4.19G/4.54G [02:37<00:06, 56.8MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  93% 4.20G/4.54G [02:37<00:05, 57.6MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  93% 4.22G/4.54G [02:37<00:05, 60.6MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  93% 4.23G/4.54G [02:37<00:05, 61.5MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  93% 4.24G/4.54G [02:38<00:04, 61.2MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  94% 4.25G/4.54G [02:38<00:05, 54.0MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  94% 4.26G/4.54G [02:38<00:06, 42.4MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  94% 4.27G/4.54G [02:38<00:05, 49.2MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  94% 4.28G/4.54G [02:39<00:05, 46.8MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  94% 4.29G/4.54G [02:39<00:05, 50.3MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  95% 4.30G/4.54G [02:39<00:04, 57.0MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  95% 4.31G/4.54G [02:39<00:03, 61.1MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  95% 4.32G/4.54G [02:39<00:04, 54.0MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  95% 4.33G/4.54G [02:39<00:03, 59.3MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  96% 4.34G/4.54G [02:40<00:03, 52.7MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  96% 4.35G/4.54G [02:40<00:03, 49.3MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  96% 4.36G/4.54G [02:40<00:03, 47.4MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  96% 4.37G/4.54G [02:40<00:03, 47.1MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  97% 4.38G/4.54G [02:41<00:03, 50.9MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  97% 4.39G/4.54G [02:41<00:02, 53.6MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  97% 4.40G/4.54G [02:41<00:03, 41.0MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  97% 4.41G/4.54G [02:41<00:02, 47.2MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  97% 4.42G/4.54G [02:41<00:02, 49.9MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  98% 4.44G/4.54G [02:42<00:01, 57.5MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  98% 4.45G/4.54G [02:42<00:01, 63.3MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  98% 4.46G/4.54G [02:42<00:01, 49.6MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  98% 4.47G/4.54G [02:42<00:01, 53.2MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  99% 4.48G/4.54G [02:42<00:01, 54.8MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  99% 4.49G/4.54G [02:43<00:00, 55.1MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  99% 4.50G/4.54G [02:43<00:00, 49.9MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  99% 4.51G/4.54G [02:43<00:00, 52.5MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors: 100% 4.52G/4.54G [02:43<00:00, 46.6MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors: 100% 4.53G/4.54G [02:44<00:00, 33.1MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors: 100% 4.54G/4.54G [02:44<00:00, 27.6MB/s]\n",
            "Fetching 11 files: 100% 11/11 [02:45<00:00, 15.09s/it]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls -lash upshot-sih"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qT_C2ZpuISMI",
        "outputId": "bbb3c5e8-7039-44ff-f980-bb1fe9e3f79e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total 14G\n",
            "4.0K drwxr-xr-x 2 root root 4.0K Dec 14 23:10 .\n",
            "4.0K drwxr-xr-x 1 root root 4.0K Dec 14 23:10 ..\n",
            "4.0K -rw-r--r-- 1 root root   51 Dec 14 23:08 added_tokens.json\n",
            "4.0K -rw-r--r-- 1 root root  654 Dec 14 23:08 config.json\n",
            "4.0K -rw-r--r-- 1 root root  115 Dec 14 23:08 generation_config.json\n",
            "4.0K -rw-r--r-- 1 root root 1.5K Dec 14 23:08 .gitattributes\n",
            "4.7G -rw-r--r-- 1 root root 4.7G Dec 14 23:09 model-00001-of-00003.safetensors\n",
            "4.7G -rw-r--r-- 1 root root 4.7G Dec 14 23:10 model-00002-of-00003.safetensors\n",
            "4.3G -rw-r--r-- 1 root root 4.3G Dec 14 23:10 model-00003-of-00003.safetensors\n",
            " 24K -rw-r--r-- 1 root root  24K Dec 14 23:08 model.safetensors.index.json\n",
            "4.0K -rw-r--r-- 1 root root  449 Dec 14 23:08 special_tokens_map.json\n",
            "4.0K -rw-r--r-- 1 root root 1.6K Dec 14 23:08 tokenizer_config.json\n",
            "484K -rw-r--r-- 1 root root 482K Dec 14 23:08 tokenizer.model\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/ggerganov/llama.cpp.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uKZN8x3CI3vb",
        "outputId": "f1670dc9-ddee-4458-a8f5-54638d6ca8c5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'llama.cpp'...\n",
            "remote: Enumerating objects: 13832, done.\u001b[K\n",
            "remote: Counting objects: 100% (4325/4325), done.\u001b[K\n",
            "remote: Compressing objects: 100% (461/461), done.\u001b[K\n",
            "remote: Total 13832 (delta 4106), reused 3941 (delta 3864), pack-reused 9507\u001b[K\n",
            "Receiving objects: 100% (13832/13832), 15.93 MiB | 22.04 MiB/s, done.\n",
            "Resolving deltas: 100% (9651/9651), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls llama.cpp"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x15he_pGI9nU",
        "outputId": "d56e8893-19ed-4611-f4ba-8c208e675bd5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "build.zig\t\t       flake.nix\t    ggml-mpi.c\t     mypy.ini\n",
            "ci\t\t\t       ggml-alloc.c\t    ggml-mpi.h\t     Package.swift\n",
            "cmake\t\t\t       ggml-alloc.h\t    ggml-opencl.cpp  pocs\n",
            "CMakeLists.txt\t\t       ggml-backend.c\t    ggml-opencl.h    prompts\n",
            "codecov.yml\t\t       ggml-backend.h\t    ggml-quants.c    README.md\n",
            "common\t\t\t       ggml-backend-impl.h  ggml-quants.h    requirements-hf-to-gguf.txt\n",
            "convert-hf-to-gguf.py\t       ggml.c\t\t    gguf-py\t     requirements.txt\n",
            "convert-llama-ggml-to-gguf.py  ggml-cuda.cu\t    grammars\t     run_with_preset.py\n",
            "convert-lora-to-ggml.py        ggml-cuda.h\t    LICENSE\t     scripts\n",
            "convert-persimmon-to-gguf.py   ggml.h\t\t    llama.cpp\t     SHA256SUMS\n",
            "convert.py\t\t       ggml-impl.h\t    llama.h\t     spm-headers\n",
            "docs\t\t\t       ggml-metal.h\t    Makefile\t     tests\n",
            "examples\t\t       ggml-metal.m\t    media\t     unicode.h\n",
            "flake.lock\t\t       ggml-metal.metal     models\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -r llama.cpp/requirements.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 897
        },
        "id": "jGiOfxqBJB1F",
        "outputId": "5724b516-9524-4bcb-baac-1744aa5456f7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting numpy==1.24.4 (from -r llama.cpp/requirements.txt (line 1))\n",
            "  Downloading numpy-1.24.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.3/17.3 MB\u001b[0m \u001b[31m31.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting sentencepiece==0.1.98 (from -r llama.cpp/requirements.txt (line 2))\n",
            "  Downloading sentencepiece-0.1.98-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m58.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: transformers>=4.34.0 in /usr/local/lib/python3.10/dist-packages (from -r llama.cpp/requirements.txt (line 3)) (4.35.2)\n",
            "Collecting gguf>=0.1.0 (from -r llama.cpp/requirements.txt (line 4))\n",
            "  Downloading gguf-0.6.0-py3-none-any.whl (23 kB)\n",
            "Collecting protobuf>=4.21.0 (from -r llama.cpp/requirements.txt (line 5))\n",
            "  Downloading protobuf-4.25.1-cp37-abi3-manylinux2014_x86_64.whl (294 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m294.6/294.6 kB\u001b[0m \u001b[31m31.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers>=4.34.0->-r llama.cpp/requirements.txt (line 3)) (3.13.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.34.0->-r llama.cpp/requirements.txt (line 3)) (0.19.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.34.0->-r llama.cpp/requirements.txt (line 3)) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.34.0->-r llama.cpp/requirements.txt (line 3)) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.34.0->-r llama.cpp/requirements.txt (line 3)) (2023.6.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers>=4.34.0->-r llama.cpp/requirements.txt (line 3)) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.34.0->-r llama.cpp/requirements.txt (line 3)) (0.15.0)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.34.0->-r llama.cpp/requirements.txt (line 3)) (0.4.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.34.0->-r llama.cpp/requirements.txt (line 3)) (4.66.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers>=4.34.0->-r llama.cpp/requirements.txt (line 3)) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers>=4.34.0->-r llama.cpp/requirements.txt (line 3)) (4.5.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers>=4.34.0->-r llama.cpp/requirements.txt (line 3)) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers>=4.34.0->-r llama.cpp/requirements.txt (line 3)) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers>=4.34.0->-r llama.cpp/requirements.txt (line 3)) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers>=4.34.0->-r llama.cpp/requirements.txt (line 3)) (2023.11.17)\n",
            "Installing collected packages: sentencepiece, protobuf, numpy, gguf\n",
            "  Attempting uninstall: protobuf\n",
            "    Found existing installation: protobuf 3.20.3\n",
            "    Uninstalling protobuf-3.20.3:\n",
            "      Successfully uninstalled protobuf-3.20.3\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.23.5\n",
            "    Uninstalling numpy-1.23.5:\n",
            "      Successfully uninstalled numpy-1.23.5\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "lida 0.0.10 requires fastapi, which is not installed.\n",
            "lida 0.0.10 requires kaleido, which is not installed.\n",
            "lida 0.0.10 requires python-multipart, which is not installed.\n",
            "lida 0.0.10 requires uvicorn, which is not installed.\n",
            "tensorboard 2.15.1 requires protobuf<4.24,>=3.19.6, but you have protobuf 4.25.1 which is incompatible.\n",
            "tensorflow-metadata 1.14.0 requires protobuf<4.21,>=3.20.3, but you have protobuf 4.25.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed gguf-0.6.0 numpy-1.24.4 protobuf-4.25.1 sentencepiece-0.1.98\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "numpy"
                ]
              }
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python llama.cpp/convert.py -h"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-UVLDNGZJHN1",
        "outputId": "d14fa398-c9ef-4a7c-9ad6-b95aebbc0316"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "usage: convert.py [-h] [--dump] [--dump-single] [--vocab-only] [--outtype {f32,f16,q8_0}]\n",
            "                  [--vocab-dir VOCAB_DIR] [--outfile OUTFILE] [--vocabtype {spm,bpe}] [--ctx CTX]\n",
            "                  [--concurrency CONCURRENCY] [--bigendian]\n",
            "                  model\n",
            "\n",
            "Convert a LLaMa model to a GGML compatible file\n",
            "\n",
            "positional arguments:\n",
            "  model                 directory containing model file, or model file itself (*.pth, *.pt, *.bin,\n",
            "                        *.safetensors)\n",
            "\n",
            "options:\n",
            "  -h, --help            show this help message and exit\n",
            "  --dump                don't convert, just show what's in the model\n",
            "  --dump-single         don't convert, just show what's in a single model file\n",
            "  --vocab-only          extract only the vocab\n",
            "  --outtype {f32,f16,q8_0}\n",
            "                        output format - note: q8_0 may be very slow (default: f16 or f32 based on\n",
            "                        input)\n",
            "  --vocab-dir VOCAB_DIR\n",
            "                        directory containing tokenizer.model, if separate from model file\n",
            "  --outfile OUTFILE     path to write to; default: based on input\n",
            "  --vocabtype {spm,bpe}\n",
            "                        vocab format (default: spm)\n",
            "  --ctx CTX             model training context (default: based on input)\n",
            "  --concurrency CONCURRENCY\n",
            "                        concurrency used for conversion (default: 8)\n",
            "  --bigendian           model is executed on big endian machine\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python llama.cpp/convert.py upshot-sih \\\n",
        "  --outfile upshot-sih-7b-v2.0.gguf \\\n",
        "  --outtype q8_0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SH9JMhuRJM2u",
        "outputId": "afd3545d-eb60-4b09-ce24-08fb5832a498"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading model file upshot-sih/model-00001-of-00003.safetensors\n",
            "Loading model file upshot-sih/model-00001-of-00003.safetensors\n",
            "Loading model file upshot-sih/model-00002-of-00003.safetensors\n",
            "Loading model file upshot-sih/model-00003-of-00003.safetensors\n",
            "params = Params(n_vocab=32002, n_embd=4096, n_layer=32, n_ctx=32768, n_ff=14336, n_head=32, n_head_kv=8, n_experts=None, n_experts_used=None, f_norm_eps=1e-05, rope_scaling_type=None, f_rope_freq_base=10000.0, f_rope_scale=None, n_orig_ctx=None, rope_finetuned=None, ftype=<GGMLFileType.MostlyQ8_0: 7>, path_model=PosixPath('upshot-sih'))\n",
            "The cache for model files in Transformers v4.22.0 has been updated. Migrating your old cache. This is a one-time only operation. You can interrupt this and resume the migration later on by calling `transformers.utils.move_cache()`.\n",
            "0it [00:00, ?it/s]\n",
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
            "32000 32000\n",
            "Vocab info: <VocabLoader with 32000 base tokens and 2 added tokens>\n",
            "Special vocab info: <SpecialVocab with 0 merges, special tokens {'bos': 1, 'eos': 32000}, add special tokens {'bos': True, 'eos': False}>\n",
            "Permuting layer 0\n",
            "Permuting layer 1\n",
            "Permuting layer 2\n",
            "Permuting layer 3\n",
            "Permuting layer 4\n",
            "Permuting layer 5\n",
            "Permuting layer 6\n",
            "Permuting layer 7\n",
            "Permuting layer 8\n",
            "Permuting layer 9\n",
            "Permuting layer 10\n",
            "Permuting layer 11\n",
            "Permuting layer 12\n",
            "Permuting layer 13\n",
            "Permuting layer 14\n",
            "Permuting layer 15\n",
            "Permuting layer 16\n",
            "Permuting layer 17\n",
            "Permuting layer 18\n",
            "Permuting layer 19\n",
            "Permuting layer 20\n",
            "Permuting layer 21\n",
            "Permuting layer 22\n",
            "Permuting layer 23\n",
            "Permuting layer 24\n",
            "Permuting layer 25\n",
            "Permuting layer 26\n",
            "Permuting layer 27\n",
            "Permuting layer 28\n",
            "Permuting layer 29\n",
            "Permuting layer 30\n",
            "Permuting layer 31\n",
            "model.embed_tokens.weight                        -> token_embd.weight                        | F16    | [32002, 4096]\n",
            "model.layers.0.input_layernorm.weight            -> blk.0.attn_norm.weight                   | F16    | [4096]\n",
            "model.layers.0.mlp.down_proj.weight              -> blk.0.ffn_down.weight                    | F16    | [4096, 14336]\n",
            "model.layers.0.mlp.gate_proj.weight              -> blk.0.ffn_gate.weight                    | F16    | [14336, 4096]\n",
            "model.layers.0.mlp.up_proj.weight                -> blk.0.ffn_up.weight                      | F16    | [14336, 4096]\n",
            "model.layers.0.post_attention_layernorm.weight   -> blk.0.ffn_norm.weight                    | F16    | [4096]\n",
            "model.layers.0.self_attn.k_proj.weight           -> blk.0.attn_k.weight                      | F16    | [1024, 4096]\n",
            "model.layers.0.self_attn.o_proj.weight           -> blk.0.attn_output.weight                 | F16    | [4096, 4096]\n",
            "model.layers.0.self_attn.q_proj.weight           -> blk.0.attn_q.weight                      | F16    | [4096, 4096]\n",
            "model.layers.0.self_attn.v_proj.weight           -> blk.0.attn_v.weight                      | F16    | [1024, 4096]\n",
            "model.layers.1.input_layernorm.weight            -> blk.1.attn_norm.weight                   | F16    | [4096]\n",
            "model.layers.1.mlp.down_proj.weight              -> blk.1.ffn_down.weight                    | F16    | [4096, 14336]\n",
            "model.layers.1.mlp.gate_proj.weight              -> blk.1.ffn_gate.weight                    | F16    | [14336, 4096]\n",
            "model.layers.1.mlp.up_proj.weight                -> blk.1.ffn_up.weight                      | F16    | [14336, 4096]\n",
            "model.layers.1.post_attention_layernorm.weight   -> blk.1.ffn_norm.weight                    | F16    | [4096]\n",
            "model.layers.1.self_attn.k_proj.weight           -> blk.1.attn_k.weight                      | F16    | [1024, 4096]\n",
            "model.layers.1.self_attn.o_proj.weight           -> blk.1.attn_output.weight                 | F16    | [4096, 4096]\n",
            "model.layers.1.self_attn.q_proj.weight           -> blk.1.attn_q.weight                      | F16    | [4096, 4096]\n",
            "model.layers.1.self_attn.v_proj.weight           -> blk.1.attn_v.weight                      | F16    | [1024, 4096]\n",
            "model.layers.10.mlp.gate_proj.weight             -> blk.10.ffn_gate.weight                   | F16    | [14336, 4096]\n",
            "model.layers.10.mlp.up_proj.weight               -> blk.10.ffn_up.weight                     | F16    | [14336, 4096]\n",
            "model.layers.10.self_attn.k_proj.weight          -> blk.10.attn_k.weight                     | F16    | [1024, 4096]\n",
            "model.layers.10.self_attn.o_proj.weight          -> blk.10.attn_output.weight                | F16    | [4096, 4096]\n",
            "model.layers.10.self_attn.q_proj.weight          -> blk.10.attn_q.weight                     | F16    | [4096, 4096]\n",
            "model.layers.10.self_attn.v_proj.weight          -> blk.10.attn_v.weight                     | F16    | [1024, 4096]\n",
            "model.layers.2.input_layernorm.weight            -> blk.2.attn_norm.weight                   | F16    | [4096]\n",
            "model.layers.2.mlp.down_proj.weight              -> blk.2.ffn_down.weight                    | F16    | [4096, 14336]\n",
            "model.layers.2.mlp.gate_proj.weight              -> blk.2.ffn_gate.weight                    | F16    | [14336, 4096]\n",
            "model.layers.2.mlp.up_proj.weight                -> blk.2.ffn_up.weight                      | F16    | [14336, 4096]\n",
            "model.layers.2.post_attention_layernorm.weight   -> blk.2.ffn_norm.weight                    | F16    | [4096]\n",
            "model.layers.2.self_attn.k_proj.weight           -> blk.2.attn_k.weight                      | F16    | [1024, 4096]\n",
            "model.layers.2.self_attn.o_proj.weight           -> blk.2.attn_output.weight                 | F16    | [4096, 4096]\n",
            "model.layers.2.self_attn.q_proj.weight           -> blk.2.attn_q.weight                      | F16    | [4096, 4096]\n",
            "model.layers.2.self_attn.v_proj.weight           -> blk.2.attn_v.weight                      | F16    | [1024, 4096]\n",
            "model.layers.3.input_layernorm.weight            -> blk.3.attn_norm.weight                   | F16    | [4096]\n",
            "model.layers.3.mlp.down_proj.weight              -> blk.3.ffn_down.weight                    | F16    | [4096, 14336]\n",
            "model.layers.3.mlp.gate_proj.weight              -> blk.3.ffn_gate.weight                    | F16    | [14336, 4096]\n",
            "model.layers.3.mlp.up_proj.weight                -> blk.3.ffn_up.weight                      | F16    | [14336, 4096]\n",
            "model.layers.3.post_attention_layernorm.weight   -> blk.3.ffn_norm.weight                    | F16    | [4096]\n",
            "model.layers.3.self_attn.k_proj.weight           -> blk.3.attn_k.weight                      | F16    | [1024, 4096]\n",
            "model.layers.3.self_attn.o_proj.weight           -> blk.3.attn_output.weight                 | F16    | [4096, 4096]\n",
            "model.layers.3.self_attn.q_proj.weight           -> blk.3.attn_q.weight                      | F16    | [4096, 4096]\n",
            "model.layers.3.self_attn.v_proj.weight           -> blk.3.attn_v.weight                      | F16    | [1024, 4096]\n",
            "model.layers.4.input_layernorm.weight            -> blk.4.attn_norm.weight                   | F16    | [4096]\n",
            "model.layers.4.mlp.down_proj.weight              -> blk.4.ffn_down.weight                    | F16    | [4096, 14336]\n",
            "model.layers.4.mlp.gate_proj.weight              -> blk.4.ffn_gate.weight                    | F16    | [14336, 4096]\n",
            "model.layers.4.mlp.up_proj.weight                -> blk.4.ffn_up.weight                      | F16    | [14336, 4096]\n",
            "model.layers.4.post_attention_layernorm.weight   -> blk.4.ffn_norm.weight                    | F16    | [4096]\n",
            "model.layers.4.self_attn.k_proj.weight           -> blk.4.attn_k.weight                      | F16    | [1024, 4096]\n",
            "model.layers.4.self_attn.o_proj.weight           -> blk.4.attn_output.weight                 | F16    | [4096, 4096]\n",
            "model.layers.4.self_attn.q_proj.weight           -> blk.4.attn_q.weight                      | F16    | [4096, 4096]\n",
            "model.layers.4.self_attn.v_proj.weight           -> blk.4.attn_v.weight                      | F16    | [1024, 4096]\n",
            "model.layers.5.input_layernorm.weight            -> blk.5.attn_norm.weight                   | F16    | [4096]\n",
            "model.layers.5.mlp.down_proj.weight              -> blk.5.ffn_down.weight                    | F16    | [4096, 14336]\n",
            "model.layers.5.mlp.gate_proj.weight              -> blk.5.ffn_gate.weight                    | F16    | [14336, 4096]\n",
            "model.layers.5.mlp.up_proj.weight                -> blk.5.ffn_up.weight                      | F16    | [14336, 4096]\n",
            "model.layers.5.post_attention_layernorm.weight   -> blk.5.ffn_norm.weight                    | F16    | [4096]\n",
            "model.layers.5.self_attn.k_proj.weight           -> blk.5.attn_k.weight                      | F16    | [1024, 4096]\n",
            "model.layers.5.self_attn.o_proj.weight           -> blk.5.attn_output.weight                 | F16    | [4096, 4096]\n",
            "model.layers.5.self_attn.q_proj.weight           -> blk.5.attn_q.weight                      | F16    | [4096, 4096]\n",
            "model.layers.5.self_attn.v_proj.weight           -> blk.5.attn_v.weight                      | F16    | [1024, 4096]\n",
            "model.layers.6.input_layernorm.weight            -> blk.6.attn_norm.weight                   | F16    | [4096]\n",
            "model.layers.6.mlp.down_proj.weight              -> blk.6.ffn_down.weight                    | F16    | [4096, 14336]\n",
            "model.layers.6.mlp.gate_proj.weight              -> blk.6.ffn_gate.weight                    | F16    | [14336, 4096]\n",
            "model.layers.6.mlp.up_proj.weight                -> blk.6.ffn_up.weight                      | F16    | [14336, 4096]\n",
            "model.layers.6.post_attention_layernorm.weight   -> blk.6.ffn_norm.weight                    | F16    | [4096]\n",
            "model.layers.6.self_attn.k_proj.weight           -> blk.6.attn_k.weight                      | F16    | [1024, 4096]\n",
            "model.layers.6.self_attn.o_proj.weight           -> blk.6.attn_output.weight                 | F16    | [4096, 4096]\n",
            "model.layers.6.self_attn.q_proj.weight           -> blk.6.attn_q.weight                      | F16    | [4096, 4096]\n",
            "model.layers.6.self_attn.v_proj.weight           -> blk.6.attn_v.weight                      | F16    | [1024, 4096]\n",
            "model.layers.7.input_layernorm.weight            -> blk.7.attn_norm.weight                   | F16    | [4096]\n",
            "model.layers.7.mlp.down_proj.weight              -> blk.7.ffn_down.weight                    | F16    | [4096, 14336]\n",
            "model.layers.7.mlp.gate_proj.weight              -> blk.7.ffn_gate.weight                    | F16    | [14336, 4096]\n",
            "model.layers.7.mlp.up_proj.weight                -> blk.7.ffn_up.weight                      | F16    | [14336, 4096]\n",
            "model.layers.7.post_attention_layernorm.weight   -> blk.7.ffn_norm.weight                    | F16    | [4096]\n",
            "model.layers.7.self_attn.k_proj.weight           -> blk.7.attn_k.weight                      | F16    | [1024, 4096]\n",
            "model.layers.7.self_attn.o_proj.weight           -> blk.7.attn_output.weight                 | F16    | [4096, 4096]\n",
            "model.layers.7.self_attn.q_proj.weight           -> blk.7.attn_q.weight                      | F16    | [4096, 4096]\n",
            "model.layers.7.self_attn.v_proj.weight           -> blk.7.attn_v.weight                      | F16    | [1024, 4096]\n",
            "model.layers.8.input_layernorm.weight            -> blk.8.attn_norm.weight                   | F16    | [4096]\n",
            "model.layers.8.mlp.down_proj.weight              -> blk.8.ffn_down.weight                    | F16    | [4096, 14336]\n",
            "model.layers.8.mlp.gate_proj.weight              -> blk.8.ffn_gate.weight                    | F16    | [14336, 4096]\n",
            "model.layers.8.mlp.up_proj.weight                -> blk.8.ffn_up.weight                      | F16    | [14336, 4096]\n",
            "model.layers.8.post_attention_layernorm.weight   -> blk.8.ffn_norm.weight                    | F16    | [4096]\n",
            "model.layers.8.self_attn.k_proj.weight           -> blk.8.attn_k.weight                      | F16    | [1024, 4096]\n",
            "model.layers.8.self_attn.o_proj.weight           -> blk.8.attn_output.weight                 | F16    | [4096, 4096]\n",
            "model.layers.8.self_attn.q_proj.weight           -> blk.8.attn_q.weight                      | F16    | [4096, 4096]\n",
            "model.layers.8.self_attn.v_proj.weight           -> blk.8.attn_v.weight                      | F16    | [1024, 4096]\n",
            "model.layers.9.input_layernorm.weight            -> blk.9.attn_norm.weight                   | F16    | [4096]\n",
            "model.layers.9.mlp.down_proj.weight              -> blk.9.ffn_down.weight                    | F16    | [4096, 14336]\n",
            "model.layers.9.mlp.gate_proj.weight              -> blk.9.ffn_gate.weight                    | F16    | [14336, 4096]\n",
            "model.layers.9.mlp.up_proj.weight                -> blk.9.ffn_up.weight                      | F16    | [14336, 4096]\n",
            "model.layers.9.post_attention_layernorm.weight   -> blk.9.ffn_norm.weight                    | F16    | [4096]\n",
            "model.layers.9.self_attn.k_proj.weight           -> blk.9.attn_k.weight                      | F16    | [1024, 4096]\n",
            "model.layers.9.self_attn.o_proj.weight           -> blk.9.attn_output.weight                 | F16    | [4096, 4096]\n",
            "model.layers.9.self_attn.q_proj.weight           -> blk.9.attn_q.weight                      | F16    | [4096, 4096]\n",
            "model.layers.9.self_attn.v_proj.weight           -> blk.9.attn_v.weight                      | F16    | [1024, 4096]\n",
            "model.layers.10.input_layernorm.weight           -> blk.10.attn_norm.weight                  | F16    | [4096]\n",
            "model.layers.10.mlp.down_proj.weight             -> blk.10.ffn_down.weight                   | F16    | [4096, 14336]\n",
            "model.layers.10.post_attention_layernorm.weight  -> blk.10.ffn_norm.weight                   | F16    | [4096]\n",
            "model.layers.11.input_layernorm.weight           -> blk.11.attn_norm.weight                  | F16    | [4096]\n",
            "model.layers.11.mlp.down_proj.weight             -> blk.11.ffn_down.weight                   | F16    | [4096, 14336]\n",
            "model.layers.11.mlp.gate_proj.weight             -> blk.11.ffn_gate.weight                   | F16    | [14336, 4096]\n",
            "model.layers.11.mlp.up_proj.weight               -> blk.11.ffn_up.weight                     | F16    | [14336, 4096]\n",
            "model.layers.11.post_attention_layernorm.weight  -> blk.11.ffn_norm.weight                   | F16    | [4096]\n",
            "model.layers.11.self_attn.k_proj.weight          -> blk.11.attn_k.weight                     | F16    | [1024, 4096]\n",
            "model.layers.11.self_attn.o_proj.weight          -> blk.11.attn_output.weight                | F16    | [4096, 4096]\n",
            "model.layers.11.self_attn.q_proj.weight          -> blk.11.attn_q.weight                     | F16    | [4096, 4096]\n",
            "model.layers.11.self_attn.v_proj.weight          -> blk.11.attn_v.weight                     | F16    | [1024, 4096]\n",
            "model.layers.12.input_layernorm.weight           -> blk.12.attn_norm.weight                  | F16    | [4096]\n",
            "model.layers.12.mlp.down_proj.weight             -> blk.12.ffn_down.weight                   | F16    | [4096, 14336]\n",
            "model.layers.12.mlp.gate_proj.weight             -> blk.12.ffn_gate.weight                   | F16    | [14336, 4096]\n",
            "model.layers.12.mlp.up_proj.weight               -> blk.12.ffn_up.weight                     | F16    | [14336, 4096]\n",
            "model.layers.12.post_attention_layernorm.weight  -> blk.12.ffn_norm.weight                   | F16    | [4096]\n",
            "model.layers.12.self_attn.k_proj.weight          -> blk.12.attn_k.weight                     | F16    | [1024, 4096]\n",
            "model.layers.12.self_attn.o_proj.weight          -> blk.12.attn_output.weight                | F16    | [4096, 4096]\n",
            "model.layers.12.self_attn.q_proj.weight          -> blk.12.attn_q.weight                     | F16    | [4096, 4096]\n",
            "model.layers.12.self_attn.v_proj.weight          -> blk.12.attn_v.weight                     | F16    | [1024, 4096]\n",
            "model.layers.13.input_layernorm.weight           -> blk.13.attn_norm.weight                  | F16    | [4096]\n",
            "model.layers.13.mlp.down_proj.weight             -> blk.13.ffn_down.weight                   | F16    | [4096, 14336]\n",
            "model.layers.13.mlp.gate_proj.weight             -> blk.13.ffn_gate.weight                   | F16    | [14336, 4096]\n",
            "model.layers.13.mlp.up_proj.weight               -> blk.13.ffn_up.weight                     | F16    | [14336, 4096]\n",
            "model.layers.13.post_attention_layernorm.weight  -> blk.13.ffn_norm.weight                   | F16    | [4096]\n",
            "model.layers.13.self_attn.k_proj.weight          -> blk.13.attn_k.weight                     | F16    | [1024, 4096]\n",
            "model.layers.13.self_attn.o_proj.weight          -> blk.13.attn_output.weight                | F16    | [4096, 4096]\n",
            "model.layers.13.self_attn.q_proj.weight          -> blk.13.attn_q.weight                     | F16    | [4096, 4096]\n",
            "model.layers.13.self_attn.v_proj.weight          -> blk.13.attn_v.weight                     | F16    | [1024, 4096]\n",
            "model.layers.14.input_layernorm.weight           -> blk.14.attn_norm.weight                  | F16    | [4096]\n",
            "model.layers.14.mlp.down_proj.weight             -> blk.14.ffn_down.weight                   | F16    | [4096, 14336]\n",
            "model.layers.14.mlp.gate_proj.weight             -> blk.14.ffn_gate.weight                   | F16    | [14336, 4096]\n",
            "model.layers.14.mlp.up_proj.weight               -> blk.14.ffn_up.weight                     | F16    | [14336, 4096]\n",
            "model.layers.14.post_attention_layernorm.weight  -> blk.14.ffn_norm.weight                   | F16    | [4096]\n",
            "model.layers.14.self_attn.k_proj.weight          -> blk.14.attn_k.weight                     | F16    | [1024, 4096]\n",
            "model.layers.14.self_attn.o_proj.weight          -> blk.14.attn_output.weight                | F16    | [4096, 4096]\n",
            "model.layers.14.self_attn.q_proj.weight          -> blk.14.attn_q.weight                     | F16    | [4096, 4096]\n",
            "model.layers.14.self_attn.v_proj.weight          -> blk.14.attn_v.weight                     | F16    | [1024, 4096]\n",
            "model.layers.15.input_layernorm.weight           -> blk.15.attn_norm.weight                  | F16    | [4096]\n",
            "model.layers.15.mlp.down_proj.weight             -> blk.15.ffn_down.weight                   | F16    | [4096, 14336]\n",
            "model.layers.15.mlp.gate_proj.weight             -> blk.15.ffn_gate.weight                   | F16    | [14336, 4096]\n",
            "model.layers.15.mlp.up_proj.weight               -> blk.15.ffn_up.weight                     | F16    | [14336, 4096]\n",
            "model.layers.15.post_attention_layernorm.weight  -> blk.15.ffn_norm.weight                   | F16    | [4096]\n",
            "model.layers.15.self_attn.k_proj.weight          -> blk.15.attn_k.weight                     | F16    | [1024, 4096]\n",
            "model.layers.15.self_attn.o_proj.weight          -> blk.15.attn_output.weight                | F16    | [4096, 4096]\n",
            "model.layers.15.self_attn.q_proj.weight          -> blk.15.attn_q.weight                     | F16    | [4096, 4096]\n",
            "model.layers.15.self_attn.v_proj.weight          -> blk.15.attn_v.weight                     | F16    | [1024, 4096]\n",
            "model.layers.16.input_layernorm.weight           -> blk.16.attn_norm.weight                  | F16    | [4096]\n",
            "model.layers.16.mlp.down_proj.weight             -> blk.16.ffn_down.weight                   | F16    | [4096, 14336]\n",
            "model.layers.16.mlp.gate_proj.weight             -> blk.16.ffn_gate.weight                   | F16    | [14336, 4096]\n",
            "model.layers.16.mlp.up_proj.weight               -> blk.16.ffn_up.weight                     | F16    | [14336, 4096]\n",
            "model.layers.16.post_attention_layernorm.weight  -> blk.16.ffn_norm.weight                   | F16    | [4096]\n",
            "model.layers.16.self_attn.k_proj.weight          -> blk.16.attn_k.weight                     | F16    | [1024, 4096]\n",
            "model.layers.16.self_attn.o_proj.weight          -> blk.16.attn_output.weight                | F16    | [4096, 4096]\n",
            "model.layers.16.self_attn.q_proj.weight          -> blk.16.attn_q.weight                     | F16    | [4096, 4096]\n",
            "model.layers.16.self_attn.v_proj.weight          -> blk.16.attn_v.weight                     | F16    | [1024, 4096]\n",
            "model.layers.17.input_layernorm.weight           -> blk.17.attn_norm.weight                  | F16    | [4096]\n",
            "model.layers.17.mlp.down_proj.weight             -> blk.17.ffn_down.weight                   | F16    | [4096, 14336]\n",
            "model.layers.17.mlp.gate_proj.weight             -> blk.17.ffn_gate.weight                   | F16    | [14336, 4096]\n",
            "model.layers.17.mlp.up_proj.weight               -> blk.17.ffn_up.weight                     | F16    | [14336, 4096]\n",
            "model.layers.17.post_attention_layernorm.weight  -> blk.17.ffn_norm.weight                   | F16    | [4096]\n",
            "model.layers.17.self_attn.k_proj.weight          -> blk.17.attn_k.weight                     | F16    | [1024, 4096]\n",
            "model.layers.17.self_attn.o_proj.weight          -> blk.17.attn_output.weight                | F16    | [4096, 4096]\n",
            "model.layers.17.self_attn.q_proj.weight          -> blk.17.attn_q.weight                     | F16    | [4096, 4096]\n",
            "model.layers.17.self_attn.v_proj.weight          -> blk.17.attn_v.weight                     | F16    | [1024, 4096]\n",
            "model.layers.18.input_layernorm.weight           -> blk.18.attn_norm.weight                  | F16    | [4096]\n",
            "model.layers.18.mlp.down_proj.weight             -> blk.18.ffn_down.weight                   | F16    | [4096, 14336]\n",
            "model.layers.18.mlp.gate_proj.weight             -> blk.18.ffn_gate.weight                   | F16    | [14336, 4096]\n",
            "model.layers.18.mlp.up_proj.weight               -> blk.18.ffn_up.weight                     | F16    | [14336, 4096]\n",
            "model.layers.18.post_attention_layernorm.weight  -> blk.18.ffn_norm.weight                   | F16    | [4096]\n",
            "model.layers.18.self_attn.k_proj.weight          -> blk.18.attn_k.weight                     | F16    | [1024, 4096]\n",
            "model.layers.18.self_attn.o_proj.weight          -> blk.18.attn_output.weight                | F16    | [4096, 4096]\n",
            "model.layers.18.self_attn.q_proj.weight          -> blk.18.attn_q.weight                     | F16    | [4096, 4096]\n",
            "model.layers.18.self_attn.v_proj.weight          -> blk.18.attn_v.weight                     | F16    | [1024, 4096]\n",
            "model.layers.19.input_layernorm.weight           -> blk.19.attn_norm.weight                  | F16    | [4096]\n",
            "model.layers.19.mlp.down_proj.weight             -> blk.19.ffn_down.weight                   | F16    | [4096, 14336]\n",
            "model.layers.19.mlp.gate_proj.weight             -> blk.19.ffn_gate.weight                   | F16    | [14336, 4096]\n",
            "model.layers.19.mlp.up_proj.weight               -> blk.19.ffn_up.weight                     | F16    | [14336, 4096]\n",
            "model.layers.19.post_attention_layernorm.weight  -> blk.19.ffn_norm.weight                   | F16    | [4096]\n",
            "model.layers.19.self_attn.k_proj.weight          -> blk.19.attn_k.weight                     | F16    | [1024, 4096]\n",
            "model.layers.19.self_attn.o_proj.weight          -> blk.19.attn_output.weight                | F16    | [4096, 4096]\n",
            "model.layers.19.self_attn.q_proj.weight          -> blk.19.attn_q.weight                     | F16    | [4096, 4096]\n",
            "model.layers.19.self_attn.v_proj.weight          -> blk.19.attn_v.weight                     | F16    | [1024, 4096]\n",
            "model.layers.20.input_layernorm.weight           -> blk.20.attn_norm.weight                  | F16    | [4096]\n",
            "model.layers.20.mlp.down_proj.weight             -> blk.20.ffn_down.weight                   | F16    | [4096, 14336]\n",
            "model.layers.20.mlp.gate_proj.weight             -> blk.20.ffn_gate.weight                   | F16    | [14336, 4096]\n",
            "model.layers.20.mlp.up_proj.weight               -> blk.20.ffn_up.weight                     | F16    | [14336, 4096]\n",
            "model.layers.20.post_attention_layernorm.weight  -> blk.20.ffn_norm.weight                   | F16    | [4096]\n",
            "model.layers.20.self_attn.k_proj.weight          -> blk.20.attn_k.weight                     | F16    | [1024, 4096]\n",
            "model.layers.20.self_attn.o_proj.weight          -> blk.20.attn_output.weight                | F16    | [4096, 4096]\n",
            "model.layers.20.self_attn.q_proj.weight          -> blk.20.attn_q.weight                     | F16    | [4096, 4096]\n",
            "model.layers.20.self_attn.v_proj.weight          -> blk.20.attn_v.weight                     | F16    | [1024, 4096]\n",
            "model.layers.21.input_layernorm.weight           -> blk.21.attn_norm.weight                  | F16    | [4096]\n",
            "model.layers.21.mlp.down_proj.weight             -> blk.21.ffn_down.weight                   | F16    | [4096, 14336]\n",
            "model.layers.21.mlp.gate_proj.weight             -> blk.21.ffn_gate.weight                   | F16    | [14336, 4096]\n",
            "model.layers.21.mlp.up_proj.weight               -> blk.21.ffn_up.weight                     | F16    | [14336, 4096]\n",
            "model.layers.21.post_attention_layernorm.weight  -> blk.21.ffn_norm.weight                   | F16    | [4096]\n",
            "model.layers.21.self_attn.k_proj.weight          -> blk.21.attn_k.weight                     | F16    | [1024, 4096]\n",
            "model.layers.21.self_attn.o_proj.weight          -> blk.21.attn_output.weight                | F16    | [4096, 4096]\n",
            "model.layers.21.self_attn.q_proj.weight          -> blk.21.attn_q.weight                     | F16    | [4096, 4096]\n",
            "model.layers.21.self_attn.v_proj.weight          -> blk.21.attn_v.weight                     | F16    | [1024, 4096]\n",
            "model.layers.22.self_attn.k_proj.weight          -> blk.22.attn_k.weight                     | F16    | [1024, 4096]\n",
            "model.layers.22.self_attn.o_proj.weight          -> blk.22.attn_output.weight                | F16    | [4096, 4096]\n",
            "model.layers.22.self_attn.q_proj.weight          -> blk.22.attn_q.weight                     | F16    | [4096, 4096]\n",
            "model.layers.22.self_attn.v_proj.weight          -> blk.22.attn_v.weight                     | F16    | [1024, 4096]\n",
            "lm_head.weight                                   -> output.weight                            | F16    | [32002, 4096]\n",
            "model.layers.22.input_layernorm.weight           -> blk.22.attn_norm.weight                  | F16    | [4096]\n",
            "model.layers.22.mlp.down_proj.weight             -> blk.22.ffn_down.weight                   | F16    | [4096, 14336]\n",
            "model.layers.22.mlp.gate_proj.weight             -> blk.22.ffn_gate.weight                   | F16    | [14336, 4096]\n",
            "model.layers.22.mlp.up_proj.weight               -> blk.22.ffn_up.weight                     | F16    | [14336, 4096]\n",
            "model.layers.22.post_attention_layernorm.weight  -> blk.22.ffn_norm.weight                   | F16    | [4096]\n",
            "model.layers.23.input_layernorm.weight           -> blk.23.attn_norm.weight                  | F16    | [4096]\n",
            "model.layers.23.mlp.down_proj.weight             -> blk.23.ffn_down.weight                   | F16    | [4096, 14336]\n",
            "model.layers.23.mlp.gate_proj.weight             -> blk.23.ffn_gate.weight                   | F16    | [14336, 4096]\n",
            "model.layers.23.mlp.up_proj.weight               -> blk.23.ffn_up.weight                     | F16    | [14336, 4096]\n",
            "model.layers.23.post_attention_layernorm.weight  -> blk.23.ffn_norm.weight                   | F16    | [4096]\n",
            "model.layers.23.self_attn.k_proj.weight          -> blk.23.attn_k.weight                     | F16    | [1024, 4096]\n",
            "model.layers.23.self_attn.o_proj.weight          -> blk.23.attn_output.weight                | F16    | [4096, 4096]\n",
            "model.layers.23.self_attn.q_proj.weight          -> blk.23.attn_q.weight                     | F16    | [4096, 4096]\n",
            "model.layers.23.self_attn.v_proj.weight          -> blk.23.attn_v.weight                     | F16    | [1024, 4096]\n",
            "model.layers.24.input_layernorm.weight           -> blk.24.attn_norm.weight                  | F16    | [4096]\n",
            "model.layers.24.mlp.down_proj.weight             -> blk.24.ffn_down.weight                   | F16    | [4096, 14336]\n",
            "model.layers.24.mlp.gate_proj.weight             -> blk.24.ffn_gate.weight                   | F16    | [14336, 4096]\n",
            "model.layers.24.mlp.up_proj.weight               -> blk.24.ffn_up.weight                     | F16    | [14336, 4096]\n",
            "model.layers.24.post_attention_layernorm.weight  -> blk.24.ffn_norm.weight                   | F16    | [4096]\n",
            "model.layers.24.self_attn.k_proj.weight          -> blk.24.attn_k.weight                     | F16    | [1024, 4096]\n",
            "model.layers.24.self_attn.o_proj.weight          -> blk.24.attn_output.weight                | F16    | [4096, 4096]\n",
            "model.layers.24.self_attn.q_proj.weight          -> blk.24.attn_q.weight                     | F16    | [4096, 4096]\n",
            "model.layers.24.self_attn.v_proj.weight          -> blk.24.attn_v.weight                     | F16    | [1024, 4096]\n",
            "model.layers.25.input_layernorm.weight           -> blk.25.attn_norm.weight                  | F16    | [4096]\n",
            "model.layers.25.mlp.down_proj.weight             -> blk.25.ffn_down.weight                   | F16    | [4096, 14336]\n",
            "model.layers.25.mlp.gate_proj.weight             -> blk.25.ffn_gate.weight                   | F16    | [14336, 4096]\n",
            "model.layers.25.mlp.up_proj.weight               -> blk.25.ffn_up.weight                     | F16    | [14336, 4096]\n",
            "model.layers.25.post_attention_layernorm.weight  -> blk.25.ffn_norm.weight                   | F16    | [4096]\n",
            "model.layers.25.self_attn.k_proj.weight          -> blk.25.attn_k.weight                     | F16    | [1024, 4096]\n",
            "model.layers.25.self_attn.o_proj.weight          -> blk.25.attn_output.weight                | F16    | [4096, 4096]\n",
            "model.layers.25.self_attn.q_proj.weight          -> blk.25.attn_q.weight                     | F16    | [4096, 4096]\n",
            "model.layers.25.self_attn.v_proj.weight          -> blk.25.attn_v.weight                     | F16    | [1024, 4096]\n",
            "model.layers.26.input_layernorm.weight           -> blk.26.attn_norm.weight                  | F16    | [4096]\n",
            "model.layers.26.mlp.down_proj.weight             -> blk.26.ffn_down.weight                   | F16    | [4096, 14336]\n",
            "model.layers.26.mlp.gate_proj.weight             -> blk.26.ffn_gate.weight                   | F16    | [14336, 4096]\n",
            "model.layers.26.mlp.up_proj.weight               -> blk.26.ffn_up.weight                     | F16    | [14336, 4096]\n",
            "model.layers.26.post_attention_layernorm.weight  -> blk.26.ffn_norm.weight                   | F16    | [4096]\n",
            "model.layers.26.self_attn.k_proj.weight          -> blk.26.attn_k.weight                     | F16    | [1024, 4096]\n",
            "model.layers.26.self_attn.o_proj.weight          -> blk.26.attn_output.weight                | F16    | [4096, 4096]\n",
            "model.layers.26.self_attn.q_proj.weight          -> blk.26.attn_q.weight                     | F16    | [4096, 4096]\n",
            "model.layers.26.self_attn.v_proj.weight          -> blk.26.attn_v.weight                     | F16    | [1024, 4096]\n",
            "model.layers.27.input_layernorm.weight           -> blk.27.attn_norm.weight                  | F16    | [4096]\n",
            "model.layers.27.mlp.down_proj.weight             -> blk.27.ffn_down.weight                   | F16    | [4096, 14336]\n",
            "model.layers.27.mlp.gate_proj.weight             -> blk.27.ffn_gate.weight                   | F16    | [14336, 4096]\n",
            "model.layers.27.mlp.up_proj.weight               -> blk.27.ffn_up.weight                     | F16    | [14336, 4096]\n",
            "model.layers.27.post_attention_layernorm.weight  -> blk.27.ffn_norm.weight                   | F16    | [4096]\n",
            "model.layers.27.self_attn.k_proj.weight          -> blk.27.attn_k.weight                     | F16    | [1024, 4096]\n",
            "model.layers.27.self_attn.o_proj.weight          -> blk.27.attn_output.weight                | F16    | [4096, 4096]\n",
            "model.layers.27.self_attn.q_proj.weight          -> blk.27.attn_q.weight                     | F16    | [4096, 4096]\n",
            "model.layers.27.self_attn.v_proj.weight          -> blk.27.attn_v.weight                     | F16    | [1024, 4096]\n",
            "model.layers.28.input_layernorm.weight           -> blk.28.attn_norm.weight                  | F16    | [4096]\n",
            "model.layers.28.mlp.down_proj.weight             -> blk.28.ffn_down.weight                   | F16    | [4096, 14336]\n",
            "model.layers.28.mlp.gate_proj.weight             -> blk.28.ffn_gate.weight                   | F16    | [14336, 4096]\n",
            "model.layers.28.mlp.up_proj.weight               -> blk.28.ffn_up.weight                     | F16    | [14336, 4096]\n",
            "model.layers.28.post_attention_layernorm.weight  -> blk.28.ffn_norm.weight                   | F16    | [4096]\n",
            "model.layers.28.self_attn.k_proj.weight          -> blk.28.attn_k.weight                     | F16    | [1024, 4096]\n",
            "model.layers.28.self_attn.o_proj.weight          -> blk.28.attn_output.weight                | F16    | [4096, 4096]\n",
            "model.layers.28.self_attn.q_proj.weight          -> blk.28.attn_q.weight                     | F16    | [4096, 4096]\n",
            "model.layers.28.self_attn.v_proj.weight          -> blk.28.attn_v.weight                     | F16    | [1024, 4096]\n",
            "model.layers.29.input_layernorm.weight           -> blk.29.attn_norm.weight                  | F16    | [4096]\n",
            "model.layers.29.mlp.down_proj.weight             -> blk.29.ffn_down.weight                   | F16    | [4096, 14336]\n",
            "model.layers.29.mlp.gate_proj.weight             -> blk.29.ffn_gate.weight                   | F16    | [14336, 4096]\n",
            "model.layers.29.mlp.up_proj.weight               -> blk.29.ffn_up.weight                     | F16    | [14336, 4096]\n",
            "model.layers.29.post_attention_layernorm.weight  -> blk.29.ffn_norm.weight                   | F16    | [4096]\n",
            "model.layers.29.self_attn.k_proj.weight          -> blk.29.attn_k.weight                     | F16    | [1024, 4096]\n",
            "model.layers.29.self_attn.o_proj.weight          -> blk.29.attn_output.weight                | F16    | [4096, 4096]\n",
            "model.layers.29.self_attn.q_proj.weight          -> blk.29.attn_q.weight                     | F16    | [4096, 4096]\n",
            "model.layers.29.self_attn.v_proj.weight          -> blk.29.attn_v.weight                     | F16    | [1024, 4096]\n",
            "model.layers.30.input_layernorm.weight           -> blk.30.attn_norm.weight                  | F16    | [4096]\n",
            "model.layers.30.mlp.down_proj.weight             -> blk.30.ffn_down.weight                   | F16    | [4096, 14336]\n",
            "model.layers.30.mlp.gate_proj.weight             -> blk.30.ffn_gate.weight                   | F16    | [14336, 4096]\n",
            "model.layers.30.mlp.up_proj.weight               -> blk.30.ffn_up.weight                     | F16    | [14336, 4096]\n",
            "model.layers.30.post_attention_layernorm.weight  -> blk.30.ffn_norm.weight                   | F16    | [4096]\n",
            "model.layers.30.self_attn.k_proj.weight          -> blk.30.attn_k.weight                     | F16    | [1024, 4096]\n",
            "model.layers.30.self_attn.o_proj.weight          -> blk.30.attn_output.weight                | F16    | [4096, 4096]\n",
            "model.layers.30.self_attn.q_proj.weight          -> blk.30.attn_q.weight                     | F16    | [4096, 4096]\n",
            "model.layers.30.self_attn.v_proj.weight          -> blk.30.attn_v.weight                     | F16    | [1024, 4096]\n",
            "model.layers.31.input_layernorm.weight           -> blk.31.attn_norm.weight                  | F16    | [4096]\n",
            "model.layers.31.mlp.down_proj.weight             -> blk.31.ffn_down.weight                   | F16    | [4096, 14336]\n",
            "model.layers.31.mlp.gate_proj.weight             -> blk.31.ffn_gate.weight                   | F16    | [14336, 4096]\n",
            "model.layers.31.mlp.up_proj.weight               -> blk.31.ffn_up.weight                     | F16    | [14336, 4096]\n",
            "model.layers.31.post_attention_layernorm.weight  -> blk.31.ffn_norm.weight                   | F16    | [4096]\n",
            "model.layers.31.self_attn.k_proj.weight          -> blk.31.attn_k.weight                     | F16    | [1024, 4096]\n",
            "model.layers.31.self_attn.o_proj.weight          -> blk.31.attn_output.weight                | F16    | [4096, 4096]\n",
            "model.layers.31.self_attn.q_proj.weight          -> blk.31.attn_q.weight                     | F16    | [4096, 4096]\n",
            "model.layers.31.self_attn.v_proj.weight          -> blk.31.attn_v.weight                     | F16    | [1024, 4096]\n",
            "model.norm.weight                                -> output_norm.weight                       | F16    | [4096]\n",
            "Writing upshot-sih-7b-v2.0.gguf, format 7\n",
            "gguf: This GGUF file is for Little Endian only\n",
            "gguf: WARNING: Adding merges requested but no merges found, output may be non-functional.\n",
            "gguf: Setting special token type bos to 1\n",
            "gguf: Setting special token type eos to 32000\n",
            "gguf: Setting add_bos_token to True\n",
            "gguf: Setting add_eos_token to False\n",
            "gguf: Setting chat_template to {% for message in messages %}{{'<|im_start|>' + message['role'] + '\n",
            "' + message['content'] + '<|im_end|>' + '\n",
            "'}}{% endfor %}{% if add_generation_prompt %}{{ '<|im_start|>assistant\n",
            "' }}{% endif %}\n",
            "/content/llama.cpp/convert.py:100: RuntimeWarning: invalid value encountered in divide\n",
            "  qs = (blocks / d[:, None]).round()\n",
            "[  1/291] Writing tensor token_embd.weight                      | size  32002 x   4096  | type Q8_0 | T+  27\n",
            "[  2/291] Writing tensor blk.0.attn_norm.weight                 | size   4096           | type F32  | T+  27\n",
            "[  3/291] Writing tensor blk.0.ffn_down.weight                  | size   4096 x  14336  | type Q8_0 | T+  27\n",
            "[  4/291] Writing tensor blk.0.ffn_gate.weight                  | size  14336 x   4096  | type Q8_0 | T+  27\n",
            "[  5/291] Writing tensor blk.0.ffn_up.weight                    | size  14336 x   4096  | type Q8_0 | T+  28\n",
            "[  6/291] Writing tensor blk.0.ffn_norm.weight                  | size   4096           | type F32  | T+  30\n",
            "[  7/291] Writing tensor blk.0.attn_k.weight                    | size   1024 x   4096  | type Q8_0 | T+  30\n",
            "[  8/291] Writing tensor blk.0.attn_output.weight               | size   4096 x   4096  | type Q8_0 | T+  30\n",
            "[  9/291] Writing tensor blk.0.attn_q.weight                    | size   4096 x   4096  | type Q8_0 | T+  32\n",
            "[ 10/291] Writing tensor blk.0.attn_v.weight                    | size   1024 x   4096  | type Q8_0 | T+  32\n",
            "[ 11/291] Writing tensor blk.1.attn_norm.weight                 | size   4096           | type F32  | T+  32\n",
            "[ 12/291] Writing tensor blk.1.ffn_down.weight                  | size   4096 x  14336  | type Q8_0 | T+  40\n",
            "[ 13/291] Writing tensor blk.1.ffn_gate.weight                  | size  14336 x   4096  | type Q8_0 | T+  44\n",
            "[ 14/291] Writing tensor blk.1.ffn_up.weight                    | size  14336 x   4096  | type Q8_0 | T+  47\n",
            "[ 15/291] Writing tensor blk.1.ffn_norm.weight                  | size   4096           | type F32  | T+  47\n",
            "[ 16/291] Writing tensor blk.1.attn_k.weight                    | size   1024 x   4096  | type Q8_0 | T+  47\n",
            "[ 17/291] Writing tensor blk.1.attn_output.weight               | size   4096 x   4096  | type Q8_0 | T+  47\n",
            "[ 18/291] Writing tensor blk.1.attn_q.weight                    | size   4096 x   4096  | type Q8_0 | T+  47\n",
            "[ 19/291] Writing tensor blk.1.attn_v.weight                    | size   1024 x   4096  | type Q8_0 | T+  47\n",
            "[ 20/291] Writing tensor blk.10.ffn_gate.weight                 | size  14336 x   4096  | type Q8_0 | T+  53\n",
            "[ 21/291] Writing tensor blk.10.ffn_up.weight                   | size  14336 x   4096  | type Q8_0 | T+  57\n",
            "[ 22/291] Writing tensor blk.10.attn_k.weight                   | size   1024 x   4096  | type Q8_0 | T+  59\n",
            "[ 23/291] Writing tensor blk.10.attn_output.weight              | size   4096 x   4096  | type Q8_0 | T+  59\n",
            "[ 24/291] Writing tensor blk.10.attn_q.weight                   | size   4096 x   4096  | type Q8_0 | T+  59\n",
            "[ 25/291] Writing tensor blk.10.attn_v.weight                   | size   1024 x   4096  | type Q8_0 | T+  59\n",
            "[ 26/291] Writing tensor blk.2.attn_norm.weight                 | size   4096           | type F32  | T+  59\n",
            "[ 27/291] Writing tensor blk.2.ffn_down.weight                  | size   4096 x  14336  | type Q8_0 | T+  63\n",
            "[ 28/291] Writing tensor blk.2.ffn_gate.weight                  | size  14336 x   4096  | type Q8_0 | T+  66\n",
            "[ 29/291] Writing tensor blk.2.ffn_up.weight                    | size  14336 x   4096  | type Q8_0 | T+  68\n",
            "[ 30/291] Writing tensor blk.2.ffn_norm.weight                  | size   4096           | type F32  | T+  69\n",
            "[ 31/291] Writing tensor blk.2.attn_k.weight                    | size   1024 x   4096  | type Q8_0 | T+  69\n",
            "[ 32/291] Writing tensor blk.2.attn_output.weight               | size   4096 x   4096  | type Q8_0 | T+  69\n",
            "[ 33/291] Writing tensor blk.2.attn_q.weight                    | size   4096 x   4096  | type Q8_0 | T+  69\n",
            "[ 34/291] Writing tensor blk.2.attn_v.weight                    | size   1024 x   4096  | type Q8_0 | T+  70\n",
            "[ 35/291] Writing tensor blk.3.attn_norm.weight                 | size   4096           | type F32  | T+  70\n",
            "[ 36/291] Writing tensor blk.3.ffn_down.weight                  | size   4096 x  14336  | type Q8_0 | T+  76\n",
            "[ 37/291] Writing tensor blk.3.ffn_gate.weight                  | size  14336 x   4096  | type Q8_0 | T+  81\n",
            "[ 38/291] Writing tensor blk.3.ffn_up.weight                    | size  14336 x   4096  | type Q8_0 | T+  81\n",
            "[ 39/291] Writing tensor blk.3.ffn_norm.weight                  | size   4096           | type F32  | T+  82\n",
            "[ 40/291] Writing tensor blk.3.attn_k.weight                    | size   1024 x   4096  | type Q8_0 | T+  82\n",
            "[ 41/291] Writing tensor blk.3.attn_output.weight               | size   4096 x   4096  | type Q8_0 | T+  82\n",
            "[ 42/291] Writing tensor blk.3.attn_q.weight                    | size   4096 x   4096  | type Q8_0 | T+  82\n",
            "[ 43/291] Writing tensor blk.3.attn_v.weight                    | size   1024 x   4096  | type Q8_0 | T+  82\n",
            "[ 44/291] Writing tensor blk.4.attn_norm.weight                 | size   4096           | type F32  | T+  82\n",
            "[ 45/291] Writing tensor blk.4.ffn_down.weight                  | size   4096 x  14336  | type Q8_0 | T+  94\n",
            "[ 46/291] Writing tensor blk.4.ffn_gate.weight                  | size  14336 x   4096  | type Q8_0 | T+  95\n",
            "[ 47/291] Writing tensor blk.4.ffn_up.weight                    | size  14336 x   4096  | type Q8_0 | T+  96\n",
            "[ 48/291] Writing tensor blk.4.ffn_norm.weight                  | size   4096           | type F32  | T+  96\n",
            "[ 49/291] Writing tensor blk.4.attn_k.weight                    | size   1024 x   4096  | type Q8_0 | T+  96\n",
            "[ 50/291] Writing tensor blk.4.attn_output.weight               | size   4096 x   4096  | type Q8_0 | T+  96\n",
            "[ 51/291] Writing tensor blk.4.attn_q.weight                    | size   4096 x   4096  | type Q8_0 | T+  96\n",
            "[ 52/291] Writing tensor blk.4.attn_v.weight                    | size   1024 x   4096  | type Q8_0 | T+  96\n",
            "[ 53/291] Writing tensor blk.5.attn_norm.weight                 | size   4096           | type F32  | T+  96\n",
            "[ 54/291] Writing tensor blk.5.ffn_down.weight                  | size   4096 x  14336  | type Q8_0 | T+ 109\n",
            "[ 55/291] Writing tensor blk.5.ffn_gate.weight                  | size  14336 x   4096  | type Q8_0 | T+ 109\n",
            "[ 56/291] Writing tensor blk.5.ffn_up.weight                    | size  14336 x   4096  | type Q8_0 | T+ 110\n",
            "[ 57/291] Writing tensor blk.5.ffn_norm.weight                  | size   4096           | type F32  | T+ 111\n",
            "[ 58/291] Writing tensor blk.5.attn_k.weight                    | size   1024 x   4096  | type Q8_0 | T+ 111\n",
            "[ 59/291] Writing tensor blk.5.attn_output.weight               | size   4096 x   4096  | type Q8_0 | T+ 111\n",
            "[ 60/291] Writing tensor blk.5.attn_q.weight                    | size   4096 x   4096  | type Q8_0 | T+ 111\n",
            "[ 61/291] Writing tensor blk.5.attn_v.weight                    | size   1024 x   4096  | type Q8_0 | T+ 111\n",
            "[ 62/291] Writing tensor blk.6.attn_norm.weight                 | size   4096           | type F32  | T+ 111\n",
            "[ 63/291] Writing tensor blk.6.ffn_down.weight                  | size   4096 x  14336  | type Q8_0 | T+ 120\n",
            "[ 64/291] Writing tensor blk.6.ffn_gate.weight                  | size  14336 x   4096  | type Q8_0 | T+ 124\n",
            "[ 65/291] Writing tensor blk.6.ffn_up.weight                    | size  14336 x   4096  | type Q8_0 | T+ 125\n",
            "[ 66/291] Writing tensor blk.6.ffn_norm.weight                  | size   4096           | type F32  | T+ 125\n",
            "[ 67/291] Writing tensor blk.6.attn_k.weight                    | size   1024 x   4096  | type Q8_0 | T+ 125\n",
            "[ 68/291] Writing tensor blk.6.attn_output.weight               | size   4096 x   4096  | type Q8_0 | T+ 125\n",
            "[ 69/291] Writing tensor blk.6.attn_q.weight                    | size   4096 x   4096  | type Q8_0 | T+ 125\n",
            "[ 70/291] Writing tensor blk.6.attn_v.weight                    | size   1024 x   4096  | type Q8_0 | T+ 125\n",
            "[ 71/291] Writing tensor blk.7.attn_norm.weight                 | size   4096           | type F32  | T+ 125\n",
            "[ 72/291] Writing tensor blk.7.ffn_down.weight                  | size   4096 x  14336  | type Q8_0 | T+ 135\n",
            "[ 73/291] Writing tensor blk.7.ffn_gate.weight                  | size  14336 x   4096  | type Q8_0 | T+ 138\n",
            "[ 74/291] Writing tensor blk.7.ffn_up.weight                    | size  14336 x   4096  | type Q8_0 | T+ 139\n",
            "[ 75/291] Writing tensor blk.7.ffn_norm.weight                  | size   4096           | type F32  | T+ 140\n",
            "[ 76/291] Writing tensor blk.7.attn_k.weight                    | size   1024 x   4096  | type Q8_0 | T+ 140\n",
            "[ 77/291] Writing tensor blk.7.attn_output.weight               | size   4096 x   4096  | type Q8_0 | T+ 140\n",
            "[ 78/291] Writing tensor blk.7.attn_q.weight                    | size   4096 x   4096  | type Q8_0 | T+ 140\n",
            "[ 79/291] Writing tensor blk.7.attn_v.weight                    | size   1024 x   4096  | type Q8_0 | T+ 140\n",
            "[ 80/291] Writing tensor blk.8.attn_norm.weight                 | size   4096           | type F32  | T+ 140\n",
            "[ 81/291] Writing tensor blk.8.ffn_down.weight                  | size   4096 x  14336  | type Q8_0 | T+ 149\n",
            "[ 82/291] Writing tensor blk.8.ffn_gate.weight                  | size  14336 x   4096  | type Q8_0 | T+ 152\n",
            "[ 83/291] Writing tensor blk.8.ffn_up.weight                    | size  14336 x   4096  | type Q8_0 | T+ 153\n",
            "[ 84/291] Writing tensor blk.8.ffn_norm.weight                  | size   4096           | type F32  | T+ 153\n",
            "[ 85/291] Writing tensor blk.8.attn_k.weight                    | size   1024 x   4096  | type Q8_0 | T+ 153\n",
            "[ 86/291] Writing tensor blk.8.attn_output.weight               | size   4096 x   4096  | type Q8_0 | T+ 154\n",
            "[ 87/291] Writing tensor blk.8.attn_q.weight                    | size   4096 x   4096  | type Q8_0 | T+ 154\n",
            "[ 88/291] Writing tensor blk.8.attn_v.weight                    | size   1024 x   4096  | type Q8_0 | T+ 154\n",
            "[ 89/291] Writing tensor blk.9.attn_norm.weight                 | size   4096           | type F32  | T+ 154\n",
            "[ 90/291] Writing tensor blk.9.ffn_down.weight                  | size   4096 x  14336  | type Q8_0 | T+ 163\n",
            "[ 91/291] Writing tensor blk.9.ffn_gate.weight                  | size  14336 x   4096  | type Q8_0 | T+ 166\n",
            "[ 92/291] Writing tensor blk.9.ffn_up.weight                    | size  14336 x   4096  | type Q8_0 | T+ 167\n",
            "[ 93/291] Writing tensor blk.9.ffn_norm.weight                  | size   4096           | type F32  | T+ 167\n",
            "[ 94/291] Writing tensor blk.9.attn_k.weight                    | size   1024 x   4096  | type Q8_0 | T+ 167\n",
            "[ 95/291] Writing tensor blk.9.attn_output.weight               | size   4096 x   4096  | type Q8_0 | T+ 167\n",
            "[ 96/291] Writing tensor blk.9.attn_q.weight                    | size   4096 x   4096  | type Q8_0 | T+ 167\n",
            "[ 97/291] Writing tensor blk.9.attn_v.weight                    | size   1024 x   4096  | type Q8_0 | T+ 167\n",
            "[ 98/291] Writing tensor blk.10.attn_norm.weight                | size   4096           | type F32  | T+ 167\n",
            "[ 99/291] Writing tensor blk.10.ffn_down.weight                 | size   4096 x  14336  | type Q8_0 | T+ 177\n",
            "[100/291] Writing tensor blk.10.ffn_norm.weight                 | size   4096           | type F32  | T+ 177\n",
            "[101/291] Writing tensor blk.11.attn_norm.weight                | size   4096           | type F32  | T+ 177\n",
            "[102/291] Writing tensor blk.11.ffn_down.weight                 | size   4096 x  14336  | type Q8_0 | T+ 182\n",
            "[103/291] Writing tensor blk.11.ffn_gate.weight                 | size  14336 x   4096  | type Q8_0 | T+ 184\n",
            "[104/291] Writing tensor blk.11.ffn_up.weight                   | size  14336 x   4096  | type Q8_0 | T+ 185\n",
            "[105/291] Writing tensor blk.11.ffn_norm.weight                 | size   4096           | type F32  | T+ 185\n",
            "[106/291] Writing tensor blk.11.attn_k.weight                   | size   1024 x   4096  | type Q8_0 | T+ 185\n",
            "[107/291] Writing tensor blk.11.attn_output.weight              | size   4096 x   4096  | type Q8_0 | T+ 185\n",
            "[108/291] Writing tensor blk.11.attn_q.weight                   | size   4096 x   4096  | type Q8_0 | T+ 185\n",
            "[109/291] Writing tensor blk.11.attn_v.weight                   | size   1024 x   4096  | type Q8_0 | T+ 185\n",
            "[110/291] Writing tensor blk.12.attn_norm.weight                | size   4096           | type F32  | T+ 185\n",
            "[111/291] Writing tensor blk.12.ffn_down.weight                 | size   4096 x  14336  | type Q8_0 | T+ 196\n",
            "[112/291] Writing tensor blk.12.ffn_gate.weight                 | size  14336 x   4096  | type Q8_0 | T+ 197\n",
            "[113/291] Writing tensor blk.12.ffn_up.weight                   | size  14336 x   4096  | type Q8_0 | T+ 199\n",
            "[114/291] Writing tensor blk.12.ffn_norm.weight                 | size   4096           | type F32  | T+ 199\n",
            "[115/291] Writing tensor blk.12.attn_k.weight                   | size   1024 x   4096  | type Q8_0 | T+ 199\n",
            "[116/291] Writing tensor blk.12.attn_output.weight              | size   4096 x   4096  | type Q8_0 | T+ 200\n",
            "[117/291] Writing tensor blk.12.attn_q.weight                   | size   4096 x   4096  | type Q8_0 | T+ 200\n",
            "[118/291] Writing tensor blk.12.attn_v.weight                   | size   1024 x   4096  | type Q8_0 | T+ 200\n",
            "[119/291] Writing tensor blk.13.attn_norm.weight                | size   4096           | type F32  | T+ 200\n",
            "[120/291] Writing tensor blk.13.ffn_down.weight                 | size   4096 x  14336  | type Q8_0 | T+ 208\n",
            "[121/291] Writing tensor blk.13.ffn_gate.weight                 | size  14336 x   4096  | type Q8_0 | T+ 210\n",
            "[122/291] Writing tensor blk.13.ffn_up.weight                   | size  14336 x   4096  | type Q8_0 | T+ 212\n",
            "[123/291] Writing tensor blk.13.ffn_norm.weight                 | size   4096           | type F32  | T+ 212\n",
            "[124/291] Writing tensor blk.13.attn_k.weight                   | size   1024 x   4096  | type Q8_0 | T+ 212\n",
            "[125/291] Writing tensor blk.13.attn_output.weight              | size   4096 x   4096  | type Q8_0 | T+ 212\n",
            "[126/291] Writing tensor blk.13.attn_q.weight                   | size   4096 x   4096  | type Q8_0 | T+ 212\n",
            "[127/291] Writing tensor blk.13.attn_v.weight                   | size   1024 x   4096  | type Q8_0 | T+ 212\n",
            "[128/291] Writing tensor blk.14.attn_norm.weight                | size   4096           | type F32  | T+ 212\n",
            "[129/291] Writing tensor blk.14.ffn_down.weight                 | size   4096 x  14336  | type Q8_0 | T+ 223\n",
            "[130/291] Writing tensor blk.14.ffn_gate.weight                 | size  14336 x   4096  | type Q8_0 | T+ 224\n",
            "[131/291] Writing tensor blk.14.ffn_up.weight                   | size  14336 x   4096  | type Q8_0 | T+ 225\n",
            "[132/291] Writing tensor blk.14.ffn_norm.weight                 | size   4096           | type F32  | T+ 226\n",
            "[133/291] Writing tensor blk.14.attn_k.weight                   | size   1024 x   4096  | type Q8_0 | T+ 226\n",
            "[134/291] Writing tensor blk.14.attn_output.weight              | size   4096 x   4096  | type Q8_0 | T+ 226\n",
            "[135/291] Writing tensor blk.14.attn_q.weight                   | size   4096 x   4096  | type Q8_0 | T+ 226\n",
            "[136/291] Writing tensor blk.14.attn_v.weight                   | size   1024 x   4096  | type Q8_0 | T+ 226\n",
            "[137/291] Writing tensor blk.15.attn_norm.weight                | size   4096           | type F32  | T+ 226\n",
            "[138/291] Writing tensor blk.15.ffn_down.weight                 | size   4096 x  14336  | type Q8_0 | T+ 237\n",
            "[139/291] Writing tensor blk.15.ffn_gate.weight                 | size  14336 x   4096  | type Q8_0 | T+ 238\n",
            "[140/291] Writing tensor blk.15.ffn_up.weight                   | size  14336 x   4096  | type Q8_0 | T+ 239\n",
            "[141/291] Writing tensor blk.15.ffn_norm.weight                 | size   4096           | type F32  | T+ 239\n",
            "[142/291] Writing tensor blk.15.attn_k.weight                   | size   1024 x   4096  | type Q8_0 | T+ 239\n",
            "[143/291] Writing tensor blk.15.attn_output.weight              | size   4096 x   4096  | type Q8_0 | T+ 239\n",
            "[144/291] Writing tensor blk.15.attn_q.weight                   | size   4096 x   4096  | type Q8_0 | T+ 239\n",
            "[145/291] Writing tensor blk.15.attn_v.weight                   | size   1024 x   4096  | type Q8_0 | T+ 240\n",
            "[146/291] Writing tensor blk.16.attn_norm.weight                | size   4096           | type F32  | T+ 240\n",
            "[147/291] Writing tensor blk.16.ffn_down.weight                 | size   4096 x  14336  | type Q8_0 | T+ 251\n",
            "[148/291] Writing tensor blk.16.ffn_gate.weight                 | size  14336 x   4096  | type Q8_0 | T+ 252\n",
            "[149/291] Writing tensor blk.16.ffn_up.weight                   | size  14336 x   4096  | type Q8_0 | T+ 253\n",
            "[150/291] Writing tensor blk.16.ffn_norm.weight                 | size   4096           | type F32  | T+ 253\n",
            "[151/291] Writing tensor blk.16.attn_k.weight                   | size   1024 x   4096  | type Q8_0 | T+ 253\n",
            "[152/291] Writing tensor blk.16.attn_output.weight              | size   4096 x   4096  | type Q8_0 | T+ 253\n",
            "[153/291] Writing tensor blk.16.attn_q.weight                   | size   4096 x   4096  | type Q8_0 | T+ 253\n",
            "[154/291] Writing tensor blk.16.attn_v.weight                   | size   1024 x   4096  | type Q8_0 | T+ 254\n",
            "[155/291] Writing tensor blk.17.attn_norm.weight                | size   4096           | type F32  | T+ 254\n",
            "[156/291] Writing tensor blk.17.ffn_down.weight                 | size   4096 x  14336  | type Q8_0 | T+ 265\n",
            "[157/291] Writing tensor blk.17.ffn_gate.weight                 | size  14336 x   4096  | type Q8_0 | T+ 266\n",
            "[158/291] Writing tensor blk.17.ffn_up.weight                   | size  14336 x   4096  | type Q8_0 | T+ 267\n",
            "[159/291] Writing tensor blk.17.ffn_norm.weight                 | size   4096           | type F32  | T+ 267\n",
            "[160/291] Writing tensor blk.17.attn_k.weight                   | size   1024 x   4096  | type Q8_0 | T+ 267\n",
            "[161/291] Writing tensor blk.17.attn_output.weight              | size   4096 x   4096  | type Q8_0 | T+ 267\n",
            "[162/291] Writing tensor blk.17.attn_q.weight                   | size   4096 x   4096  | type Q8_0 | T+ 267\n",
            "[163/291] Writing tensor blk.17.attn_v.weight                   | size   1024 x   4096  | type Q8_0 | T+ 267\n",
            "[164/291] Writing tensor blk.18.attn_norm.weight                | size   4096           | type F32  | T+ 267\n",
            "[165/291] Writing tensor blk.18.ffn_down.weight                 | size   4096 x  14336  | type Q8_0 | T+ 279\n",
            "[166/291] Writing tensor blk.18.ffn_gate.weight                 | size  14336 x   4096  | type Q8_0 | T+ 280\n",
            "[167/291] Writing tensor blk.18.ffn_up.weight                   | size  14336 x   4096  | type Q8_0 | T+ 281\n",
            "[168/291] Writing tensor blk.18.ffn_norm.weight                 | size   4096           | type F32  | T+ 282\n",
            "[169/291] Writing tensor blk.18.attn_k.weight                   | size   1024 x   4096  | type Q8_0 | T+ 282\n",
            "[170/291] Writing tensor blk.18.attn_output.weight              | size   4096 x   4096  | type Q8_0 | T+ 282\n",
            "[171/291] Writing tensor blk.18.attn_q.weight                   | size   4096 x   4096  | type Q8_0 | T+ 282\n",
            "[172/291] Writing tensor blk.18.attn_v.weight                   | size   1024 x   4096  | type Q8_0 | T+ 282\n",
            "[173/291] Writing tensor blk.19.attn_norm.weight                | size   4096           | type F32  | T+ 282\n",
            "[174/291] Writing tensor blk.19.ffn_down.weight                 | size   4096 x  14336  | type Q8_0 | T+ 294\n",
            "[175/291] Writing tensor blk.19.ffn_gate.weight                 | size  14336 x   4096  | type Q8_0 | T+ 295\n",
            "[176/291] Writing tensor blk.19.ffn_up.weight                   | size  14336 x   4096  | type Q8_0 | T+ 296\n",
            "[177/291] Writing tensor blk.19.ffn_norm.weight                 | size   4096           | type F32  | T+ 296\n",
            "[178/291] Writing tensor blk.19.attn_k.weight                   | size   1024 x   4096  | type Q8_0 | T+ 296\n",
            "[179/291] Writing tensor blk.19.attn_output.weight              | size   4096 x   4096  | type Q8_0 | T+ 296\n",
            "[180/291] Writing tensor blk.19.attn_q.weight                   | size   4096 x   4096  | type Q8_0 | T+ 296\n",
            "[181/291] Writing tensor blk.19.attn_v.weight                   | size   1024 x   4096  | type Q8_0 | T+ 296\n",
            "[182/291] Writing tensor blk.20.attn_norm.weight                | size   4096           | type F32  | T+ 296\n",
            "[183/291] Writing tensor blk.20.ffn_down.weight                 | size   4096 x  14336  | type Q8_0 | T+ 308\n",
            "[184/291] Writing tensor blk.20.ffn_gate.weight                 | size  14336 x   4096  | type Q8_0 | T+ 309\n",
            "[185/291] Writing tensor blk.20.ffn_up.weight                   | size  14336 x   4096  | type Q8_0 | T+ 311\n",
            "[186/291] Writing tensor blk.20.ffn_norm.weight                 | size   4096           | type F32  | T+ 311\n",
            "[187/291] Writing tensor blk.20.attn_k.weight                   | size   1024 x   4096  | type Q8_0 | T+ 311\n",
            "[188/291] Writing tensor blk.20.attn_output.weight              | size   4096 x   4096  | type Q8_0 | T+ 311\n",
            "[189/291] Writing tensor blk.20.attn_q.weight                   | size   4096 x   4096  | type Q8_0 | T+ 311\n",
            "[190/291] Writing tensor blk.20.attn_v.weight                   | size   1024 x   4096  | type Q8_0 | T+ 311\n",
            "[191/291] Writing tensor blk.21.attn_norm.weight                | size   4096           | type F32  | T+ 311\n",
            "[192/291] Writing tensor blk.21.ffn_down.weight                 | size   4096 x  14336  | type Q8_0 | T+ 322\n",
            "[193/291] Writing tensor blk.21.ffn_gate.weight                 | size  14336 x   4096  | type Q8_0 | T+ 325\n",
            "[194/291] Writing tensor blk.21.ffn_up.weight                   | size  14336 x   4096  | type Q8_0 | T+ 325\n",
            "[195/291] Writing tensor blk.21.ffn_norm.weight                 | size   4096           | type F32  | T+ 326\n",
            "[196/291] Writing tensor blk.21.attn_k.weight                   | size   1024 x   4096  | type Q8_0 | T+ 326\n",
            "[197/291] Writing tensor blk.21.attn_output.weight              | size   4096 x   4096  | type Q8_0 | T+ 326\n",
            "[198/291] Writing tensor blk.21.attn_q.weight                   | size   4096 x   4096  | type Q8_0 | T+ 326\n",
            "[199/291] Writing tensor blk.21.attn_v.weight                   | size   1024 x   4096  | type Q8_0 | T+ 326\n",
            "[200/291] Writing tensor blk.22.attn_k.weight                   | size   1024 x   4096  | type Q8_0 | T+ 326\n",
            "[201/291] Writing tensor blk.22.attn_output.weight              | size   4096 x   4096  | type Q8_0 | T+ 329\n",
            "[202/291] Writing tensor blk.22.attn_q.weight                   | size   4096 x   4096  | type Q8_0 | T+ 329\n",
            "[203/291] Writing tensor blk.22.attn_v.weight                   | size   1024 x   4096  | type Q8_0 | T+ 329\n",
            "[204/291] Writing tensor output.weight                          | size  32002 x   4096  | type Q8_0 | T+ 351\n",
            "[205/291] Writing tensor blk.22.attn_norm.weight                | size   4096           | type F32  | T+ 352\n",
            "[206/291] Writing tensor blk.22.ffn_down.weight                 | size   4096 x  14336  | type Q8_0 | T+ 352\n",
            "[207/291] Writing tensor blk.22.ffn_gate.weight                 | size  14336 x   4096  | type Q8_0 | T+ 352\n",
            "[208/291] Writing tensor blk.22.ffn_up.weight                   | size  14336 x   4096  | type Q8_0 | T+ 352\n",
            "[209/291] Writing tensor blk.22.ffn_norm.weight                 | size   4096           | type F32  | T+ 352\n",
            "[210/291] Writing tensor blk.23.attn_norm.weight                | size   4096           | type F32  | T+ 352\n",
            "[211/291] Writing tensor blk.23.ffn_down.weight                 | size   4096 x  14336  | type Q8_0 | T+ 352\n",
            "[212/291] Writing tensor blk.23.ffn_gate.weight                 | size  14336 x   4096  | type Q8_0 | T+ 359\n",
            "[213/291] Writing tensor blk.23.ffn_up.weight                   | size  14336 x   4096  | type Q8_0 | T+ 360\n",
            "[214/291] Writing tensor blk.23.ffn_norm.weight                 | size   4096           | type F32  | T+ 360\n",
            "[215/291] Writing tensor blk.23.attn_k.weight                   | size   1024 x   4096  | type Q8_0 | T+ 360\n",
            "[216/291] Writing tensor blk.23.attn_output.weight              | size   4096 x   4096  | type Q8_0 | T+ 360\n",
            "[217/291] Writing tensor blk.23.attn_q.weight                   | size   4096 x   4096  | type Q8_0 | T+ 360\n",
            "[218/291] Writing tensor blk.23.attn_v.weight                   | size   1024 x   4096  | type Q8_0 | T+ 360\n",
            "[219/291] Writing tensor blk.24.attn_norm.weight                | size   4096           | type F32  | T+ 360\n",
            "[220/291] Writing tensor blk.24.ffn_down.weight                 | size   4096 x  14336  | type Q8_0 | T+ 372\n",
            "[221/291] Writing tensor blk.24.ffn_gate.weight                 | size  14336 x   4096  | type Q8_0 | T+ 373\n",
            "[222/291] Writing tensor blk.24.ffn_up.weight                   | size  14336 x   4096  | type Q8_0 | T+ 374\n",
            "[223/291] Writing tensor blk.24.ffn_norm.weight                 | size   4096           | type F32  | T+ 374\n",
            "[224/291] Writing tensor blk.24.attn_k.weight                   | size   1024 x   4096  | type Q8_0 | T+ 374\n",
            "[225/291] Writing tensor blk.24.attn_output.weight              | size   4096 x   4096  | type Q8_0 | T+ 374\n",
            "[226/291] Writing tensor blk.24.attn_q.weight                   | size   4096 x   4096  | type Q8_0 | T+ 374\n",
            "[227/291] Writing tensor blk.24.attn_v.weight                   | size   1024 x   4096  | type Q8_0 | T+ 374\n",
            "[228/291] Writing tensor blk.25.attn_norm.weight                | size   4096           | type F32  | T+ 374\n",
            "[229/291] Writing tensor blk.25.ffn_down.weight                 | size   4096 x  14336  | type Q8_0 | T+ 386\n",
            "[230/291] Writing tensor blk.25.ffn_gate.weight                 | size  14336 x   4096  | type Q8_0 | T+ 387\n",
            "[231/291] Writing tensor blk.25.ffn_up.weight                   | size  14336 x   4096  | type Q8_0 | T+ 388\n",
            "[232/291] Writing tensor blk.25.ffn_norm.weight                 | size   4096           | type F32  | T+ 388\n",
            "[233/291] Writing tensor blk.25.attn_k.weight                   | size   1024 x   4096  | type Q8_0 | T+ 388\n",
            "[234/291] Writing tensor blk.25.attn_output.weight              | size   4096 x   4096  | type Q8_0 | T+ 388\n",
            "[235/291] Writing tensor blk.25.attn_q.weight                   | size   4096 x   4096  | type Q8_0 | T+ 388\n",
            "[236/291] Writing tensor blk.25.attn_v.weight                   | size   1024 x   4096  | type Q8_0 | T+ 388\n",
            "[237/291] Writing tensor blk.26.attn_norm.weight                | size   4096           | type F32  | T+ 388\n",
            "[238/291] Writing tensor blk.26.ffn_down.weight                 | size   4096 x  14336  | type Q8_0 | T+ 399\n",
            "[239/291] Writing tensor blk.26.ffn_gate.weight                 | size  14336 x   4096  | type Q8_0 | T+ 401\n",
            "[240/291] Writing tensor blk.26.ffn_up.weight                   | size  14336 x   4096  | type Q8_0 | T+ 402\n",
            "[241/291] Writing tensor blk.26.ffn_norm.weight                 | size   4096           | type F32  | T+ 402\n",
            "[242/291] Writing tensor blk.26.attn_k.weight                   | size   1024 x   4096  | type Q8_0 | T+ 402\n",
            "[243/291] Writing tensor blk.26.attn_output.weight              | size   4096 x   4096  | type Q8_0 | T+ 402\n",
            "[244/291] Writing tensor blk.26.attn_q.weight                   | size   4096 x   4096  | type Q8_0 | T+ 402\n",
            "[245/291] Writing tensor blk.26.attn_v.weight                   | size   1024 x   4096  | type Q8_0 | T+ 402\n",
            "[246/291] Writing tensor blk.27.attn_norm.weight                | size   4096           | type F32  | T+ 402\n",
            "[247/291] Writing tensor blk.27.ffn_down.weight                 | size   4096 x  14336  | type Q8_0 | T+ 416\n",
            "[248/291] Writing tensor blk.27.ffn_gate.weight                 | size  14336 x   4096  | type Q8_0 | T+ 417\n",
            "[249/291] Writing tensor blk.27.ffn_up.weight                   | size  14336 x   4096  | type Q8_0 | T+ 419\n",
            "[250/291] Writing tensor blk.27.ffn_norm.weight                 | size   4096           | type F32  | T+ 420\n",
            "[251/291] Writing tensor blk.27.attn_k.weight                   | size   1024 x   4096  | type Q8_0 | T+ 420\n",
            "[252/291] Writing tensor blk.27.attn_output.weight              | size   4096 x   4096  | type Q8_0 | T+ 420\n",
            "[253/291] Writing tensor blk.27.attn_q.weight                   | size   4096 x   4096  | type Q8_0 | T+ 420\n",
            "[254/291] Writing tensor blk.27.attn_v.weight                   | size   1024 x   4096  | type Q8_0 | T+ 420\n",
            "[255/291] Writing tensor blk.28.attn_norm.weight                | size   4096           | type F32  | T+ 420\n",
            "[256/291] Writing tensor blk.28.ffn_down.weight                 | size   4096 x  14336  | type Q8_0 | T+ 428\n",
            "[257/291] Writing tensor blk.28.ffn_gate.weight                 | size  14336 x   4096  | type Q8_0 | T+ 431\n",
            "[258/291] Writing tensor blk.28.ffn_up.weight                   | size  14336 x   4096  | type Q8_0 | T+ 432\n",
            "[259/291] Writing tensor blk.28.ffn_norm.weight                 | size   4096           | type F32  | T+ 432\n",
            "[260/291] Writing tensor blk.28.attn_k.weight                   | size   1024 x   4096  | type Q8_0 | T+ 432\n",
            "[261/291] Writing tensor blk.28.attn_output.weight              | size   4096 x   4096  | type Q8_0 | T+ 432\n",
            "[262/291] Writing tensor blk.28.attn_q.weight                   | size   4096 x   4096  | type Q8_0 | T+ 433\n",
            "[263/291] Writing tensor blk.28.attn_v.weight                   | size   1024 x   4096  | type Q8_0 | T+ 433\n",
            "[264/291] Writing tensor blk.29.attn_norm.weight                | size   4096           | type F32  | T+ 433\n",
            "[265/291] Writing tensor blk.29.ffn_down.weight                 | size   4096 x  14336  | type Q8_0 | T+ 445\n",
            "[266/291] Writing tensor blk.29.ffn_gate.weight                 | size  14336 x   4096  | type Q8_0 | T+ 446\n",
            "[267/291] Writing tensor blk.29.ffn_up.weight                   | size  14336 x   4096  | type Q8_0 | T+ 447\n",
            "[268/291] Writing tensor blk.29.ffn_norm.weight                 | size   4096           | type F32  | T+ 447\n",
            "[269/291] Writing tensor blk.29.attn_k.weight                   | size   1024 x   4096  | type Q8_0 | T+ 447\n",
            "[270/291] Writing tensor blk.29.attn_output.weight              | size   4096 x   4096  | type Q8_0 | T+ 447\n",
            "[271/291] Writing tensor blk.29.attn_q.weight                   | size   4096 x   4096  | type Q8_0 | T+ 447\n",
            "[272/291] Writing tensor blk.29.attn_v.weight                   | size   1024 x   4096  | type Q8_0 | T+ 447\n",
            "[273/291] Writing tensor blk.30.attn_norm.weight                | size   4096           | type F32  | T+ 447\n",
            "[274/291] Writing tensor blk.30.ffn_down.weight                 | size   4096 x  14336  | type Q8_0 | T+ 458\n",
            "[275/291] Writing tensor blk.30.ffn_gate.weight                 | size  14336 x   4096  | type Q8_0 | T+ 460\n",
            "[276/291] Writing tensor blk.30.ffn_up.weight                   | size  14336 x   4096  | type Q8_0 | T+ 461\n",
            "[277/291] Writing tensor blk.30.ffn_norm.weight                 | size   4096           | type F32  | T+ 462\n",
            "[278/291] Writing tensor blk.30.attn_k.weight                   | size   1024 x   4096  | type Q8_0 | T+ 462\n",
            "[279/291] Writing tensor blk.30.attn_output.weight              | size   4096 x   4096  | type Q8_0 | T+ 462\n",
            "[280/291] Writing tensor blk.30.attn_q.weight                   | size   4096 x   4096  | type Q8_0 | T+ 462\n",
            "[281/291] Writing tensor blk.30.attn_v.weight                   | size   1024 x   4096  | type Q8_0 | T+ 462\n",
            "[282/291] Writing tensor blk.31.attn_norm.weight                | size   4096           | type F32  | T+ 462\n",
            "[283/291] Writing tensor blk.31.ffn_down.weight                 | size   4096 x  14336  | type Q8_0 | T+ 469\n",
            "[284/291] Writing tensor blk.31.ffn_gate.weight                 | size  14336 x   4096  | type Q8_0 | T+ 470\n",
            "[285/291] Writing tensor blk.31.ffn_up.weight                   | size  14336 x   4096  | type Q8_0 | T+ 472\n",
            "[286/291] Writing tensor blk.31.ffn_norm.weight                 | size   4096           | type F32  | T+ 472\n",
            "[287/291] Writing tensor blk.31.attn_k.weight                   | size   1024 x   4096  | type Q8_0 | T+ 472\n",
            "[288/291] Writing tensor blk.31.attn_output.weight              | size   4096 x   4096  | type Q8_0 | T+ 472\n",
            "[289/291] Writing tensor blk.31.attn_q.weight                   | size   4096 x   4096  | type Q8_0 | T+ 472\n",
            "[290/291] Writing tensor blk.31.attn_v.weight                   | size   1024 x   4096  | type Q8_0 | T+ 472\n",
            "[291/291] Writing tensor output_norm.weight                     | size   4096           | type F32  | T+ 472\n",
            "Wrote upshot-sih-7b-v2.0.gguf\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls -lash upshot-sih-7b-v2.0.gguf"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2krjRVnpLNJo",
        "outputId": "0d3968ed-c475-4e8f-954b-8c76d33be927"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "7.2G -rw-r--r-- 1 root root 7.2G Dec 14 23:23 upshot-sih-7b-v2.0.gguf\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "HUGGING_FACE_HUB_TOKEN = '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'"
      ],
      "metadata": {
        "id": "IfuYWTP-JWoz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from huggingface_hub import HfApi\n",
        "api = HfApi()\n",
        "\n",
        "model_id = \"Aditya685/upshot-7b-v2.0.gguf\"\n",
        "api.create_repo(model_id, exist_ok=True, repo_type=\"model\", token = HUGGING_FACE_HUB_TOKEN)\n",
        "api.upload_file(\n",
        "    path_or_fileobj=\"upshot-sih-7b-v2.0.gguf\",\n",
        "    path_in_repo=\"upshot-sih-7b-v2.0.gguf\",\n",
        "    repo_id=model_id,\n",
        "    token = HUGGING_FACE_HUB_TOKEN\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67,
          "referenced_widgets": [
            "b4538bac146543f49103cfeef567b5c8",
            "7f3aa6fa1f21468ba52f1bc60139ebce",
            "9ce108f35cb149c8aafca408e64a7e63",
            "040bcdbdfd3f4d34a4b65ec02da8d69f",
            "301561d4cc6e41dbae667c7331f3dd75",
            "8293cad12eb648b7b062770cb2f684d6",
            "1f9f630895ba4ebfb2e278a88766ff06",
            "ff81bdcb6c6b4fecbd9c0a1151f008c3",
            "693e4217f8d14c81bec27ff600feda01",
            "27d449c464f049efbfe902567cd44753",
            "050a6b5c55884e0a9a563d2dd77f5cc4"
          ]
        },
        "id": "OgyHGC7QLbi8",
        "outputId": "02cefd9d-c97d-4a67-9f93-0419a04a37f4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "upshot-sih-7b-v2.0.gguf:   0%|          | 0.00/7.70G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b4538bac146543f49103cfeef567b5c8"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'https://huggingface.co/Aditya685/upshot-7b-v2.0.gguf/blob/main/upshot-sih-7b-v2.0.gguf'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "source": [
        "api.upload_file(\n",
        "    path_or_fileobj=\"/content/upshot-sih-7b-v1.0.gguf.pt\",\n",
        "    path_in_repo=\"upshot-sih-7b-v1.0.gguf.pt\",\n",
        "    repo_id=model_id,\n",
        ")"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "IGs2RE6aMUlQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "cYO7-y78LqcQ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}